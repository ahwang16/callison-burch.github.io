<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "DTD/xhtml1-transitional.dtd">
<html>
<head>
<title>Chris Callison-Burch</title>
<link rel="stylesheet" href="include/computerscience-new.css" type="text/css" />
<script type="text/javascript" src="include/cs.js"></script>
<style type="text/css">
.hidden-abstract, .unhidden-abstract {
  text-indent: 0pt;
  margin: 10pt;
}

.hidden-abstract { 
  display: none; 
}

.unhidden-abstract { 
  display: block; 
  padding: 5pt;
  background-color: #EEEEEE;
}
</style>
<script type="text/javascript">
function unhide(divID) {
  var item = document.getElementById(divID);
    if (item) {
      item.className=(item.className=='hidden-abstract')?'unhidden-abstract':'hidden-abstract';
    }
  }
</script>
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-24970275-1']);
  _gaq.push(['_trackPageview']);
  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
</head>

<div id="frame">
	<div id="contentleft">

	<a href="http://cis.upenn.edu"><img src="images/upenn_logo.gif" alt="University of Pennsylvania" border="0px" width="150" /></a>

	</div>
  
	<div id="contentcenter">                  

<!-- begin header -->
<table width=100%>
<tr>
  <td align=left><img src="images/JHU2739.jpg" height="250" alt="Chris Callison-Burch"  border="0"></td>
  <td>
    <table>
      <tr><td nowrap><h2>Chris Callison-Burch</h2></td></tr>
      <tr><td nowrap>&nbsp;</td></tr>
      <tr><td nowrap>Computer and Information Science Department</td></tr>
      <tr><td nowrap>University of Pennsylvania</td></tr>
      <tr><td nowrap>Levine Hall room 506</td></tr>
      <tr><td nowrap>3330 Walnut Street</td></tr>
      <tr><td nowrap>Philadelphia, PA 19104</td></tr>
      <tr><td nowrap>&nbsp;</td></tr>
      <tr><td nowrap>Tel: 1 267 909 2668</td></tr>
      <tr><td>&#101;&#109;&#097;il: &#099;&#099;b&#064;&#099;is<img src="images/dot_1.jpg" align = "bottom" alt="." border="0">upenn<img src="images/dot_1.jpg" align = "bottom" alt="." border="0">edu</td></tr>
    </table></td></tr>
</table>
<!-- end header -->


<h2>Current Information</h2>
<!--
!-->

<p>I am the Aravind K Joshi Term Assistant Professor in the <a href="http://www.cis.upenn.edu/">Computer and Information Sciences Department</a> at the University of Pennsylvania.  I joined the department in the Fall of 2013.  
<!--  I will be starting there in September 2013, and I am looking for 2-3 new PhD students.  If you're interested in joining me at Penn <a href="http://www.cis.upenn.edu/grad/applications.shtml">apply here</a> by December 15, 2012.</p> 
On the personal front, my wife and I just had <a href="images/reed.jpg">our first fild</a>.
-->
My research interests include statistical machine translation, data-driven paraphrasing, crowdsourcing, and evaluation metrics.</p>

<p>In 2014 I was named a Sloan Research Fellow.  <a href="http://www.upenn.edu/pennnews/news/three-penn-researchers-awarded-sloan-fellowships">Here is a press release</a> from Penn about my research and the research of the two other Penn faculty members who received the award.</p>



<p>I am the program co-chair for <a href="http://emnlp2015.emnlp.org">EMNLP 2015 in Lisbon</a>. I am an action editor for the new journal Transactions of the ACL (<a href="http://www.transacl.org/">TACL</a>).  I recently finished my terms on the editorial board of <a href="http://cljournal.org/">Computational Linguistics</a>, and as the Chair of the <a href="http://naacl.org/">NAACL</a> Executive Board.</p>


<!--<p>I co-organize the annual <a href="http://statmt.org/wmt13/">Workshop on Statistical Machine Translation (WMT)</a>, which has several shared tasks to evaluate the quality of machine translation, confidence estimation for MT, and automatic evaluation metrics.  <a href="http://statmt.org/wmt13">WMT13</a> was held at <a href="http://acl2013.org/site/">ACL in Bulgaria</a>.</p>-->

<!--
<p>This year, I also co-organized a <a href="http://sites.google.com/site/amtworkshop2010/">workshop on creating speech and language data using Amazon's Mechanical Turk</a>, which was held at <a href="http://naaclhlt2010.isi.edu/">NAACL in LA</a>.  Amazon generously sponsored the workshop, giving $100 credits for researchers to try experiments, and Lukas Biewald of CrowdFlower gave an excellent invited talk.   There were two articles in the IEEE SLTC newsletter about the MTurk WS: <a href="http://www.signalprocessingsociety.org/technical-committees/list/sl-tc/spl-nl/2010-07/mturk-workshop-report/">a report on the workshop</a> and <a href="http://www.signalprocessingsociety.org/technical-committees/list/sl-tc/spl-nl/2010-07/mturk-workshop-organizers-interview/">an interview with Mark Dredze and me</a>.  I was <a href="images/mturk-leaderboard.jpg">#6 on the leaderboard</a> for MTurk Requesters for a while.</p>

<p>Last year, I served on the board of AMTA, helped to start the ACL SIGMT, was elected to the NAACL Executive Board and co-organized the <a href="http://art.uniroma2.it/TextInfer2009/">TextInfer workshop</a>. This year I was appointed to the editorial board of Computational Linguistics for a three year term, and I was promoted to associate research professor.</p>

<p>I am currently <a href="https://www.mturk.com/mturk/searchbar?requesterId=A32TTE4XXN6MQZ">translating 10,000 words in 100 languages</a> on Mechanical Turk.  If you speak another language, you can <a href="https://www.mturk.com/mturk/searchbar?requesterId=A32TTE4XXN6MQZ">help us translate</a>! Even if you are monolingual, you can <a href="https://www.mturk.com/mturk/searchbar?requesterId=A32TTE4XXN6MQZ&searchWords=synonyms">still help</a>.</p>
-->
<p>My research group develops <a href="http://joshua-decoder.org">Joshua, an open source decoder for statistical machine translation</a>, which uses synchronous context free grammars, and extracts linguistically informed translation rules. You can find information about the 5.0 release on the <a href="http://joshua-decoder.org/">Joshua decoder web site</a>.
<!-- The new software is on github: <a href="https://github.com/joshua-decoder">the Joshua decoder</a> and <a href="https://github.com/joshua-decoder/thrax">the Trax grammar extractor</a>.
-->
</p>

<!--
<p>I released my <a href="howto-extract-paraphrases.html">software for generating paraphrases</a> from parallel corpora, along with step-by-step instructions on how to use it.</p>
-->
<p>We have released <a href="http://paraphrase.org">PPDB, the paraphrase database</a>, a resource with 169 million paraphrase transformation rules.</p>

<h2>Research Group</h2>

<p>I work with lots of very talented students from the University of Pennsylvania and from Johns Hopkins University (where I was a research faculty member before joining Penn).  My research group is a small army (<a href="http://cis.upenn.edu/~ccb/images/TeCho2012.jpg">here's a group photo</a>):</p>
<ul>
<li>2nd year PhD student: Anne Cocos</li>
<li>4th year PhD student: <a href="http://www.seas.upenn.edu/~epavlick/">Ellie Pavlick</a>
<!-- (Ellie is keeping a <a href="http://elliepavlick.blogspot.com/">research journal about her work with me this summer</a>) -->
</li>
<li>Senior PhD students (JHU): <a href="http://cs.jhu.edu/~juri">Juri Ganitkevitch</a>, <a href="http://www.clsp.jhu.edu/people/napoles/">Courtney Napoles</a>, <a href="http://cs.jhu.edu/~jonny/">Jonny Weese</a></li>
<li>Postdoc (UPenn): <a href="http://www.cis.upenn.edu/~xwe/">Wei Xu</a></li>
<!--
<li>Undergraduate RAs (JHU): <a href="https://www.sites.google.com/site/joshlangfus/">Josh Langfus</a> (Josh kept <a href="http://jlangclsp.blogspot.com">a blog about his summer research)</a>, <a href="http://hilarypaisley.com/resume.html">Hilary Paisley</a> (Hilary kept <a href="http://hilarypaisley.wordpress.com">a blog about her summer research</a>)</li>
<li>Undergraduate RAs: <a href="http://www.ugrad.cs.jhu.edu/~kwu16/">Katherine Wu</a> </li>
 (Katherine is keeping a <a href="http://compscistory.blogspot.com/">blog about her summer work with me</a>)</li>
-->
</ul>
<!--
<p>I co-supervise many of my students with <a href="http://www.cs.jhu.edu/~vandurme/">Ben Van Durme</a>.  
We also run the <a href="http://cs.jhu.edu/~vandurme/techo/">Seminar in Meaning, Translation and Generation of Text</a> together.
!-->  

<!--
I work with two other machine translation researchers at the HLTCOE: <a href="http://www.cs.jhu.edu/~alopez/">Adam Lopez</a> and <a href="http://www.cs.rochester.edu/~post/">Matt Post</a>. We co-taught a <a href="http://mt-class.org/">Machine Translation</a> course in Spring 2012.</p>
-->


<p>Past members (and what they did after working with me):
<p><b>PhD students:</b> 
<a href="http://www.clsp.jhu.edu/people/anni">Ann Irvine</a> (<a href="http://redowlanalytics.com">Red Owl Analytics</a>), 
<a href="http://www.cs.jhu.edu/~xuchen/">Xuchen Yao</a> (an AI2 incubated startup called <a href="http://kitt.ai">KITT.AI</a>),
<a href="http://www.cs.jhu.edu/~ozaidan/">Omar Zaidan</a> (Microsoft Research),
<a href="http://dowobeha.github.io/">Lane Schwartz</a> (first AFRL, now a faculty member at UIUC),
<a href="http://www.cs.jhu.edu/~zfli/">Zhifei Li</a> (Google)
</p>

<p><b>Postdocs:</b>
<a href="http://www.cs.jhu.edu/~aklement/">Alex Klementiev</a> (second postdoc at Saarland University, now doing machine learning research at Amazon)
</p>

<p><b>Masters students:</b>
<a href="https://sites.google.com/site/mingkungao/">Mingkun Gao</a> (PhD at UIUC),
Rui Yan,
Byung Gyu Ahn (Google), 
<a href="http://hubal.cs.jhu.edu/personal/">Ryan Cotterell</a> (PhD at JHU), 
Gaurav Kumar  (PhD at JHU), 
<a href="http://www.linkedin.com/pub/luke-orland/7/62b/545">Luke Orland</a> (<a href="Voxy.com">Voxy.com</a>)</a>, 
<a href="http://www.clsp.jhu.edu/~tsz/">Charley Chan</a> (Bloomberg),  
Wren Thornton (PhD in cognitive science at Indiana University)
</p>


<p>
<b>Research programmer</b>
<a href="http://about.me/dmitrykachaev/">Dmitry Kachaev</a>  (Presidential Innovation Fellow)
</p>

<!--
<p>
<b>Undergrads</b>
<a href="http://ugrad.cs.jhu.edu/~sjeblee/">Serena Jeblee</a> (master's student at CMU/LTI), 
</p>
-->




<p>I served on the thesis committees of Paramveer Dhillon, Qiuye "Sofie" Zhao, Ann Irvine, Xuchen Yao, Emily Pitler, Chang Hu, Hala Almaghout, Emily Tucker Prud'hommeaux, Aaron Phillips, Omar Zaidan, Lane Schwartz, Zhifei Li, Nitin Madnani, Yuval Marton, Elliott Drabek and Roy Tromble.</p>

<!--
<p>Past visitors: Abby Levenberg (Edinburgh), <a href="http://www.coli.uni-saarland.de/~rwang/">Rui Wang</a> (Saarland), and <a href="http://www.coli.uni-saarland.de/~micha/">Michael Jellinghaus</a> (Saarland)
</p>
-->

<h2>Teaching</h2>

<h3><a href="http://crowdsourcing-class.org">Crowdsourcing and Human Computation</a> (Spring 2016)</h3> 
<p>Crowdsourcing and human computation are emerging fields that sit squarely at the intersection of economics and computer science. They examine how people can be used to solve complex tasks that are currently beyond the capabilities of artificial intelligence algorithms. Online marketplaces like Mechanical Turk provide an infrastructure that allows micropayments to be given to people in return for completing human intelligence tasks. This opens up previously unthinkable possibilities like people being used as function calls in software. We will investigate how crowdsourcing can be used for computer science applications like machine learning, next-generation interfaces, and data mining. Beyond these computer science aspects, we will also delve into topics like prediction markets, how businesses can capitalize on collective intelligence, and the fundamental principles that underly democracy and other group decision-making processes.</p>

<h3><a href="http://mt-class.org">Machine Translation</a> (next offered Spring 2017)</h3>
<p>Google translate can instantly translate between any pair of over fifty human languages (for instance, from French to English). How does it do that? Why does it make the errors that it does? And how can you build something better? Modern translation systems like Google Translate and Bing Translator learn how to translate by reading millions of words of already translated text, and this course will show you how they work. The course covers a diverse set of fundamental building blocks from linguistics, machine learning, algorithms, data structures, and formal language theory, along with their application to a real and difficult problem in artificial intelligence.</p>

<h2>Publications [<a href=callisonburch-publications.bib>bib</a>]</h2>

<h3>2015</h3>
<a name="new-data-for-text-simplification" />
<P><a href="publications/new-data-for-text-simplification.pdf">Problems in Current Text Simplification Research: New Data Can Help</a>. Wei Xu, Chris Callison-Burch, and Courtney Napoles. In  TACL-2015.
<a href="javascript:unhide('abstract/new-data-for-text-simplification')">[abstract]</a>
<a href="javascript:unhide('bib/new-data-for-text-simplification')">[bib]</a>
<div id="abstract/new-data-for-text-simplification" class="hidden-abstract">
Simple Wikipedia has dominated simplification research in the past 5 years. In this opinion paper, we argue that focusing on Wikipedia limits simplification research. We back up our arguments with corpus analysis and by highlighting statements that other researchers have made in the simplification literature. We introduce a new simplification dataset that is a significant improvement over Simple Wikipedia, and present a novel quantitative-comparative approach to study the quality of simplification data resources.
</div>
<div id="bib/new-data-for-text-simplification" class="hidden-abstract">
<font size="-2">
<pre>
@article{Xu-EtAl:2015:TACL,
  author = {Wei Xu and Chris Callison-Burch and Courtney Napoles},
  title = {Problems in Current Text Simplification Research: New Data Can
Help},
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {3},
  year = {2015},
  url = {http://www.cis.upenn.edu/~ccb/publications/new-data-for-text-simplification.pdf},
  pages = {283--297}
}
</pre>
</font>
</div>
</P>


<a name="adding-semantics-to-data-driven-paraphrasing" />
<P><a href="publications/adding-semantics-to-data-driven-paraphrasing.pdf">Adding Semantics to Data-Driven Paraphrasing</a>. Ellie Pavlick, Johan Bos, Malvina Nissim, Charley Beller, Benjamin Van Durme, and Chris Callison-Burch. In ACL-2015.
<a href="javascript:unhide('abstract/adding-semantics-to-data-driven-paraphrasing')">[abstract]</a>
<a href="javascript:unhide('bib/adding-semantics-to-data-driven-paraphrasing')">[bib]</a>
<div id="abstract/adding-semantics-to-data-driven-paraphrasing" class="hidden-abstract">
We add an interpretable semantics to the paraphrase database (PPDB). To date, the relationship between the phrase pairs in the database has been weakly defined as approximately equivalent. We show that in fact these pairs represent a variety of relations, including directed entailment (little girl/girl) and exclusion (nobody/someone). We automatically assign semantic entailment relations to entries in PPDB using features derived from past work on discovering inference rules from text and semantic taxonomy induction. We demonstrate that our model assigns these entailment relations with high accuracy. In a downstream RTE task, our labels rival relations from WordNet and improve the coverage of a proof-based RTE system by 17%.
</div>
<div id="bib/adding-semantics-to-data-driven-paraphrasing" class="hidden-abstract">
<font size="-2">
<pre>
@inproceedings{Pavlick-EtAl:2015:ACL,
author = {Ellie Pavlick and Johan Bos and Malvina Nissim and Charley Beller and Benjamin Van Durme and Chris Callison-Burch},
title = {Cost Optimization in Crowdsourcing Translation},
booktitle = {The 53rd Annual Meeting of the Association for Computational
Linguistics (ACL 2015)},
month = {July},
year = {2015},
address = {Beijing, China},
url = {http://www.cis.upenn.edu/~ccb/publications/adding-semantics-to-data-driven-paraphrasing.pdf}
}
</pre>
</font>
</div>
</P>



<a name="cost-optimization-for-crowdsourcing-translation" />
<P><a href="publications/cost-optimization-for-crowdsourcing-translation.pdf">Cost Optimization for Crowdsourcing Translation</a>. Mingkun Gao, Wei Xu, and Chris Callison-Burch. In  NAACL-2015.
<a href="javascript:unhide('abstract/cost-optimization-for-crowdsourcing-translation')">[abstract]</a>
<a href="javascript:unhide('bib/cost-optimization-for-crowdsourcing-translation')">[bib]</a>
<div id="abstract/cost-optimization-for-crowdsourcing-translation" class="hidden-abstract">
Crowdsourcing makes it possible to create translations at much lower cost than hiring professional translators. However, it is still expensive to obtain the millions of translations that are needed to train statistical machine translation systems. We propose two mechanisms to reduce the cost of crowdsourcing while maintaining high translation quality. First, we develop a method to reduce redundant translations. We train a linear model to evaluate the translation quality on a sentence-by-sentence basis, and fit a threshold between acceptable and unacceptable translations. Unlike past work, which always paid for a fixed number of translations for each source sentence and then chose the best from them, we can stop earlier and pay less when we receive a translation that is good enough. Second, we introduce a method to reduce the pool of translators by quickly identifying bad translators after they have translated only a few sentences. This also allows us to rank translators, so that we re-hire only good translators to reduce cost.
</div>
<div id="bib/cost-optimization-for-crowdsourcing-translation" class="hidden-abstract">
<font size="-2">
<pre>
@inproceedings{Gao-EtAl:2015:NAACL,
author = {Mingkun Gao and Wei Xu and Chris Callison-Burch},
title = {Cost Optimization in Crowdsourcing Translation},
booktitle = {Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL 2015)},
month = {June},
year = {2015},
address = {Denver, Colorado},
url = {http://www.cis.upenn.edu/~ccb/publications/cost-optimization-for-crowdsourcing-translation.pdf}
}
</pre>
</font>
</div>
</P>



<a name="paraphrase-and-semantic-similarity-in-twitter" />
<P><a href="publications/paraphrase-and-semantic-similarity-in-twitter.pdf">SemEval-2015 Task 1: Paraphrase and Semantic Similarity in Twitter</a>. Wei Xu, Chris Callison-Burch, and Bill Dolan. In  SemEval-2015.
<a href="javascript:unhide('abstract/paraphrase-and-semantic-similarity-in-twitter')">[abstract]</a>
<a href="javascript:unhide('bib/paraphrase-and-semantic-similarity-in-twitter')">[bib]</a>
<div id="abstract/paraphrase-and-semantic-similarity-in-twitter" class="hidden-abstract">
In this shared task, we present evaluations on two related tasks Paraphrase Identification (PI) and Semantic Textual Similarity (SS) systems for the Twitter data. Given a pair of sentences, participants are asked to produce a binary yes/no judgement or a graded score to measure their semantic equivalence. The task features a newly constructed Twitter Paraphrase Corpus that contains 18,762 sentence pairs. A total of 19 teams participated, submitting 36 runs to the PI task and 26 runs to the SS task. The evaluation shows encouraging results and open challenges for future research. The best systems scored a F1-measure of 0.674 for the PI task and a Pearson correlation of 0.619 for the SS task respectively, comparing to a strong baseline using logistic regression model of 0.589 F1 and 0.511 Pearson; while the best SS systems can often reach >0.80 Pearson on well-formed text. This shared task also provides insights into the relation between the PI and SS tasks and suggests the importance to bringing these two research areas together. We make all the data, baseline systems and evaluation scripts publicly available.
</div>
<div id="bib/paraphrase-and-semantic-similarity-in-twitter" class="hidden-abstract">
<font size="-2">
<pre>
@inproceedings{Xu-EtAl:2015:semeval,
  author    = {Wei Xu and Chris Callison-Burch and William B. Dolan},
  title     = {{SemEval-2015 Task} 1: Paraphrase and Semantic Similarity in {Twitter} ({PIT})},
  booktitle = {Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval)},
  year      = {2015},
  url = 
}
</pre>
</font>
</div>
</P>




<h3>2014</h3>
<a name="extracting-paraphrases-from-twitter" />
<P><a href="publications/extracting-paraphrases-from-twitter.pdf">Extracting Lexically Divergent Paraphrases from Twitter</a>. Wei Xu, Alan Ritter, Chris Callison-Burch, William B. Dolan and Yangfeng Ji. In TACL-2014.
<a href="javascript:unhide('abstract/extracting-paraphrases-from-twitter')">[abstract]</a>
<a href="javascript:unhide('bib/extracting-paraphrases-from-twitter')">[bib]</a>
<div id="abstract/extracting-paraphrases-from-twitter" class="hidden-abstract">
We present MULTIP (Multi-instance Learning Paraphrase Model), a new model suited to identify paraphrases within the short messages on Twitter. We jointly model paraphrase relations between word and sentence pairs and assume only sentence-level annotations during learning. Using this principled latent variable model alone, we achieve the performance competitive with a state-of-the-art method which combines a latent space model with a feature-based supervised classifier. Our model also captures lexically divergent paraphrases that differ from yet complement previous methods; combining our model with previous work significantly outperforms the state-of-the-art. In addition, we present a novel annotation methodology that has allowed us to crowdsource a paraphrase corpus from Twitter. We make this new dataset available to the research community.
</div>
<div id="bib/extracting-paraphrases-from-twitter" class="hidden-abstract">
<font size="-2">
<pre>
@article{Xu-EtAl-2014:TACL,
  author =  {Wei Xu and Alan Ritter and Chris Callison-Burch and William B. Dolan and Yangfeng Ji},
  title =   {Extracting Lexically Divergent Paraphrases from {Twitter}},
  journal = {Transactions of the Association for Computational Linguistics},
  volume =  {2},
  number =  {},
  year =    {2014},
  pages = {435--448},
  publisher = {Association for Computational Linguistics},
  url = {http://cis.upenn.edu/~ccb/publications/extracting-paraphrases-from-twitter.pdf}
}
</pre>
</font>
</div>
</P>




<a name="callhome-egyptian-arabic-speech-translations" />
<P><a href="publications/callhome-egyptian-arabic-speech-translations.pdf">Translations of the CALLHOME Egyptian Arabic corpus for conversational speech translation</a>. Gaurav Kumar, Yuan Cao, Ryan Cotterell, Chris Callison-Burch, Daniel Povey, and Sanjeev Khudanpur.  In IWSLT-2014.
<a href="javascript:unhide('abstract/callhome-egyptian-arabic-speech-translations')">[abstract]</a>
<a href="javascript:unhide('bib/callhome-egyptian-arabic-speech-translations')">[bib]</a>
<div id="abstract/callhome-egyptian-arabic-speech-translations" class="hidden-abstract">
Translation of the output of automatic speech recognition (ASR) systems, also known as speech translation, has received a lot of research interest recently. This is especially true for programs such as DARPA BOLT which focus on improving spontaneous human-human conversation across languages. However, this research is hindered by the dearth of datasets developed for this explicit purpose. For Egyptian Arabic-English, in particular, no parallel speech-transcription-translation dataset exists in the same domain. In order to support research in speech translation, we introduce the Callhome Egyptian Arabic-English Speech Translation Corpus. This supplements the existing LDC corpus with four reference translations for each utterance in the transcripts. The result is a three-way parallel dataset of Egyptian Arabic Speech, transcriptions and English translations.
</div>
<div id="bib/callhome-egyptian-arabic-speech-translations" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{kumar-EtAl:2014:IWSLT,
  author    = {Matt Post and Gaurav Kumar and Adam Lopez and Damianos Karakos and Chris Callison-Burch and Sanjeev Khudanpur},
  title     = {Translations of the {CALLHOME} {Egyptian} {Arabic} corpus for conversational speech translation},
  booktitle = {Proceedings of the International Workshop on Spoken Language Translation (IWSLT)}
  month     = {December},
  year      = {2014},
  address   = {Lake Tahoe, USA},
  publisher = {Association for Computational Linguistics},
  url = {http://cis.upenn.edu/~ccb/publications/callhome-egyptian-arabic-speech-translations.pdf}
}
</pre>
</font>
</div>
</P>



<a name="poetry-generation-with-crowdsourcing" />
<P><a href="publications/poetry-generation-with-crowdsourcing.pdf">Poetry of the Crowd: A Human Computation Algorithm to Convert Prose into Rhyming Verse</a>. Quanze Chen, Chenyang Lei, Wei Xu, Ellie Pavlick and Chris Callison-Burch. In HCOMP-2014 Poster. 
<a href="javascript:unhide('abstract/poetry-generation-with-crowdsourcing')">[abstract]</a>
<a href="javascript:unhide('bib/poetry-generation-with-crowdsourcing')">[bib]</a>
<div id="abstract/poetry-generation-with-crowdsourcing" class="hidden-abstract">
Poetry composition is a very complex task that requires a poet to satisfy multiple constraints concurrently. We believe that the task can be augmented by combining the creative abilities of humans with computational algorithms that efficiently constrain and permute available choices. We present a hybrid method for generating poetry from prose that combines crowdsourcing with natural language processing (NLP) machinery. We test the ability of crowd workers to accomplish the technically challenging and creative task of composing poems.
</div>
<div id="bib/poetry-generation-with-crowdsourcing" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{Chen-et-al:HCOMP:2014,
  author    = {Quanze Chen and Chenyang Lei and Wei Xu and Ellie Pavlick and Chris Callison-Burch},
  title     = {Poetry of the Crowd: A Human Computation Algorithm to Convert Prose into Rhyming Verse},
  booktitle = {The Second AAAI Conference on Human Computation and Crowdsourcing (HCOMP-2014)},
  month     = {November},
  year      = {2014},
  url       = {http://cis.upenn.edu/~ccb/publications/poetry-generation-with-crowdsourcing.pdf}
}
</pre>
</font>
</div>
</P>


<a name="crowd-workers" />
<P><a href="publications/crowd-workers.pdf">Crowd-Workers: Aggregating Information Across Turkers To Help Them Find Higher Paying Work</a>. Chris Callison-Burch. In HCOMP-2014 Poster.
<a href="javascript:unhide('abstract/crowd-workers')">[abstract]</a>
<a href="javascript:unhide('bib/crowd-workers')">[bib]</a>
<div id="abstract/crowd-workers" class="hidden-abstract">
The Mechanical Turk crowdsourcing platform currently fails to provide the most basic piece of information to enable workers to make informed decisions about which tasks to undertake: what is the expected hourly pay? Mechanical Turk advertises a reward amount per assignment, but does not give any indication of how long each assignment will take. We have developed a browser plugin that tracks the length of time it takes to complete a task, and a web service that aggregates the information across many workers. Crowd-Workers. com allows workers to discovery higher paying work by sorting tasks by estimated hourly rate.
</div>
<div id="bib/crowd-workers" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{Chen-et-al:HCOMP:2014,
  author    = {Chris Callison-Burch},
  title     = {Crowd-Workers: Aggregating Information Across Turkers To Help Them Find Higher Paying Work},
  booktitle = {The Second AAAI Conference on Human Computation and Crowdsourcing (HCOMP-2014)},
  month     = {November},
  year      = {2014},
  url       = {http://cis.upenn.edu/~ccb/publications/crowd-workers.pdf}
}
</pre>
</font>
</div>
</P>



<a name="language-demographics-of-mechanical-turk" />
<P><a href="publications/language-demographics-of-mechanical-turk.pdf">The Language Demographics of  Amazon Mechanical Turk</a>. Ellie Pavlick, Matt Post, Ann Irvine, Dmitry Kachaev, and Chris Callison-Burch. In TACL-2014.
<a href="javascript:unhide('abstract/language-demographics-of-mechanical-turk')">[abstract]</a>
<a href="javascript:unhide('bib/language-demographics-of-mechanical-turk')">[bib]</a>
<div id="abstract/language-demographics-of-mechanical-turk" class="hidden-abstract">
We present a large scale study of the languages spoken by bilingual workers on Mechanical Turk (MTurk). We establish a  methodology for determining the language skills of anonymous crowd workers that is more robust than simple surveying.  We validate workers' self-reported language skill claims by measuring their ability to correctly translate words, and by geolocating workers to see if they reside in countries where the languages are likely to be spoken. Rather than posting a one-off survey, we posted paid tasks consisting of 1,000 assignments to translate a total of 10,000 words in each of 100 languages.  Our study ran for several months, and was highly visible on the MTurk crowdsourcing platform, increasing the chances that bilingual workers would complete it.  Our study was useful both to create bilingual dictionaries and to act as census of the bilingual speakers on MTurk.  We use this data to recommend languages with the largest speaker populations as good candidates for other researchers who want to  develop crowdsourced, multilingual technologies. To further demonstrate the value of creating data via crowdsourcing, we hire workers to create bilingual parallel corpora in six Indian languages, and use them to train statistical machine translation systems. 
</div>
<div id="bib/language-demographics-of-mechanical-turk" class="hidden-abstract">
<font size="-2">
<pre>
@article{Pavlick-EtAl-2014:TACL,
  author =  {Ellie Pavlick and Matt Post and Ann Irvine and Dmitry Kachaev and Chris Callison-Burch},
  title =   {The Language Demographics of {Amazon Mechanical Turk}},
  journal = {Transactions of the Association for Computational Linguistics},
  volume =  {2},
  number =  {Feb},
  year =    {2014},
  pages = {79--92},
  publisher = {Association for Computational Linguistics},
  url = {http://cis.upenn.edu/~ccb/publications/language-demographics-of-mechanical-turk.pdf}
}
</pre>
</font>
</div>
</P>


<a name="hallucinating-phrase-translations" />
<P><a href="publications/hallucinating-phrase-translations.pdf">Hallucinating Phrase Translations for Low Resource MT</a>. Ann Irvine and Chris Callison-Burch. In CoNLL-2014.
<a href="javascript:unhide('abstract/hallucinating-phrase-translations')">[abstract]</a>
<a href="javascript:unhide('bib/hallucinating-phrase-translations')">[bib]</a>
<div id="abstract/hallucinating-phrase-translations" class="hidden-abstract">
We demonstrate that “hallucinating” phrasal translations can significantly improve the quality of machine translation in low resource conditions. Our hallucinated phrase tables consist of entries composed from multiple unigram translations drawn from the baseline phrase table and from translations that are induced from monolingual corpora. The hallucinated phrase table is very noisy. Its translations are low precision but high recall. We counter this by introducing 30 new feature functions (including a variety of monolingually-estimated features) and by aggressively pruning the phrase table. Our analysis evaluates the intrinsic quality of our hallucinated phrase pairs as well as their impact in end-to-end Spanish-English and Hindi-English MT.
</div>
<div id="bib/hallucinating-phrase-translations" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{irvine-callisonburch:2014:W14-16,
  author    = {Irvine, Ann  and  Callison-Burch, Chris},
  title     = {Hallucinating Phrase Translations for Low Resource MT},
  booktitle = {Proceedings of the Eighteenth Conference on Computational Natural Language Learning},
  month     = {June},
  year      = {2014},
  pages     = {160--170},
  url       = {http://www.aclweb.org/anthology/W14-1617}
}
</pre>
</font>
</div>
</P>


<a name="using-comparable-corpora-for-mt-adaptation" />
<P><a href="publications/using-comparable-corpora-for-mt-adaptation.pdf">Using Comparable Corpora to Adapt MT Models to New Domains</a>. Ann Irvine and Chris Callison-Burch. In WMT-2014.
<a href="javascript:unhide('abstract/using-comparable-corpora-for-mt-adaptation')">[abstract]</a>
<a href="javascript:unhide('bib/using-comparable-corpora-for-mt-adaptation')">[bib]</a>
<div id="abstract/using-comparable-corpora-for-mt-adaptation" class="hidden-abstract">
In previous work we showed that when using an SMT model trained on old-domain data to translate text in a new-domain, most errors are due to unseen source words, unseen target translations, and inaccurate translation model scores (Irvine et al., 2013a). In this work, we target errors due to inaccurate translation model scores using new-domain comparable corpora, which we mine from Wikipedia. We assume that we have access to a large olddomain parallel training corpus but only enough new-domain parallel data to tune model parameters and do evaluation. We use the new-domain comparable corpora to estimate additional feature scores over the phrase pairs in our baseline models. Augmenting models with the new features improves the quality of machine translations in the medical and science domains by up to 1.3 BLEU points over very strong baselines trained on the 150 million word Canadian Hansard dataset.
</div>
<div id="bib/using-comparable-corpora-for-mt-adaptation" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{irvine-callisonburch:2014:W14-33,
  author    = {Irvine, Ann  and  Callison-Burch, Chris},
  title     = {Using Comparable Corpora to Adapt MT Models to New Domains},
  booktitle = {Proceedings of the Ninth Workshop on Statistical Machine Translation},
  month     = {June},
  year      = {2014},
  pages     = {437--444},
  url       = {http://www.aclweb.org/anthology/W14-3357}
}
</pre>
</font>
</div>
</P>


<a name="crowdsourced-translation-via-collaboration-between-translators-and-editors" />
<P><a href="publications/crowdsourced-translation-via-collaboration-between-translators-and-editors.pdf">Are Two Heads are Better than One? Crowdsourced Translation via a Two-Step Collaboration between Translators and Editors</a>. Rui Yan, Mingkun Gao, Ellie Pavlick, and Chris Callison-Burch. In ACL-2014.
<a href="javascript:unhide('abstract/crowdsourced-translation-via-collaboration-between-translators-and-editors')">[abstract]</a>
<a href="javascript:unhide('bib/crowdsourced-translation-via-collaboration-between-translators-and-editors')">[bib]</a>
<div id="abstract/crowdsourced-translation-via-collaboration-between-translators-and-editors" class="hidden-abstract">
  Crowdsourcing is a viable mechanism for creating training data for machine translation.  It provides a low cost, fast turn-around way of processing large volumes of data. However, when compared professional translation, naive collection of translations from non-professionals yields low-quality results. Careful quality control is necessary for crowdsourcing to work well. In this paper, we examine the challenges of a two-step collaboration process with translation and post-editing by non-professionals.  We develop graph-based ranking models that automatically select the best output from multiple redundant versions of translations and edits, and improves translation quality closer to professionals. 
</div>
<div id="bib/crowdsourced-translation-via-collaboration-between-translators-and-editors" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{Yan-EtAl-2014:ACL,
  author =  {Rui Yan and Mingkun Gao and Ellie Pavlick and Chris Callison-Burch},
  title =   {Are Two Heads are Better than One? Crowdsourced Translation via a Two-Step Collaboration between Translators and Editors},
  booktitle = {The 52nd Annual Meeting of the Association for Computational Linguistics},
  month     = {June},
  year      = {2014},
  address   = {Baltimore, Maryland},
  publisher = {Association for Computional Linguistics},
  url = {http://www.cis.upenn.edu/~ccb/publications/crowdsourced-translation-via-collaboration-between-translators-and-editors.pdf}
}
</pre>
</font>
</div>
</P>


<a name="paradigm-paraphrase-evaluation" />
<P><a href="publications/paradigm-paraphrase-evaluation.pdf">PARADIGM: Paraphrase Diagnostics through Grammar Matching</a>. Jonathan Weese, Juri Ganitkevitch, and Chris Callison-Burch. EACL-2014.
<a href="javascript:unhide('abstract/paradigm-paraphrase-evaluation')">[abstract]</a>
<a href="javascript:unhide('bib/paradigm-paraphrase-evaluation')">[bib]</a>
<div id="abstract/paradigm-paraphrase-evaluation" class="hidden-abstract">
Paraphrase evaluation is typically done either manually or through indirect, task-based evaluation. We introduce an intrinsic evaluation PARADIGM which measures the goodness of paraphrase collections that are represented using synchronous grammars. We formulate two measures that evaluate these paraphrase grammars using gold standard sentential paraphrases drawn from a monolingual parallel corpus. The first measure calculates how often a paraphrase grammar is able to synchronously parse the sentence pairs in the corpus. The second measure enumerates paraphrase rules from the monolingual parallel corpus and calculates the overlap between this reference paraphrase collection and the paraphrase resource being evaluated. We demonstrate the use of these evaluation metrics on paraphrase collections derived from three different data types: multiple translations of classic French novels, comparable sentence pairs drawn from different newspapers, and bilingual parallel corpora. We show that PARADIGM correlates with human judgments more strongly than BLEU on a task-based evaluation of paraphrase quality.
</div>
<div id="bib/paradigm-paraphrase-evaluation" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{Weese-EtAl:2014:EACL,
  author    = {Jonathan Weese and Juri Ganitkevitch and Chris Callison-Burch},
  title     = {PARADIGM: Paraphrase Diagnostics through Grammar Matching},
  booktitle = {14th Conference of the European Chapter of the Association for Computational Linguistics},
  month     = {April},
  year      = {2014},
  address   = {Gothenburg, Sweden},
  publisher = {Association for Computional Linguistics},
  url       = {http://cis.upenn.edu/~ccb/publications/paradigm-paraphrase-evaluation.pdf}}
}
</pre>
</font>
</div>
</P>


<a name="crowdsourcing-for-grammatical-error-correction" />
<P><a href="publications/crowdsourcing-for-grammatical-error-correction.pdf">Crowdsourcing for Grammatical Error Correction</a>. Ellie Pavlick, Rui Yan, and Chris Callison-Burch. CSCW-2014 Poster.
<a href="javascript:unhide('abstract/crowdsourcing-for-grammatical-error-correction')">[abstract]</a>
<a href="javascript:unhide('bib/crowdsourcing-for-grammatical-error-correction')">[bib]</a>
<div id="abstract/crowdsourcing-for-grammatical-error-correction" class="hidden-abstract">
We discuss the problem of grammatical error correction, which has gained attention for its usefulness both in the development of tools for learners of foreign languages and as a component of statistical machine translation systems. We believe the task of suggesting grammar and style corrections in writing is well suited to a crowdsourcing solution but is currently hindered by the difficulty of automatic quality control. In this proposal, we motivate the problem of grammatical error correction and outline the challenges of ensuring quality in a setting where traditional methods of aggregation (e.g. majority vote) fail to produce the desired results. We then propose a design for quality control and present preliminary results indicating the potential of crowd workers to provide a scalable solution.
</div>
<div id="bib/crowdsourcing-for-grammatical-error-correction" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{Pavlick-EtAl:2014:CSCW,
  author    = {Ellie Pavlick and Rui Yan and Chris Callison-Burch},
  title     = {Crowdsourcing for Grammatical Error Correction},
  booktitle = {17th ACM Conference on Computer Supported Cooperative Work and Social Computing, Companion Volume},
  month     = {February},
  year      = {2014},
  address   = {Baltimore, Maryland},
  publisher = {Association for Computing Machinery},
  pages     = {209--213},
  url       = {http://cis.upenn.edu/~ccb/publications/crowdsourcing-for-grammatical-error-correction.pdf}}
}
</pre>
</font>
</div>
</P>

<a name="ppdb-multilingual" />
<P><a href="publications/ppdb-multilingual.pdf">The Multilingual Paraphrase Database</a>. Juri Ganitkevitch and Chris Callison-Burch. In LREC-2014.
<a href="javascript:unhide('abstract/ppdb-multilingual')">[abstract]</a>
<a href="javascript:unhide('bib/ppdb-multilingual')">[bib]</a>
<div id="abstract/ppdb-multilingual" class="hidden-abstract">
We release a massive expansion of the paraphrase database (PPDB) that now includes a collection of paraphrases in 23 different languages. The resource is derived from large volumes of bilingual parallel data. Our collection is extracted and ranked using state of the art methods. The multilingual PPDB has over a billion paraphrase pairs in total, covering the following languages: Arabic, Bulgarian, Chinese, Czech, Dutch, Estonian, Finnish, French, German, Greek, Hungarian, Italian, Latvian, Lithuanian, Polish, Portugese, Romanian, Russian, Slovak, Slovenian, and Swedish.
</div>
<div id="bib/ppdb-multilingual" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{Ganitkevitch-Callison-Burch-2014:LREC,
  author =  {Juri Ganitkevitch and Chris Callison-Burch},
  title =   {The Multilingual Paraphrase Database},
  booktitle = {The 9th edition of the Language Resources and Evaluation Conference},
  month     = {May},
  year      = {2014},
  address   = {Reykjavik, Iceland},
  pages     = {},
  publisher = {European Language Resources Association},
  url = {http://cis.upenn.edu/~ccb/publications/ppdb-multilingual.pdf}
}
</pre>
</font>
</div>
</P>

<a name="american-local-news-corpus" />
<P><a href="publications/american-local-news-corpus.pdf">The American Local News Corpus</a>. Ann Irvine, Joshua Langfus, and Chris Callison-Burch. In LREC-2014.
<a href="javascript:unhide('abstract/american-local-news-corpus')">[abstract]</a>
<a href="javascript:unhide('bib/american-local-news-corpus')">[bib]</a>
<div id="abstract/american-local-news-corpus" class="hidden-abstract">
We present the American Local News Corpus (ALNC), containing over 4 billion words of text from 2, 652 online newspapers in the United States. Each article in the corpus is associated with a timestamp, state, and city. All 50 U.S. states and 1, 924 cities are represented. We detail our method for taking daily snapshots of thousands of local and national newspapers and present two example corpus analyses. The first explores how different sports are talked about over time and geography. The second compares per capita murder rates with news coverage of murders across the 50 states. The ALNC is about the same size as the Gigaword corpus and is growing continuously. Version 1.0 is available for research use.
</div>
<div id="bib/american-local-news-corpus" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{Irvine-EtAl-2014:LREC,
  author =  {Ann Irvine and Joshua Langfus and Chris Callison-Burch},
  title =   {The {American} Local News Corpus},
  booktitle = {The 9th edition of the Language Resources and Evaluation Conference},
  month     = {May},
  year      = {2014},
  address   = {Reykjavik, Iceland},
  pages     = {},
  publisher = {European Language Resources Association},
  url = {http://cis.upenn.edu/~ccb/publications/american-local-news-corpus.pdf}
}
</pre>
</font>
</div>
</P>


<a name="arabic-dialect-corpus-2" />
<P><a href="publications/arabic-dialect-corpus-2.pdf">A Multi-Dialect, Multi-Genre Corpus of Informal Written Arabic</a>. Ryan Cotterell and Chris Callison-Burch. In LREC-2014.
<a href="javascript:unhide('abstract/arabic-dialect-corpus-2')">[abstract]</a>
<a href="javascript:unhide('bib/arabic-dialect-corpus-2')">[bib]</a>
<div id="abstract/arabic-dialect-corpus-2" class="hidden-abstract">
This paper presents a multi-dialect, multi-genre, human annotated corpus of dialectal Arabic with data obtained from both online newspaper commentary and Twitter. Most Arabic corpora are small and focus on Modern Standard Arabic (MSA). There has been recent interest, however, in the construction of dialectal Arabic corpora. This work differs from previously constructed corpora in two ways. First, we include coverage of five dialects of Arabic: Egyptian, Gulf, Levantine, Maghrebi and Iraqi. This is the most complete coverage of any dialectal corpus known to the authors. In addition to data, we provide results for the Arabic dialect identification task that outperform those reported in Zaidan and Callison-Burch (2011).
</div>
<div id="bib/arabic-dialect-corpus-2" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{Cotterell-Callison-Burch-2014:LREC,
  author =  {Ryan Cotterell and Chris Callison-Burch},
  title =   {A Multi-Dialect, Multi-Genre Corpus of Informal Written {Arabic}},
  booktitle = {The 9th edition of the Language Resources and Evaluation Conference},
  month     = {May},
  year      = {2014},
  address   = {Reykjavik, Iceland},
  pages     = {},
  publisher = {European Language Resources Association},
  url = {http://cis.upenn.edu/~ccb/publications/arabic-dialect-corpus-2.pdf}
}
</pre>
</font>
</div>
</P>

<a name="arabic-french-codeswitching" />
<P><a href="publications/arabic-french-codeswitching.pdf">An Algerian Arabic-French Code-Switched Corpus</a>. Ryan Cotterell, Adithya Renduchintala, Naomi Saphra, and Chris Callison-Burch. In LREC-2014 Workshop on Free/Open-Source Arabic Corpora and Corpora Processing Tools.
<a href="javascript:unhide('abstract/arabic-french-codeswitching')">[abstract]</a>
<a href="javascript:unhide('bib/arabic-french-codeswitching')">[bib]</a>
<div id="abstract/arabic-french-codeswitching" class="hidden-abstract">

Arabic is not just one language, but rather a collection of dialects in addition to Modern Standard Arabic (MSA). While MSA is used in formal situations, dialects are the language of every day life. Until recently, there was very little dialectal Arabic in written form. With the advent of social-media, however, the landscape has changed. We provide the first romanized code-switched Algerian Arabic-French corpus annotated for word-level language id. We review the history and sociological factors that make the linguistic situation in Algerian unique and highlight the value of this corpus to the natural language processing and linguistics communities. To build this corpus, we crawled an Algerian newspaper and extracted the comments from the news story. We discuss the informal nature of the language in the corpus and the challenges it will present. Additionally, we provide a preliminary analysis of the corpus. We then discuss some potential uses of our corpus of interest to the computational linguistics community.
</div>
<div id="bib/arabic-french-codeswitching" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{Cotterell-EtAl-2014:LREC-WS,
  author =  {Ryan Cotterell and Adithya Renduchintala and Naomi Saphra and Chris Callison-Burch},
  title =   {An {Algerian Arabic-French} Code-Switched Corpus},
  booktitle = {Workshop on Free/Open-Source Arabic Corpora and Corpora Processing Tools},
  month     = {May},
  year      = {2014},
  address   = {Reykjavik, Iceland},
  pages     = {},
  publisher = {European Language Resources Association},
  url = {http://cis.upenn.edu/~ccb/publications/arabic-french-codeswitching.pdf}
}
</pre>
</font>
</div>
</P>



<h3>2013</h3>

<p>
<a href="publications/letter-to-the-president.pdf">Open letter to President Obama</a>. Chris Callison-Burch.  In Unpublished-2013. </p>
<div id="abstract/letter-to-the-president" class="hidden-abstract">
I wrote an open letter to President Obama about my former PhD student, Omar Zaidan, who had his student visa revoked on the eve of his PhD defense, and who has not been allowed to return to the US in 1.5 years.  The letter was read by over 35,000 people in the first week after I published it.
</div>


<a name="improved-speech-to-speech-translation" />
<P><a href="publications/improved-speech-to-speech-translation.pdf">Improved Speech-to-Text Translation with the Fisher and Callhome Spanish–English Speech Translation Corpus</a>. Matt Post, Gaurav Kumar, Adam Lopez, Damianos Karakos, Chris Callison-Burch and Sanjeev Khudanpur.  In IWSLT-2013.
<a href="javascript:unhide('abstract/improved-speech-to-speech-translation')">[abstract]</a>
<a href="javascript:unhide('bib/improved-speech-to-speech-translation')">[bib]</a>
<div id="abstract/improved-speech-to-speech-translation" class="hidden-abstract">
Research into the translation of the output of automatic speech recognition (ASR) systems is hindered by the dearth of datasets developed for that explicit purpose. For Spanish-English translation, in particular, most parallel data available exists only in vastly different domains and registers. In order to support research on cross-lingual speech applications, we introduce the Fisher and Callhome Spanish-English Speech Translation Corpus, supplementing existing LDC audio and transcripts with (a) ASR 1-best, lattice, and oracle output produced by the Kaldi recognition system and (b) English translations obtained on Amazon’s Mechanical Turk. The result is a four-way parallel dataset of Spanish audio, transcriptions, ASR lattices, and English translations of approximately 38 hours of speech, with defined training, development, and held-out test sets.
We conduct baseline machine translation experiments using models trained on the provided training data, and validate the dataset by corroborating a number of known results in the field, including the utility of in-domain (information, conversational) training data, increased performance translating lattices (instead of recognizer 1-best output), and the relationship between word error rate and BLEU score.
</div>
<div id="bib/improved-speech-to-speech-translation" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{post-EtAl:2013:IWSLT,
  author    = {Matt Post and Gaurav Kumar and Adam Lopez and Damianos Karakos and Chris Callison-Burch and Sanjeev Khudanpur},
  title     = {Improved Speech-to-Text Translation with the Fisher and Callhome Spanish–English Speech Translation Corpus},
  booktitle = {Proceedings of the International Workshop on Spoken Language Translation (IWSLT)}
  month     = {December},
  year      = {2013},
  address   = {Heidelberg, Germany},
  publisher = {Association for Computational Linguistics},
  url = {http://cis.upenn.edu/~ccb/publications/improved-speech-to-speech-translation.pdf}
}
</pre>
</font>
</div>
</P>


<a name="semi-markov-phrase-based-monolingual-alignment" />
<P><a href="publications/semi-markov-phrase-based-monolingual-alignment.pdf">Semi-Markov Phrase-based Monolingual Alignment</a>. Xuchen Yao, Ben Van Durme, Chris Callison-Burch and Peter Clark.  In EMNLP-2013.
<a href="javascript:unhide('abstract/semi-markov-phrase-based-monolingual-alignment')">[abstract]</a>
<a href="javascript:unhide('bib/semi-markov-phrase-based-monolingual-alignment')">[bib]</a>
<div id="abstract/semi-markov-phrase-based-monolingual-alignment" class="hidden-abstract">
We introduce a novel discriminative model for phrase-based monolingual alignment using a semi-Markov CRF. Our model achieves state-of-the-art alignment accuracy on two phrase=based alignment datasets (RTE and paraphrase), while doing significantly better than other strong baselines in both non-identical alignment and phrase-only alignment. Additional experiments highlight the potential benefit of our alignment model to RTE, paraphrase identification and question answering, where even a naive application of our model’s alignment score approaches the state of the art.
</div>
<div id="bib/semi-markov-phrase-based-monolingual-alignment" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{yao-EtAl:2013:EMNLP,
  author    = {Xuchen Yao and Benjamin {Van Durme} and Chris Callison-Burch and Peter Clark},
  title     = {Semi-Markov Phrase-based Monolingual Alignment},
  booktitle = {Proceedings of EMNLP}
  month     = {October},
  year      = {2013},
  address   = {Seattle, Washington},
  publisher = {Association for Computational Linguistics},
  url = {http://cis.upenn.edu/~ccb/publications/semi-markov-phrase-based-monolingual-alignment.pdf}
}
</pre>
</font>
</div>
</P>



<a name="findings-of-the-wmt13-shared-tasks" />
<P><a href="publications/findings-of-the-wmt13-shared-tasks.pdf">Findings of the 2013 Workshop on Statistical Machine Translation</a>. Ondrej Bojar, Christian Buck, Chris Callison-Burch, Christian Federmann, Barry Haddow, Philipp Koehn, Christof Monz, Matt Post, Radu Soricut, and Lucia Specia.  In WMT13.
<a href="javascript:unhide('abstract/findings-of-the-wmt13-shared-tasks')">[abstract]</a>
<a href="javascript:unhide('bib/findings-of-the-wmt13-shared-tasks')">[bib]</a>
<div id="abstract/findings-of-the-wmt13-shared-tasks" class="hidden-abstract">
We present the results of the WMT13 shared tasks, which included a translation task, a task for run-time estimation of machine translation quality, and an unofficial metrics task. This year, 143 machine translation systems were submitted to the ten translation tasks from 23 institutions. An additional 6 anonymized systems were included, and were then evaluated both automatically and manually, in our largest manual evaluation to date. The quality estimation task had four subtasks, with a total of 14 teams, submitting 55 entries.
</div>
<div id="bib/findings-of-the-wmt13-shared-tasks" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{bojar-EtAl:2013:WMT,
  author    = {Bojar, Ond\v{r}ej  and  Buck, Christian  and  Callison-Burch, Chris  and  Federmann, Christian  and  Haddow, Barry  and  Koehn, Philipp  and  Monz, Christof  and  Post, Matt  and  Soricut, Radu  and  Specia, Lucia},
  title     = {Findings of the 2013 {Workshop on Statistical Machine Translation}},
  booktitle = {Proceedings of the Eighth Workshop on Statistical Machine Translation},
  month     = {August},
  year      = {2013},
  address   = {Sofia, Bulgaria},
  publisher = {Association for Computational Linguistics},
  pages     = {1--44},
  url       = {http://www.aclweb.org/anthology/W13-2201}
}
</pre>
</font>
</div>
</P>


<a name="joshua-5.0" />
<P><a href="publications/joshua-5.0.pdf">Joshua 5.0: Sparser, better, faster, server</a>. Matt Post, Juri Ganitkevitch, Luke Orland, Jonathan Weese, Yuan Cao, and Chris Callison-Burch, 2013.  In Proceedings of WMT13.
<a href="javascript:unhide('abstract/joshua-5.0')">[abstract]</a>
<a href="javascript:unhide('bib/joshua-5.0')">[bib]</a>
<div id="abstract/joshua-5.0" class="hidden-abstract">
We describe improvements made over the past year to Joshua, an open-source translation system for parsing-based machine translation. The main contributions this past year are significant improvements in both speed and usability of the grammar extraction and decoding steps. We have also rewritten the decoder to use a sparse feature representation, enabling training of large numbers of features with discriminative training methods.
</div>
<div id="bib/joshua-5.0" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{post-EtAl:2013:WMT,
  author    = {Post, Matt  and  Ganitkevitch, Juri  and  Orland, Luke  and  Weese, Jonathan  and  Cao, Yuan  and  Callison-Burch, Chris},
  title     = {Joshua 5.0: Sparser, Better, Faster, Server},
  booktitle = {Proceedings of the Eighth Workshop on Statistical Machine Translation},
  month     = {August},
  year      = {2013},
  address   = {Sofia, Bulgaria},
  publisher = {Association for Computational Linguistics},
  pages     = {206--212},
  url       = {http://www.aclweb.org/anthology/W13-2226}
}
</pre>
</font>
</div>
</P>



<a name="combining-bilingual-and-comparable-corpora" />
<P><a href="publications/combining-bilingual-and-comparable-corpora.pdf">Combining Bilingual and Comparable Corpora for Low Resource Machine Translation</a>. Ann Irvine and Chris Callison-Burch, 2013.  In Proceedings of WMT13.
<a href="javascript:unhide('abstract/combining-bilingual-and-comparable-corpora')">[abstract]</a>
<a href="javascript:unhide('bib/combining-bilingual-and-comparable-corpora')">[bib]</a>
<div id="abstract/combining-bilingual-and-comparable-corpora" class="hidden-abstract">
Statistical machine translation (SMT) performance suffers when models are trained on only small amounts of parallel data. The learned models typically have both low accuracy (incorrect translations and feature scores) and low coverage (high out-of-vocabulary rates). In this work, we use an additional data resource, comparable corpora, to improve both. Beginning with a small bitext and corresponding phrase-based SMT model, we improve coverage by using bilingual lexicon induction techniques to learn new translations from comparable corpora. Then, we supplement the model’s feature space with translation scores estimated over comparable corpora in order to improve accuracy. We observe improvements between 0.5 and 1.7 BLEU translating Tamil, Telugu, Bengali, Malayalam, Hindi, and Urdu into English.
</div>
<div id="bib/combining-bilingual-and-comparable-corpora" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{irvine-callisonburch:2013:WMT,
  author    = {Irvine, Ann  and  Callison-Burch, Chris},
  title     = {Combining Bilingual and Comparable Corpora for Low Resource Machine Translation},
  booktitle = {Proceedings of the Eighth Workshop on Statistical Machine Translation},
  month     = {August},
  year      = {2013},
  address   = {Sofia, Bulgaria},
  publisher = {Association for Computational Linguistics},
  pages     = {262--270},
  url       = {http://www.aclweb.org/anthology/W13-2233}
}
</pre>
</font>
</div>
</P>




<a name="monolingual-word-aligner" />
<P><a href="publications/monolingual-word-aligner.pdf">A Lightweight and High Performance Monolingual Word Aligner</a>. Xuchen Yao, Peter Clark, Ben Van Durme and Chris Callison-Burch.  In ACL-2013.
<a href="javascript:unhide('abstract/monolingual-word-aligner')">[abstract]</a>
<a href="javascript:unhide('bib/monolingual-word-aligner')">[bib]</a>
<div id="abstract/monolingual-word-aligner" class="hidden-abstract">
Fast alignment is essential for many natural language tasks. But in the setting of monolingual alignment, previous work has not been able to align more than one sentence pair per second. We describe a discriminatively trained monolingual word aligner that uses a Conditional Random Field to globally decode the best alignment with features drawn from source and target sentences. Using just part-of-speech tags and WordNet as external resources, our aligner gives state-of-the-art result, while being an order-of-magnitude faster than the previous best performing system.
</div>
<div id="bib/monolingual-word-aligner" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{yao-EtAl:2013:ACL,
  author    = {Xuchen Yao and Peter Clark and Benjamin {Van Durme} and Chris Callison-Burch},
  title     = {A Lightweight and High Performance Monolingual Word Aligner},
  booktitle = {Proceedings of the 2013 Conference of the Association for Computational Linguistics (ACL 2013)},
  month     = {July},
  year      = {2013},
  address   = {Sofia, Bulgaria},
  publisher = {Association for Computational Linguistics},
  url = {http://cis.upenn.edu/~ccb/publications/monolingual-word-aligner.pdf}
}
</pre>
</font>
</div>
</P>


<a name="parma" />
<P><a href="publications/parma.pdf">PARMA: A Predicate Argument Aligner</a>. Travis Wolfe, Benjamin Van Durme, Mark Dredze, Nicholas Andrews, Charley Beller, Chris Callison-Burch, Jay DeYoung, Justin Snyder, Jonathan Weese, Tan Xu and Xuchen Yao.  In ACL-2013.
<a href="javascript:unhide('abstract/parma')">[abstract]</a>
<a href="javascript:unhide('bib/parma')">[bib]</a>
<div id="abstract/parma" class="hidden-abstract">
We introduce PARMA, a system for crossdocument, semantic predicate and argument alignment. Our system combines a number of linguistic resources familiar to researchers in areas such as recognizing textual entailment and question answering, integrating them into a simple discriminative model. PARMA achieves state of the art results on an existing and a new dataset. We suggest that previous efforts have focussed on data that is biased and too easy, and we provide a more difficult dataset based on translation data which has a low baseline which we beat by 17% F1.
</div>
<div id="bib/parma" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{wolfe-EtAl:2013:ACL,
  author    = {Travis Wolfe and Benjamin {Van Durme} and Mark Dredze and Nicholas Andrews and Charley Beller and Chris Callison-Burch and Jay DeYoung and Justin Snyder and Jonathan Weese and Tan Xu and Xuchen Yao},
  title     = {{PARMA}: A Predicate Argument Aligner},
  booktitle = {Proceedings of the 2013 Conference of the Association for Computational Linguistics (ACL 2013)},
  month     = {July},
  year      = {2013},
  address   = {Sofia, Bulgaria},
  publisher = {Association for Computational Linguistics},
  url = {http://cis.upenn.edu/~ccb/publications/parma.pdf}
}
</pre>
</font>
</div>
</P>


<a name="arabic-dialect-id" />
<P><a href="publications/arabic-dialect-id.pdf">Arabic Dialect Identification</a>. Omar Zaidan and Chris Callison-Burch.  In Computational Linguistics.
<a href="javascript:unhide('abstract/arabic-dialect-id')">[abstract]</a>
<a href="javascript:unhide('bib/arabic-dialect-id')">[bib]</a>
<div id="abstract/arabic-dialect-id" class="hidden-abstract">
The written form of the Arabic language, Modern Standard Arabic (MSA), differs in a non-trivial manner from the various spoken regional dialects of Arabic – the true “native languages” of Arabic speakers. Those dialects, in turn, differ quite a bit from each other. However, due to MSA’s prevalence in written form, almost all Arabic datasets have predominantly MSA content. In this article, we describe the creation of a novel Arabic resource with dialect annotations. We have created a large monolingual dataset rich in dialectal Arabic content, called the Arabic Online Commentary Dataset (Zaidan and Callison-Burch 2011). We describe our annotation effort to identify the dialect level (and dialect itself) in each of more than 100,000 sentences from the dataset by crowdsourcing the annotation task, and delve into interesting annotator behaviors (like over-identification of one’s own dialect). Using this new annotated dataset, we consider the task of Arabic dialect identification: given the word sequence forming an Arabic sentence, determine the variety of Arabic in which it is written. We use the data to train and evaluate automatic classifiers for dialect identification, and establish that classifiers using dialectal data significantly and dramatically outperform baselines that use MSA-only data, achieving near-human classification accuracy. Finally, we apply our classifiers to discover dialectical data from a large web crawl consisting of 3.5 million pages mined from online Arabic newspapers.
</div>
<div id="bib/arabic-dialect-id" class="hidden-abstract">
<font size="-2">
<pre>
@article{zaidan-callisonburch:CL:2013,
  author    = {Omar F. Zaidan and Chris Callison-Burch},
  title =   {Arabic Dialect Identification},
  journal = {Computational Linguistics},
  year =    {2013},
  volume = {XXX},
  number = {XXX},
  pages = {XXX}
}
</pre>
</font>
</div>
</P>


<a name="teaching-machine-translation" />
<P><a href="publications/teaching-machine-translation.pdf">Learning to translate with products of novices: a suite of open-ended challenge problems for teaching MT</a>. Adam Lopez, Matt Post, Chris Callison-Burch, Jonathan Weese, Juri Ganitkevitch, Narges Ahmidi, Olivia Buzek, Leah Hanson, Beenish Jamil, Matthias Lee, Ya-Ting Lin, Henry Pao, Fatima Rivera, Leili Shahriyari, Debu Sinha, Adam Teichert, Stephen Wampler, Michael Weinberger, Daguang Xu, Lin Yang, and Shang Zhao. In TACL-2013.
<a href="javascript:unhide('abstract/teaching-machine-translation')">[abstract]</a>
<a href="javascript:unhide('bib/teaching-machine-translation')">[bib]</a>
<div id="abstract/teaching-machine-translation" class="hidden-abstract">
Machine translation (MT) draws from several different disciplines, making it a complex subject to teach. There are excellent pedagogical texts, but problems in MT and current algorithms for solving them are best learned by doing. As a centerpiece of our MT course, we devised a series of open-ended challenges for students in which the goal was to improve performance on carefully constrained instances of four key MT tasks: alignment, decoding, evaluation, and reranking. Students brought a diverse set of techniques to the problems, including some novel solutions which performed remarkably well. A surprising and exciting outcome was that student solutions or their combinations fared competitively on some tasks, demonstrating that even newcomers to the field can help improve the state-of-the-art on hard NLP problems while simultaneously learning a great deal. The problems, baseline code, and results are freely available.
</div>
<div id="bib/teaching-machine-translation" class="hidden-abstract">
<font size="-2">
<pre>
@article{Lopez-etal:TACL:2013,
  author    = {Matt Post and Chris Callison-Burch and Jonathan Weese and Juri Ganitkevitch and Narges Ahmidi and Olivia Buzek and Leah Hanson and Beenish Jamil and Matthias Lee and Ya-Ting Lin and Henry Pao and Fatima Rivera and Leili Shahriyari and Debu Sinha and Adam Teichert and Stephen Wampler and Michael Weinberger and Daguang Xu and Lin Yang and and Shang Zhao},
  title =   {Learning to translate with products of novices: a suite of open-ended challenge problems for teaching {MT}},
  journal = {Transactions of the Association for Computational Linguistics},
  year =    {2013},
  volume = {1},
  number = {May},
  pages = {166--177}
}
</pre>
</font>
</div>
</P>


<a name="bitexts-from-common-crawl" />
<P><a href="publications/bitexts-from-common-crawl.pdf">Dirt Cheap Web-Scale Parallel Text from the Common Crawl</a>. Jason Smith, Herve Saint-Amand, Magdalena Plamada, Philipp Koehn, Chris Callison-Burch and Adam Lopez.  In ACL-2013.
<a href="javascript:unhide('abstract/bitexts-from-common-crawl')">[abstract]</a>
<a href="javascript:unhide('bib/bitexts-from-common-crawl')">[bib]</a>
<div id="abstract/bitexts-from-common-crawl" class="hidden-abstract">
Parallel text is the fuel that drives modern machine translation systems. The Web is a comprehensive source of preexisting parallel text, but crawling the entire web is impossible for all but the largest companies. We bring web-scale parallel text to the masses by mining the Common Crawl, a public Web crawl hosted on Amazon’s Elastic Cloud. Starting from nothing more than a set of common two-letter language codes, our open-source extension of the STRAND algorithm mined 32 terabytes of the crawl in just under a day, at a cost of about $500. Our large-scale experiment uncovers large amounts of parallel text in dozens of language pairs across a variety of domains and genres, some previously unavailable in curated datasets. Even with minimal cleaning and filtering, the resulting data boosts translation performance across the board for five different language pairs in the news domain, and on open domain test sets we see improvements of up to 5 BLEU. We make our code and data available for other researchers seeking to mine this rich new data resource.
</div>
<div id="bib/bitexts-from-common-crawl" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{smith-EtAl:2013:ACL,
  author    = {Jason Smith and Herve Saint-Amand and Magdalena Plamada and Philipp Koehn and Chris Callison-Burch and Adam Lopez},
  title     = {Dirt Cheap Web-Scale Parallel Text from the {Common Crawl}},
  booktitle = {Proceedings of the 2013 Conference of the Association for Computational Linguistics (ACL 2013)},
  month     = {July},
  year      = {2013},
  address   = {Sofia, Bulgaria},
  publisher = {Association for Computational Linguistics},
  url = {http://cis.upenn.edu/~ccb/publications/bitexts-from-common-crawl.pdf}
}
</pre>
</font>
</div>
</P>

<a name="ppdb" />
<P><a href="publications/ppdb.pdf">PPDB: The Paraphrase Database</a>. Juri Ganitkevitch, Benjamin Van Durme, and Chris Callison-Burch.  In NAACL-2013.
<a href="javascript:unhide('abstract/ppdb')">[abstract]</a>
<a href="javascript:unhide('bib/ppdb')">[bib]</a>
<div id="abstract/ppdb" class="hidden-abstract">
We present the 1.0 release of our paraphrase database, PPDB. Its English portion, PPDB:Eng, contains over 220 million paraphrase pairs, consisting of 73 million phrasal and 8 million lexical paraphrases, as well as 140 million paraphrase patterns, which capture many meaning-preserving syntactic transformations. The paraphrases are extracted from bilingual parallel corpora totaling over 100 million sentence pairs and over 2 billion English words. We also release PPDB:Spa, a collection of 196 million Spanish paraphrases. Each paraphrase pair in PPDB contains a set of associated scores, including paraphrase probabilities derived from the bitext data and a variety of monolingual distributional similarity scores computed from the Google n-grams and the Annotated Gigaword corpus. Our release includes pruning tools that allow users to determine their own precision/recall tradeoff.
</div>
<div id="bib/ppdb" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{ganitkevitch-EtAl:2013:NAACL,
  author    = {Juri Ganitkevitch and Benjamin VanDurme and Chris Callison-Burch},
  title     = {{PPDB}: The Paraphrase Database},
  booktitle = {Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL 2013)},
  month     = {June},
  year      = {2013},
  address   = {Atlanta, Georgia},
  publisher = {Association for Computational Linguistics},
  url = {http://cis.upenn.edu/~ccb/publications/ppdb.pdf}
}
</pre>
</font>
</div>
</P>


<a name="supervised-bilingual-lexicon-induction" />
<P><a href="publications/supervised-bilingual-lexicon-induction.pdf">Supervised Bilingual Lexicon Induction with Multiple Monolingual Signals</a>. Ann Irvine and Chris Callison-Burch.  In NAACL-2013.
<a href="javascript:unhide('abstract/supervised-bilingual-lexicon-induction')">[abstract]</a>
<a href="javascript:unhide('bib/supervised-bilingual-lexicon-induction')">[bib]</a>
<div id="abstract/supervised-bilingual-lexicon-induction" class="hidden-abstract">
Prior research into learning translations from source and target language monolingual texts has treated the task as an unsupervised learning problem. Although many techniques take advantage of a seed bilingual lexicon, this work is the first to use that data for supervised learning to combine a diverse set of signals derived from a pair of monolingual corpora into a single discriminative model. Even in a low resource machine translation setting, where induced translations have the potential to improve performance substantially, it is reasonable to assume access to some amount of data to perform this kind of optimization. Our work shows that only a few hundred translation pairs are needed to achieve strong performance on the bilingual lexicon induction task, and our approach yields an average relative gain in accuracy of nearly 50% over an unsupervised baseline. Large gains in accuracy hold for all 22 languages (low and high resource) that we investigate.
</div>
<div id="bib/supervised-bilingual-lexicon-induction" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{irvine-callisonburch:2013:NAACL,
  author    = {Ann Irvine and Chris Callison-Burch},
  title     = {Supervised Bilingual Lexicon Induction with Multiple Monolingual Signals},
  booktitle = {Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL 2013)},
  month     = {June},
  year      = {2013},
  address   = {Atlanta, Georgia},
  publisher = {Association for Computational Linguistics},
  url = {http://cis.upenn.edu/~ccb/publications/supervised-bilingual-lexicon-induction.pdf}
}
</pre>
</font>
</div>
</P>



<a name="answer-extraction-as-sequence-tagging" />
<P><a href="publications/answer-extraction-as-sequence-tagging.pdf">Answer Extraction as Sequence Tagging with Tree Edit Distance</a>. Xuchen Yao, Benjamin Van Durme, Chris Callison-Burch and Peter Clark.  In NAACL-2013.
<a href="javascript:unhide('abstract/answer-extraction-as-sequence-tagging')">[abstract]</a>
<a href="javascript:unhide('bib/answer-extraction-as-sequence-tagging')">[bib]</a>
<div id="abstract/answer-extraction-as-sequence-tagging" class="hidden-abstract">
Our goal is to extract answers from pre-retrieved sentences for Question Answering (QA). We construct a linear-chain Conditional Random Field based on pairs of questions and their possible answer sentences, learning the association between questions and answer types. This casts answer extraction as an answer sequence tagging problem for the first time, where knowledge of shared structure between question and source sentence is incorporated through features based on Tree Edit Distance (TED). Our model is free of manually created question and answer templates, fast to run (processing 200 QA pairs per second excluding parsing time), and yields an F1 of 63.3% on a new public dataset based on prior TREC QA evaluations. The developed system is open-source, and includes an implementation of the TED model that is state of the art in the task of ranking QA pairs.
</div>
<div id="bib/answer-extraction-as-sequence-tagging" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{yao-EtAl:2013:NAACL,
  author    = {Xuchen Yao and Benjamin {Van Durme} and Chris Callison-Burch and Peter Clark},
  title     = {Answer Extraction as Sequence Tagging with Tree Edit Distance},
  booktitle = {Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL 2013)},
  month     = {June},
  year      = {2013},
  address   = {Atlanta, Georgia},
  publisher = {Association for Computational Linguistics},
  url = {http://cis.upenn.edu/~ccb/publications/answer-extraction-as-sequence-tagging.pdf}
}
</pre>
</font>
</div>
</P>




<h3>2012</h3>


<a name="findings-of-the-wmt12-shared-tasks" />
<P><a href="publications/findings-of-the-wmt12-shared-tasks.pdf">Findings of the 2012 Workshop on Statistical Machine Translation</a>. Chris Callison-Burch, Philipp Koehn, Christof  Monz, Matt Post, Radu Soricut, and Lucia Specia.  In WMT12.
<a href="javascript:unhide('abstract/findings-of-the-wmt12-shared-tasks')">[abstract]</a>
<a href="javascript:unhide('bib/findings-of-the-wmt12-shared-tasks')">[bib]</a>
<div id="abstract/findings-of-the-wmt12-shared-tasks" class="hidden-abstract">
This paper presents the results of the WMT12 shared tasks, which included a translation task, a task for machine translation evaluation metrics, and a task for run-time estimation of machine translation quality. We conducted a large-scale manual evaluation of 103 machine translation systems submitted by 34 teams. We used the ranking of these systems to measure how strongly automatic metrics correlate with human judgments of translation quality for 12 evaluation metrics. We introduced a new quality estimation task this year, and evaluated submissions from 11 teams.
</div>
<div id="bib/findings-of-the-wmt12-shared-tasks" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{callisonburch-EtAl:2012:WMT,
  author    = {Callison-Burch, Chris  and  Koehn, Philipp  and  Monz, Christof  and  Post, Matt  and  Soricut, Radu  and  Specia, Lucia},
  title     = {Findings of the 2012 Workshop on Statistical Machine Translation},
  booktitle = {Proceedings of the Seventh Workshop on Statistical Machine Translation},
  month     = {June},
  year      = {2012},
  address   = {Montr{\'e}al, Canada},
  publisher = {Association for Computational Linguistics},
  pages     = {10--51},
  url = {http://cis.upenn.edu/~ccb/publications/findings-of-the-wmt12-shared-tasks.pdf}
}
</pre>
</font>
</div>
</P>


<a name="constructing-parallel-corpora-for-six-indian-languages-via-crowdsourcing" />
<P><a href="publications/constructing-parallel-corpora-for-six-indian-languages-via-crowdsourcing.pdf">Constructing Parallel Corpora for Six Indian Languages via Crowdsourcing</a>.  Matt Post, Chris Callison-Burch, and Miles Osborne, 2012.  In Proceedings of WMT12.
<a href="javascript:unhide('abstract/constructing-parallel-corpora-for-six-indian-languages-via-crowdsourcing')">[abstract]</a>
<a href="javascript:unhide('bib/constructing-parallel-corpora-for-six-indian-languages-via-crowdsourcing')">[bib]</a>
<div id="abstract/constructing-parallel-corpora-for-six-indian-languages-via-crowdsourcing" class="hidden-abstract">
Recent work has established the efficacy of Amazon's Mechanical Turk for constructing parallel corpora for machine translation research. We apply this to building a collection of parallel corpora between English and six languages from the Indian subcontinent: Bengali, Hindi, Malayalam, Tamil, Telugu, and Urdu. These languages are low-resource, under-studied, and exhibit linguistic phenomena that are difficult for machine translation. We conduct a variety of baseline experiments and analysis, and release the data to the community.
</div>
<div id="bib/constructing-parallel-corpora-for-six-indian-languages-via-crowdsourcing" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{post-callisonburch-osborne:2012:WMT,
  author    = {Post, Matt  and  Callison-Burch, Chris  and  Osborne, Miles},
  title     = {Constructing Parallel Corpora for Six Indian Languages via Crowdsourcing},
  booktitle = {Proceedings of the Seventh Workshop on Statistical Machine Translation},
  month     = {June},
  year      = {2012},
  address   = {Montr{\'e}al, Canada},
  publisher = {Association for Computational Linguistics},
  pages     = {401--409},
  url       = {http://www.aclweb.org/anthology/W12-3152}
}
</pre>
</font>
</div>
</P>


<a name="using-categorial-grammar-to-label-translation-rules" />
<P><a href="publications/using-categorial-grammar-to-label-translation-rules.pdf">Using Categorial Grammar to Label Translation Rules</a>.  Jonathan Weese, Chris Callison-Burch, and Adam Lopez, 2012.  In Proceedings of WMT12.
<a href="javascript:unhide('abstract/using-categorial-grammar-to-label-translation-rules')">[abstract]</a>
<a href="javascript:unhide('bib/using-categorial-grammar-to-label-translation-rules')">[bib]</a>
<div id="abstract/using-categorial-grammar-to-label-translation-rules" class="hidden-abstract">
Adding syntactic labels to synchronous context-free translation rules can improve performance, but labeling with phrase structure constituents, as in GHKM (Galley et al., 2004), excludes potentially useful translation rules. SAMT (Zollmann and Venugopal, 2006) introduces heuristics to create new non-constituent labels, but these heuristics introduce many complex labels and tend to add rarely-applicable rules to the translation grammar. We introduce a labeling scheme based on categorial grammar, which allows syntactic labeling of many rules with a minimal, well-motivated label set. We show that our labeling scheme performs comparably to SAMT on an Urdu–English translation task, yet the label set is an order of magnitude smaller, and translation is twice as fast.
</div>
<div id="bib/using-categorial-grammar-to-label-translation-rules" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{weese-callisonburch-lopez:2012:WMT,
  author    = {Weese, Jonathan  and  Callison-Burch, Chris  and  Lopez, Adam},
  title     = {Using Categorial Grammar to Label Translation Rules},
  booktitle = {Proceedings of the Seventh Workshop on Statistical Machine Translation},
  month     = {June},
  year      = {2012},
  address   = {Montr{\'e}al, Canada},
  publisher = {Association for Computational Linguistics},
  pages     = {222--231},
  url = {http://cis.upenn.edu/~ccb/publications/using-categorial-grammar-to-label-translation-rules.pdf}
}
</pre>
</font>
</div>
</P>


<a name="joshua-4.0" />
<P><a href="publications/joshua-4.0.pdf">Joshua 4.0: Packing, PRO, and Paraphrases</a>. Juri Ganitkevitch, Yuan Cao, Jonathan Weese, Matt Post, and Chris Callison-Burch, 2012.  In Proceedings of WMT12.
<a href="javascript:unhide('abstract/joshua-4.0')">[abstract]</a>
<a href="javascript:unhide('bib/joshua-4.0')">[bib]</a>
<div id="abstract/joshua-4.0" class="hidden-abstract">
We present Joshua 4.0, the newest version of our open-source decoder for parsing-based statistical machine translation. The main contributions in this release are the introduction of a compact grammar representation based on packed tries, and the integration of our implementation of pairwise ranking optimization, J-PRO. We further present the extension of the Thrax SCFG grammar extractor to pivot-based extraction of syntactically informed sentential paraphrases.
</div>
<div id="bib/joshua-4.0" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{ganitkevitch-EtAl:2012:WMT,
  author    = {Ganitkevitch, Juri  and  Cao, Yuan  and  Weese, Jonathan  and  Post, Matt  and  Callison-Burch, Chris},
  title     = {Joshua 4.0: Packing, PRO, and Paraphrases},
  booktitle = {Proceedings of the Seventh Workshop on Statistical Machine Translation},
  month     = {June},
  year      = {2012},
  address   = {Montr{\'e}al, Canada},
  publisher = {Association for Computational Linguistics},
  pages     = {283--291},
  url = {http://cis.upenn.edu/~ccb/publications/joshua-4.0.pdf}
}
</pre>
</font>
</div>
</P>



<a name="expectations-of-word-sense-in-parallel-corpora" />
<P><a href="publications/expectations-of-word-sense-in-parallel-corpora.pdf">Expectations of Word Sense in Parallel Corpora</a>. Xuchen Yao, Benjamin Van Durme and Chris Callison-Burch, 2012.  In NAACL.
<a href="javascript:unhide('abstract/expectations-of-word-sense-in-parallel-corpora')">[abstract]</a>
<a href="javascript:unhide('bib/expectations-of-word-sense-in-parallel-corpora')">[bib]</a>
<div id="abstract/expectations-of-word-sense-in-parallel-corpora" class="hidden-abstract">
Given a parallel corpus, if two distinct words in language A, a and a2, are aligned to the same word b in language B, then this might signal that b  is polysemous, or it might signal a and a2 are synonyms. Both assumptions with successful work have been put forward in the literature. We investigate these assumptions, along with other questions of word sense, by looking at sampled parallel sentences containing tokens of the same type in English, asking how often they mean the same thing when they are: 1. aligned to the same foreign type; and 2. aligned to different foreign types. Results for French-English and Chinese-English parallel corpora show similar behavior: Synonymy is only very weakly the more prevalent scenario, where both cases regularly occur.
</div>
<div id="bib/expectations-of-word-sense-in-parallel-corpora" class="hidden-abstract">
<font size="-2"> 
<pre>
@InProceedings{yao-vandurme-callisonburch:2012:NAACL-HLT,
  author    = {Yao, Xuchen, {Van Durme}, Benjamin and Callison-Burch, Chris},
  title     = {Expectations of Word Sense in Parallel Corpora},
  booktitle = {The 2012 Conference of the North American Chapter of the Association for Computational Linguistics},
  month     = {June},
  year      = {2012},
  address   = {Montr{\'e}al, Canada},
  publisher = {Association for Computational Linguistics},
  pages     = {621--625},
  url       = {http://www.aclweb.org/anthology/N12-1078}
}

</pre>
</font>
</div>
</P>



<a name="pakistani-SMS-corpus" />
<P><a href="publications/pakistani-SMS-corpus.pdf">Processing Informal, Romanized Pakistani Text Messages</a>. Ann Irvine, Jonathan Weese, and Chris Callison-Burch, 2012.  In Proceedings of the NAACL Workshop on Language in Social Media.
<a href="javascript:unhide('abstract/pakistani-SMS-corpus')">[abstract]</a>
<a href="javascript:unhide('bib/pakistani-SMS-corpus')">[bib]</a>
<div id="abstract/pakistani-SMS-corpus" class="hidden-abstract">
Regardless of language, the standard character set for text messages (SMS) and many other social media platforms is the Roman alphabet. There are romanization conventions for some character sets, but they are used inconsistently in informal text, such as SMS. In this work, we convert informal, romanized Urdu messages into the native Arabic script and normalize non-standard SMS language. Doing so prepares the messages for existing downstream processing tools, such as machine translation, which are typically trained on well-formed, native script text. Our model combines information at the word and character levels, allowing it to handle out-of-vocabulary items. Compared with a baseline deterministic approach, our system reduces both word and character error rate by over 50%.
</div>
<div id="bib/pakistani-SMS-corpus" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{irvine-weese-callisonburch:2012:LSM,
  author    = {Irvine, Ann  and  Weese, Jonathan  and  Callison-Burch, Chris},
  title     = {Processing Informal, Romanized Pakistani Text Messages},
  booktitle = {Proceedings of the Second Workshop on Language in Social Media},
  month     = {June},
  year      = {2012},
  address   = {Montr{\'e}al, Canada},
  publisher = {Association for Computational Linguistics},
  pages     = {75--78},
  url       = {http://www.aclweb.org/anthology/W12-2109}
}
</pre>
</font>
</div>
</P>




<a name="monolingual-distributional-similarity-for-text-to-text-generation" />
<P><a href="publications/monolingual-distributional-similarity-for-text-to-text-generation.pdf">Monolingual Distributional Similarity for Text-to-Text Generation</a>. Juri Ganitkevitch, Benjamin Van Durme, and Chris Callison-Burch, 2012.  In Proceedings of STARSEM 2012.
<a href="javascript:unhide('abstract/monolingual-distributional-similarity-for-text-to-text-generation')">[abstract]</a>
<a href="javascript:unhide('bib/monolingual-distributional-similarity-for-text-to-text-generation')">[bib]</a>
<div id="abstract/monolingual-distributional-similarity-for-text-to-text-generation" class="hidden-abstract">
Previous work on paraphrase extraction and application has relied on either parallel datasets, or on distributional similarity metrics over large text corpora. Our approach combines these two orthogonal sources of information and directly integrates them into our paraphrasing system’s log-linear model. We compare different distributional similarity feature-sets and show significant improvements in grammaticality and meaning retention on the example text-to-text generation task of sentence compression, achieving state-of-the-art quality.
</div>
<div id="bib/monolingual-distributional-similarity-for-text-to-text-generation" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{Ganitkevitch-etal:2012:StarSEM,
  author =  {Juri Ganitkevitch and Benjamin {Van Durme} and Chris Callison-Burch},
  title     = {Monolingual Distributional Similarity for Text-to-Text Generation},
  booktitle = {*SEM First Joint Conference on Lexical and Computational Semantics},
  month     = {June},
  year      = {2012},
  address   = {Montreal},
  publisher = {Association for Computational Linguistics},
  url = {http://cis.upenn.edu/~ccb/publications/monolingual-distributional-similarity-for-text-to-text-generation.pdf}
}
</pre>
</font>
</div>
</P>


<P><a href="publications/machine-translation-of-arabic-dialects.pdf">Machine Translation of Arabic Dialects</a>. Rabih Zbib, Erika Malchiodi, Jacob Devlin, David Stallard, Spyros Matsoukas, Richard Schwartz, John Makhoul, Omar F. Zaidan and Chris Callison-Burch, 2012.  In Proceedings of NAACL 2012.
<a href="javascript:unhide('abstract/machine-translation-of-arabic-dialects')">[abstract]</a>
<a href="javascript:unhide('bib/machine-translation-of-arabic-dialects')">[bib]</a>
<div id="abstract/machine-translation-of-arabic-dialects" class="hidden-abstract">
Arabic dialects present many challenges for machine translation, not least of which is the lack of data resources. We use crowdsourcing to cheaply and quickly build Levantine-English and  Egyptian-English  parallel corpora, consisting of 1.1M words and 380k words, respectively.  The dialect sentences are selected from a large corpus of Arabic web text, and translated using Mechanical Turk. We use this  data to build Dialect Arabic MT systems.  Small amounts of dialect data have a dramatic impact on the quality of translation.  When translating Egyptian and Levantine test sets, our Dialect Arabic MT system performs 5.8 and 6.8 BLEU points higher than a Modern Standard Arabic MT system trained on a 150 million word Arabic-English parallel corpus -- over 100 times the amount of data as our dialect corpora.   
</div>
<div id="bib/machine-translation-of-arabic-dialects" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{Zbib-etal:2012:NAACL,
  author =  {Rabih Zbib and Erika Malchiodi and Jacob Devlin and David Stallard and Spyros Matsoukas and Richard Schwartz and John Makhoul and Omar F. Zaidan and Chris Callison-Burch},
  title     = {Machine Translation of Arabic Dialects},
  booktitle = {The 2012 Conference of the North American Chapter of the Association for Computational Linguistics},
  month     = {June},
  year      = {2012},
  address   = {Montreal},
  publisher = {Association for Computational Linguistics},
  url = {http://cis.upenn.edu/~ccb/publications/machine-translation-of-arabic-dialects.pdf}
}
</pre>
</font>
</div>
</P>


<P><a href="publications/toward-statistical-machine-translation-without-parallel-corpora.pdf">Toward Statistical Machine Translation without Parallel Corpora</a>. Alex Klementiev, Ann Irvine, Chris Callison-Burch, and David Yarowsky, 2012.  In Proceedings of EACL 2012.
<a href="javascript:unhide('abstract/toward-statistical-machine-translation-without-parallel-corpora')">[abstract]</a>
<a href="javascript:unhide('bib/toward-statistical-machine-translation-without-parallel-corpora')">[bib]</a>
<div id="abstract/toward-statistical-machine-translation-without-parallel-corpora" class="hidden-abstract">
We estimate the parameters of a phrase-based statistical machine translation system from 
monolingual corpora instead of a bilingual parallel corpus. We extend existing research on bilingual lexicon induction to estimate both lexical and phrasal translation probabilities for MT-scale phrase-tables. We propose a novel algorithm to estimate re-ordering probabilities from monolingual data. We report translation results for an end-to-end translation system using these monolingual features alone. Our method only requires monolingual corpora in source and target languages, a small bilingual dictionary, and a small bitext for tuning feature weights. In this paper, we examine an idealization where a phrase-table is given. We examine the degradation in translation performance when bilingually estimated translation probabilities are removed, and show that 82%+ of the loss can be recovered with monolingually estimated features alone. We further show that our monolingual features add 1.5 BLEU points when combined with standard bilingually estimated phrase table features. 
</div>
<div id="bib/toward-statistical-machine-translation-without-parallel-corpora" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{klementiev-etal:2012:EACL,
  author =  {Alex Klementiev and Ann Irvine and Chris Callison-Burch and David Yarowsky},
  title     = {Toward Statistical Machine Translation without Parallel Corpora},
  booktitle = {Proceedings of the 13th Conference of the European Chapter of the Association for computational Linguistics},
  month     = {April},
  year      = {2012},
  address   = {Avignon, France}
  publisher = {Association for Computational Linguistics},
}
</pre>
</font>
</div>
</P>


<P><a href="publications/modality-and-negation-in-semantically-informed-syntactic-mt.pdf">Use of Modality and Negation in Semantically-Informed Syntactic MT</a>. Kathryn Baker, Bonnie Dorr, Michael Bloodgood, Chris Callison-Burch, Wes Filardo, Christine Piatko, Lori Levin, and Scott Miller, 2012. Computational Linguistics.  
<a href="javascript:unhide('abstract/modality-and-negation-in-semantically-informed-syntactic-mt')">[abstract]</a>
<a href="javascript:unhide('bib/modality-and-negation-in-semantically-informed-syntactic-mt')">[bib]</a>
<div id="abstract/modality-and-negation-in-semantically-informed-syntactic-mt" class="hidden-abstract">
This article describes the resource- and system-building efforts of an eight-week JHU Human Language Technology Center of Excellence Summer Camp for Applied Language Exploration (SCALE-2009) on Semantically-Informed Machine Translation (SIMT). We describe a new modality/negation (MN) annotation scheme, a (publicly available) MN lexicon, and two automated MN taggers that we built using the annotation scheme and lexicon. Our annotation scheme isolates three components of modality and negation: a trigger (a word that conveys modality or negation), a target (an action associated with modality or negation) and a holder (an experiencer of modality). We describe how our MN lexicon was produced semi-automatically and we demonstrate that a structure-based MN tagger results in precision around 86% (depending on genre) for tagging of a standard LDC data set.
We apply our MN annotation scheme to statistical machine translation using a syntactic framework that supports the inclusion of semantic annotations. Syntactic tags enriched with semantic annotations are assigned to parse trees in the target-language training texts through a process of tree grafting. While the focus of our work is modality and negation, the tree grafting procedure is general and supports other types of semantic information. We exploit this capability by including named entities, produced by a pre-existing tagger, in addition to the MN elements produced by the taggers described in this paper. The resulting system significantly outperformed a linguistically naïve baseline model (Hiero), and reached the highest scores yet reported on the NIST 2009 Urdu-English test set. This finding supports the hypothesis that both syntactic and semantic information can improve translation quality.
</div>
<div id="bib/modality-and-negation-in-semantically-informed-syntactic-mt" class="hidden-abstract">
<font size="-2">
<pre>
@article{baker-etal:2012:CL,
  author =  {Kathryn Baker and Bonnie Dorr and Michael Bloodgood and Chris Callison-Burch and Nathaniel Filardo and Christine Piatko and Lori Levin and Scott Miller},
  title =   {Use of Modality and Negation in Semantically-Informed Syntactic MT},
  journal = {Computational Linguistics},
  year =    {2012},
  volume = {38},
  number = {2},
  pages = {411-438}
}
</pre>
</font>
</div>
</P>


<h3>2011</h3>
<P><a href="publications/findings-of-the-wmt11-shared-tasks.pdf">Findings of the 2011 Workshop on Statistical Machine Translation</a>. Chris Callison-Burch, Philipp Koehn, Christof Monz, and Omar Zaidan, 2011.  In WMT11. 
<a href="javascript:unhide('abstract/findings-of-the-wmt11-shared-tasks')">[abstract]</a>
<a href="javascript:unhide('bib/findings-of-the-wmt11-shared-tasks')">[bib]</a>
<div id="abstract/findings-of-the-wmt11-shared-tasks" class="hidden-abstract">
This paper presents the results of the WMT11 shared tasks, which included a translation task, a system combination task, and a task for machine translation evaluation metrics. We conducted a large-scale manual evaluation of 148 machine translation systems and 41 system combination entries. We used the ranking of these systems to measure how strongly automatic metrics correlate with human judgments of translation quality for 21 evaluation metrics. This year featured a Haitian Creole to English task translating SMS messages sent to an emergency response service in the aftermath of the Haitian earthquake. We also conducted a pilot ‘tunable metrics’ task to test whether optimizing a fixed system to different metrics would result in perceptibly different translation quality.
</div>
<div id="bib/findings-of-the-wmt11-shared-tasks" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{callisonburch-EtAl:2011:WMT,
  author    = {Callison-Burch, Chris  and  Koehn, Philipp  and  Monz, Christof  and  Zaidan, Omar},
  title     = {Findings of the 2011 Workshop on Statistical Machine Translation},
  booktitle = {Proceedings of the Sixth Workshop on Statistical Machine Translation},
  month     = {July},
  year      = {2011},
  address   = {Edinburgh, Scotland},
  publisher = {Association for Computational Linguistics},
  pages     = {22--64},
  url       = {http://www.aclweb.org/anthology/W11-2103}
}
</pre>
</font>
</div>
</P>

<P><a href="publications/learning-sentential-paraphrases-from-bilingual-parallel-corpora.pdf">Learning Sentential Paraphrases from Bilingual Parallel Corpora for Text-to-Text Generation</a>. Juri Ganitkevitch, Chris Callison-Burch, Courtney Napoles, and Benjamin Van Durme, 2011.  In Proceedings of EMNLP 2011.
<a href="javascript:unhide('abstract/learning-sentential-paraphrases-from-bilingual-parallel-corpora')">[abstract]</a> 
<a href="javascript:unhide('bib/learning-sentential-paraphrases-from-bilingual-parallel-corpora')">[bib]</a>
<div id="abstract/learning-sentential-paraphrases-from-bilingual-parallel-corpora" class="hidden-abstract">
Previous work has shown that high quality <i>phrasal</i> paraphrases can be extracted from bilingual parallel corpora. However, it is not clear whether bitexts are an appropriate resource for extracting more sophisticated sentential paraphrases, which are more obviously learnable from monolingual parallel corpora. We extend bilingual paraphrase extraction to syntactic paraphrases and demonstrate its ability to learn a variety of general paraphrastic transformations, including passivization, dative shift, and topicalization. We discuss how our model can be adapted to many text generation tasks by augmenting its feature set, development data, and parameter estimation routine. We illustrate this adaptation by using our paraphrase model for the task of sentence compression and achieve results competitive with state-of-the-art compression systems.
</div>
<div id="bib/learning-sentential-paraphrases-from-bilingual-parallel-corpora" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{ganitkevitch-EtAl:2011:EMNLP,
  author    = {Ganitkevitch, Juri  and  Callison-Burch, Chris  and  Napoles, Courtney  and  {Van Durme}, Benjamin},
  title     = {Learning Sentential Paraphrases from Bilingual Parallel Corpora for Text-to-Text Generation},
  booktitle = {Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing},
  month     = {July},
  year      = {2011},
  address   = {Edinburgh, Scotland, UK.},
  publisher = {Association for Computational Linguistics},
  pages     = {1168--1179},
  url       = {http://www.aclweb.org/anthology/D11-1108}
}
</pre>
</font>
</div>
</P>

<P><a href="publications/reranking-bilingually-extracted-paraphrases-using-monolingual-distributional-similarity.pdf">Reranking Bilingually Extracted Paraphrases Using Monolingual Distributional Similarity</a>. Charley Chan, Chris Callison-Burch, and Benjamin Van Durme, 2011.  In Proceedings of GEometrical Models of Natural Language Semantics (GEMS-2011).
<a href="javascript:unhide('abstract/reranking-bilingually-extracted-paraphrases-using-monolingual-distributional-similarity')">[abstract]</a> 
<a href="javascript:unhide('bib/reranking-bilingually-extracted-paraphrases-using-monolingual-distributional-similarity')">[bib]</a>
<div id="abstract/reranking-bilingually-extracted-paraphrases-using-monolingual-distributional-similarity" class="hidden-abstract">
This paper improves an existing bilingual paraphrase extraction technique using monolingual distributional similarity to rerank candidate paraphrases. Raw monolingual data provides a complementary and orthogonal source of information that lessens the commonly observed errors in bilingual pivot-based methods. Our experiments reveal that monolingual scoring of bilingually extracted paraphrases has a significantly stronger correlation with human judgment for grammaticality than the probabilities assigned by the bilingual pivoting method does. The results also show that monolingual distribution similarity can serve as a threshold for high precision paraphrase selection.
</div>
<div id="bib/reranking-bilingually-extracted-paraphrases-using-monolingual-distributional-similarity" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{chan-callisonburch-vandurme:2011:GEMS,
  author    = {Chan, Tsz Ping  and  Callison-Burch, Chris  and  {Van Durme}, Benjamin},
  title     = {Reranking Bilingually Extracted Paraphrases Using Monolingual Distributional Similarity},
  booktitle = {Proceedings of the GEMS 2011 Workshop on GEometrical Models of Natural Language Semantics},
  month     = {July},
  year      = {2011},
  address   = {Edinburgh, UK},
  publisher = {Association for Computational Linguistics},
  pages     = {33--42},
  url       = {http://www.aclweb.org/anthology/W11-2504}
}
</pre>
</font>
</div>
</P>

<P><a href="publications/joshua-3.0.pdf">Joshua 3.0: Syntax-based Machine Translation with the Thrax Grammar Extractor</a>. Jonathan Weese, Juri Ganitkevitch, Chris Callison-Burch, Matt Post and Adam Lopez, 2011.  In WMT11.
<a href="javascript:unhide('abstract/joshua-3.0')">[abstract]</a> 
<a href="javascript:unhide('bib/joshua-3.0')">[bib]</a>
<div id="abstract/joshua-3.0" class="hidden-abstract">
We present progress on Joshua, an open source decoder for hierarchical and syntax-based machine translation. The main focus is describing Thrax, a flexible, open source synchronous context-free grammar extractor. Thrax extracts both hierarchical (Chiang, 2007) and syntax-augmented machine translation (Zollmann and Venugopal, 2006) grammars. It is built on Apache Hadoop for efficient distributed performance, and can easily be extended with support for new grammars, feature functions, and output formats.
</div>
<div id="bib/joshua-3.0" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{weese-EtAl:2011:WMT,
  author    = {Weese, Jonathan  and  Ganitkevitch, Juri  and  Callison-Burch, Chris  and  Post, Matt  and  Lopez, Adam},
  title     = {Joshua 3.0: Syntax-based Machine Translation with the Thrax Grammar Extractor},
  booktitle = {Proceedings of the Sixth Workshop on Statistical Machine Translation},
  month     = {July},
  year      = {2011},
  address   = {Edinburgh, Scotland},
  publisher = {Association for Computational Linguistics},
  pages     = {478--484},
  url       = {http://www.aclweb.org/anthology/W11-2160}
}
</pre>
</font>
</div>
</P>


<P><a href="publications/wikitopics-what-is-popular-on-wikipedia-and-why.pdf">WikiTopics: What is Popular on Wikipedia and Why</a>. Byung Gyu Ahn, Ben Van Durme and Chris Callison-Burch, 2011.  In Proceedings of ACL Workshop on Automatic Summarization for Different Genres, Media, and Languages.
<a href="javascript:unhide('abstract/wikitopics')">[abstract]</a> 
<a href="javascript:unhide('bib/wikitopics')">[bib]</a>
<div id="abstract/wikitopics" class="hidden-abstract">
We establish a novel task in the spirit of news summarization and topic detection and tracking (TDT): daily determination of the topics newly popular with Wikipedia readers. Central to this effort is a new public dataset consisting of the hourly page view statistics of all Wikipedia articles over the last three years. We give baseline results for the tasks of: discovering individual pages of interest, clustering these pages into coherent topics, and extracting the most relevant summarizing sentence for the reader. When compared to human judgements, our system shows the viability of this task, and opens the door to a range of exciting future work.
</div>
<div id="bib/wikitopics" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{ahn-vandurme-callisonburch:2011:SummarizationWorkshop,
  author    = {Ahn, Byung Gyu  and  {Van Durme}, Benjamin  and  Callison-Burch, Chris},
  title     = {WikiTopics: What is Popular on Wikipedia and Why},
  booktitle = {Proceedings of the Workshop on Automatic Summarization for Different Genres, Media, and Languages},
  month     = {June},
  year      = {2011},
  address   = {Portland, Oregon},
  publisher = {Association for Computational Linguistics},
  pages     = {33--40},
  url       = {http://www.aclweb.org/anthology/W11-0505}
}
</pre>
</font>
</div>
</P>


<P><a href="publications/evaluating-sentence-compression-pitfalls-and-suggested-remedies.pdf">Evaluating sentence compression: Pitfalls and suggested remedies</a>. Courtney Napoles, Ben Van Durme, 2011.  In Proceedings of Workshop on Monolingual Text-To-Text Generation (Text-To-Text-2011).
<a href="javascript:unhide('abstract/evaluating-sentence-compression')">[abstract]</a> 
<a href="javascript:unhide('bib/evaluating-sentence-compression')">[bib]</a>
<div id="abstract/evaluating-sentence-compression" class="hidden-abstract">
This work surveys existing evaluation methodologies for the task of sentence compression, identifies their shortcomings, and proposes alternatives. In particular, we examine the problems of evaluating paraphrastic compression and comparing the output of different models. We demonstrate that compression rate is a strong predictor of compression quality and that perceived improvement over other models is often a side effect of producing longer output.
</div>
<div id="bib/evaluating-sentence-compression" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{napoles-vandurme-callisonburch:2011:T2TW-2011,
  author    = {Napoles, Courtney  and  {Van Durme}, Benjamin  and  Callison-Burch, Chris},
  title     = {Evaluating Sentence Compression: Pitfalls and Suggested Remedies},
  booktitle = {Proceedings of the Workshop on Monolingual Text-To-Text Generation},
  month     = {June},
  year      = {2011},
  address   = {Portland, Oregon},
  publisher = {Association for Computational Linguistics},
  pages     = {91--97},
  url       = {http://www.aclweb.org/anthology/W11-1611}
}
</pre>
</font>
</div>
</P>

<P><a href="publications/paraphrastic-sentence-compression.pdf">Paraphrastic Sentence Compression with a Character-based Metric: Tightening without Deletion</a>. Courtney Napoles, Chris Callison-Burch, Juri Ganitevitch, Ben Van Durme, 2011.  In Proceedings of Workshop on Monolingual Text-To-Text Generation (Text-To-Text-2011).
<a href="javascript:unhide('abstract/paraphrastic-sentence-compression')">[abstract]</a> 
<a href="javascript:unhide('bib/paraphrastic-sentence-compression')">[bib]</a>
<div id="abstract/paraphrastic-sentence-compression" class="hidden-abstract">
We present a substitution-only approach to sentence compression which “tightens” a sentence by reducing its character length. Replacing phrases with shorter paraphrases yields paraphrastic compressions as short as 60% of the original length. In support of this task, we introduce a novel technique for re-ranking paraphrases extracted from bilingual corpora. At high compression rates1 paraphrastic compressions outperform a state-of-the-art deletion model in an oracle experiment. For further compression, deleting from oracle paraphrastic compressions preserves more meaning than deletion alone. In either setting, paraphrastic compression shows promise for surpassing deletion-only methods.
</div>
<div id="bib/paraphrastic-sentence-compression" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{napoles-EtAl:2011:T2TW-2011,
  author    = {Napoles, Courtney  and  Callison-Burch, Chris  and  Ganitkevitch, Juri  and  {Van Durme}, Benjamin},
  title     = {Paraphrastic Sentence Compression with a Character-based Metric: Tightening without Deletion},
  booktitle = {Proceedings of the Workshop on Monolingual Text-To-Text Generation},
  month     = {June},
  year      = {2011},
  address   = {Portland, Oregon},
  publisher = {Association for Computational Linguistics},
  pages     = {84--90},
  url       = {http://www.aclweb.org/anthology/W11-1610}
}
</pre>
</font>
</div>
</P>

<P><a href="publications/paraphrase-fragment-extraction-from-monolingual-comparable-corpora.pdf">Paraphrase Fragment Extraction from Monolingual Comparable Corpora</a>. Rui Wang and Chris Callison-Burch, 2011.  In Proceedings of Fourth Workshop on Building and Using Comparable Corpora (BUCC).
<a href="javascript:unhide('abstract/paraphrase-fragment-extraction')">[abstract]</a> 
<a href="javascript:unhide('bib/paraphrase-fragment-extraction')">[bib]</a>
<div id="abstract/paraphrase-fragment-extraction" class="hidden-abstract">
We present a novel paraphrase fragment pair extraction method that uses a monolingual comparable corpus containing different articles about the same topics or events. The procedure consists of document pair extraction, sentence pair extraction, and fragment pair extraction. At each stage, we evaluate the intermediate results manually, and tune the later stages accordingly. With this minimally supervised approach, we achieve 62% of accuracy on the paraphrase fragment pairs we collected and 67% extracted from the MSR corpus. The results look promising, given the minimal supervision of the approach, which can be further scaled up.
</div>
<div id="bib/paraphrase-fragment-extraction" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{wang-callisonburch:2011:BUCC,
  author    = {Wang, Rui  and  Callison-Burch, Chris},
  title     = {Paraphrase Fragment Extraction from Monolingual Comparable Corpora},
  booktitle = {Proceedings of the 4th Workshop on Building and Using Comparable Corpora: Comparable Corpora and the Web},
  month     = {June},
  year      = {2011},
  address   = {Portland, Oregon},
  publisher = {Association for Computational Linguistics},
  pages     = {52--60},
  url       = {http://www.aclweb.org/anthology/W11-1208}
}
</pre>
</font>
</div>
</P>

<P><a href="publications/arabic-dialect-corpus.pdf">The Arabic Online Commentary Dataset: An Annotated Dataset of Informal Arabic with High Dialectal Content</a>. Omar Zaidan and Chris Callison-Burch, 2011.  In Proceedings ACL-2011. 
<a href="javascript:unhide('abstract/arabic-dialect-corpus')">[abstract]</a> 
<a href="javascript:unhide('bib/arabic-dialect-corpus')">[bib]</a> 
<a href="http://cs.jhu.edu/~ozaidan/RCLMT/AOC-dialectal-annotations_indiv.zip">[data]</a>
<div id="abstract/arabic-dialect-corpus" class="hidden-abstract">
The written form of Arabic, Modern Standard Arabic (MSA), differs quite a bit from the spoken dialects of Arabic, which are the true “native” languages of Arabic speakers used in daily life. However, due to MSA’s prevalence in written form, almost all Arabic datasets have predominantly MSA content. We present the Arabic Online Commentary Dataset, a 52M-word monolingual dataset rich in dialectal content, and we describe our long-term annotation effort to identify the dialect level (and dialect itself) in each sentence of the dataset. So far, we have labeled 108K sentences, 41% of which as having dialectal content. We also present experimental results on the task of automatic dialect identification, using the collected labels for training and evaluation.
</div>
<div id="bib/arabic-dialect-corpus" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{zaidan-callisonburch:2011:ACL-HLT2011,
  author    = {Zaidan, Omar F.  and  Callison-Burch, Chris},
  title     = {The Arabic Online Commentary Dataset: an Annotated Dataset of Informal Arabic with High Dialectal Content},
  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},
  month     = {June},
  year      = {2011},
  address   = {Portland, Oregon, USA},
  publisher = {Association for Computational Linguistics},
  pages     = {37--41},
  url       = {http://www.aclweb.org/anthology/P11-2007}
}
</pre>
</font>
</div>
</P>


<P><a href="publications/crowdsourcing-translation.pdf">Crowdsourcing Translation: Professional Quality from Non-Professionals</a>. Omar Zaidan and Chris Callison-Burch, 2011.  In Proceedings ACL-2011.
<a href="javascript:unhide('abstract/crowdsourcing-translation')">[abstract]</a> 
<a href="javascript:unhide('bib/crowdsourcing-translation')">[bib]</a>
<div id="abstract/crowdsourcing-translation" class="hidden-abstract">
Naively collecting translations by crowdsourcing the task to non-professional translators yields disfluent, low-quality results if no quality control is exercised. We demonstrate a variety of mechanisms that increase the translation quality to near professional levels. Specifically, we solicit redundant translations and edits to them, and automatically select the best output among them. We propose a set of features that model both the translations and the translators, such as country of residence, LM perplexity of the translation, edit rate from the other translations, and (optionally) calibration against professional translators. Using these features to score the collected translations, we are able to discriminate between acceptable and unacceptable translations. We recreate the NIST 2009 Urdu-toEnglish evaluation set with Mechanical Turk, and quantitatively show that our models are able to select translations within the range of quality that we expect from professional translators. The total cost is more than an order of magnitude lower than professional translation.
</div>
<div id="bib/crowdsourcing-translation" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{zaidan-callisonburch:2011:ACL-HLT2011,
  author    = {Zaidan, Omar F.  and  Callison-Burch, Chris},
  title     = {Crowdsourcing Translation: Professional Quality from Non-Professionals},
  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},
  month     = {June},
  year      = {2011},
  address   = {Portland, Oregon, USA},
  publisher = {Association for Computational Linguistics},
  pages     = {1220--1229},
  url       = {http://www.aclweb.org/anthology/P11-1122}
}
</pre>
</font>
</div>
</P>

<P><a href="publications/incremental-syntactic-language-models-for-phrase-based-translation.pdf">Incremental Syntactic Language Models for Phrase-based Translation</a>. Lane Schwartz, Chris Callison-Burch, William Schuler and Stephen Wu, 2011. In Proceedings ACL-2011. <a href="javascript:unhide('abstract/incremental-syntactic-language-models')">[abstract]</a> 
<a href="javascript:unhide('bib/incremental-syntactic-language-models')">[bib]</a>
<div id="abstract/incremental-syntactic-language-models" class="hidden-abstract">
This paper describes a novel technique for incorporating syntactic knowledge into phrasebased machine translation through incremental syntactic parsing. Bottom-up and topdown parsers typically require a completed string as input. This requirement makes it difficult to incorporate them into phrase-based translation, which generates partial hypothesized translations from left-to-right. Incremental syntactic language models score sentences in a similar left-to-right fashion, and are therefore a good mechanism for incorporating syntax into phrase-based translation. We give a formal definition of one such lineartime syntactic language model, detail its relation to phrase-based decoding, and integrate the model with the Moses phrase-based translation system. We present empirical results on a constrained Urdu-English translation task that demonstrate a significant BLEU score improvement and a large decrease in perplexity.
</div>
<div id="bib/incremental-syntactic-language-models" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{schwartz-EtAl:2011:ACL-HLT20111,
  author    = {Schwartz, Lane  and  Callison-Burch, Chris  and  Schuler, William  and  Wu, Stephen},
  title     = {Incremental Syntactic Language Models for Phrase-based Translation},
  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},
  month     = {June},
  year      = {2011},
  address   = {Portland, Oregon, USA},
  publisher = {Association for Computational Linguistics},
  pages     = {620--631},
  url       = {http://www.aclweb.org/anthology/P11-1063}
}
</pre>
</font>
</div>
</P>

<h3>2010</h3>

<P><a href="publications/predicting-HTER-from-untrained-annotators.pdf">Predicting Human-Targeted Translation Edit Rate via Untrained Human Annotators</a>. Omar Zaidan and Chris Callison-Burch, 2010.  In Proceedings NAACL-2010.
<a href="javascript:unhide('abstract/predicting-HTER-from-untrained-annotators')">[abstract]</a> 
<a href="javascript:unhide('bib/predicting-HTER-from-untrained-annotators')">[bib]</a>
<div id="abstract/predicting-HTER-from-untrained-annotators" class="hidden-abstract">
In the field of machine translation, automatic metrics have proven quite valuable in system development for tracking progress and measuring the impact of incremental changes. However, human judgment still plays a large role in the context of evaluating MT systems. For example, the GALE project uses human-targeted translation edit rate (HTER), wherein the MT output is scored against a post-edited version of itself (as opposed to being scored against an existing human reference). This poses a problem for MT researchers, since HTER is not an easy metric to calculate, and would require hiring and training human annotators to perform the editing task. In this work, we explore soliciting those edits from untrained human annotators, via the online service Amazon Mechanical Turk. We show that the collected data allows us to predict HTER-ranking of documents at a significantly higher level than the ranking obtained using automatic metrics.
</div>
<div id="bib/predicting-HTER-from-untrained-annotators" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{zaidan-callisonburch:2010:NAACLHLT,
  author    = {Zaidan, Omar F.  and  Callison-Burch, Chris},
  title     = {Predicting Human-Targeted Translation Edit Rate via Untrained Human Annotators},
  booktitle = {Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics},
  month     = {June},
  year      = {2010},
  address   = {Los Angeles, California},
  publisher = {Association for Computational Linguistics},
  pages     = {369--372},
  url       = {http://www.aclweb.org/anthology/N10-1057}
}
</pre>
</font>
</div>
</P>

<P><a href="publications/semantically-informed-syntactic-machine-translation.pdf">Semantically-Informed Syntactic Machine Translation: A Tree-Grafting Approach</a>. Kathryn Baker, Michael Bloodgood, Chris Callison-Burch, Bonnie Dorr, Scott Miller, Christine Piatko, Nathaniel W. Filardo, and Lori Levin, 2010.  In Proceedings of AMTA-2010.
<a href="javascript:unhide('abstract/semantically-informed-syntactic-machine-translation')">[abstract]</a> 
<a href="javascript:unhide('bib/semantically-informed-syntactic-machine-translation')">[bib]</a>
<div id="abstract/semantically-informed-syntactic-machine-translation" class="hidden-abstract">
We describe a unified and coherent syntactic framework for supporting a semantically-informed syntactic approach to statistical machine translation. Semantically enriched syntactic tags assigned to the target-language training texts improved translation quality. The resulting system significantly outperformed a linguistically naive baseline model (Hiero), and reached the highest scores yet reported on the NIST 2009 Urdu-English translation task. This finding supports the hypothesis (posed by many researchers in the MT community, e.g., in DARPA GALE) that both syntactic and semantic information are critical for improving translation quality—and further demonstrates that large gains can be achieved for low-resource languages with different word order than English.
</div>
<div id="bib/semantically-informed-syntactic-machine-translation" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{Baker-EtAl:2010:AMTA,
  author = {Kathryn Baker and Michael Bloodgood and Chris Callison-Burch and Bonnie J. Dorr and Nathaniel W. Filardo and Lori Levin and Scott Miller and Christine Piatko},
  title = {Semantically-Informed Machine Translation: A Tree-Grafting Approach},
  booktitle = {Proceedings of The Ninth Biennial Conference of the Association for Machine Translation in the Americas},
  address = {Denver, Colorado},
  url = {http://www.mt-archive.info/AMTA-2010-Baker.pdf},
  year = {2010}
}
</pre>
</font>
</div>
</P>


<P><a href="publications/transliterating-from-all-languages.pdf">Transliterating From All Languages</a>. Ann Irvine, Alex Klementiev, and Chris Callison-Burch.  In Proceedings of AMTA-2010.
<a href="javascript:unhide('abstract/transliterating-from-all-languages')">[abstract]</a> 
<a href="javascript:unhide('bib/transliterating-from-all-languages')">[bib]</a>
<a href="http://cis.upenn.edu/~ccb/data/transliteration/wikipedia_names.gz">[data]</a>
<div id="abstract/transliterating-from-all-languages" class="hidden-abstract">
Much of the previous work on transliteration has depended on resources and attributes specific to particular language pairs. In this work, rather than focus on a single language pair, we create robust models for transliterating from all languages in a large, diverse set to English. We create training data for 150 languages by mining name pairs from Wikipedia. We train 13 systems and analyze the effects of the amount of training data on transliteration performance. We also present an analysis of the types of errors that the systems make. Our analyses are particularly valuable for building machine translation systems for low resource languages, where creating and integrating a transliteration module for a language with few NLP resources may provide substantial gains in translation performance.
</div>
<div id="bib/transliterating-from-all-languages" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{Irvine-EtAl:2010:AMTA,
  author = {Ann Irvine and Chris Callison-Burch and Alexandre Klementiev}
  title = {Transliterating From All Languages},
  booktitle = {Proceedings of The Ninth Biennial Conference of the Association for Machine Translation in the Americas},
  address = {Denver, Colorado},
  url = {http://cis.upenn.edu/~ccb/publications/transliterating-from-all-languages.pdf},
  year = {2010}
}
</pre>
</font>
</div>
</P>

<P><a href="publications/joshua-2.0.pdf">Joshua 2.0: A Toolkit for Parsing-Based Machine Translationwith Syntax, Semirings, Discriminative Training and Other Goodies</a>. Zhifei Li, Chris Callison-Burch, Chris Dyer, Juri Ganitkevitch, Ann Irvine, Lane Schwartz, Wren N. G. Thornton, Ziyuan Wang, Jonathan Weese and Omar F. Zaidan, 2010. In Proceedings of WMT.
<a href="javascript:unhide('abstract/joshua-2.0')">[abstract]</a> 
<a href="javascript:unhide('bib/joshua-2.0')">[bib]</a>
<div id="abstract/joshua-2.0" class="hidden-abstract">
We describe the progress we have made in the past year on Joshua (Li et al., 2009a), an open source toolkit for parsing-based machine translation. The new functionality includes: support for translation grammars with a rich set of syntactic nonterminals, the ability for external modules to posit constraints on how spans in the input sentence should be translated, lattice parsing for dealing with input uncertainty, a semiring framework that provides a unified way of doing various dynamic programming calculations, variational decoding for approximating the intractable MAP decoding, hypergraph-based discriminative training for better feature engineering, a parallelized MERT module, document-level and tail-based MERT, visualization of the derivation trees, and a cleaner pipeline for MT experiments.
</div>
<div id="bib/joshua-2.0" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{li-EtAl:2010:WMT,
  author    = {Li, Zhifei  and  Callison-Burch, Chris  and  Dyer, Chris  and  Ganitkevitch, Juri  and  Irvine, Ann  and  Khudanpur, Sanjeev  and  Schwartz, Lane  and  Thornton, Wren  and  Wang, Ziyuan  and  Weese, Jonathan  and  Zaidan, Omar},
  title     = {Joshua 2.0: A Toolkit for Parsing-Based Machine Translation with Syntax, Semirings, Discriminative Training and Other Goodies},
  booktitle = {Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR},
  month     = {July},
  year      = {2010},
  address   = {Uppsala, Sweden},
  publisher = {Association for Computational Linguistics},
  pages     = {133--137},
  url       = {http://www.aclweb.org/anthology/W10-1718}
}
</pre>
</font>
</div>
</P>

<P><a href="publications/findings-of-wmt10-and-metrics-matr.pdf">Findings of the 2010 Joint Workshop on Statistical Machine Translation and Metrics for Machine Translation</a>. Chris Callison-Burch, Philipp Koehn, Christof Monz, Kay Peterson, Mark Przybocki, Omar Zaidan, 2010.  In Proceedings of WMT.
<a href="javascript:unhide('abstract/findings-of-wmt10')">[abstract]</a> 
<a href="javascript:unhide('bib/findings-of-wmt10')">[bib]</a>
<div id="abstract/findings-of-wmt10" class="hidden-abstract">
This paper presents the results of the WMT10 and MetricsMATR10 shared tasks,1 which included a translation task, a system combination task, and an evaluation task. We conducted a large-scale manual evaluation of 104 machine translation systems and 41 system combination entries. We used the ranking of these systems to measure how strongly automatic metrics correlate with human judgments of translation quality for 26 metrics. This year we also investigated increasing the number of human judgments by hiring non-expert annotators through Amazon’s Mechanical Turk.
</div>
<div id="bib/findings-of-wmt10" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{callisonburch-EtAl:2010:WMT,
  author    = {Callison-Burch, Chris  and  Koehn, Philipp  and  Monz, Christof  and  Peterson, Kay  and  Przybocki, Mark  and  Zaidan, Omar},
  title     = {Findings of the 2010 Joint Workshop on Statistical Machine Translation and Metrics for Machine Translation},
  booktitle = {Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR},
  month     = {July},
  year      = {2010},
  address   = {Uppsala, Sweden},
  publisher = {Association for Computational Linguistics},
  pages     = {17--53},
  url       = {http://www.aclweb.org/anthology/W10-1703}
}
</pre>
</font>
</div>
</P>

<P><a href="publications/cost-focused-active-learning-for-statistical-machine-translation.pdf">Large-Scale, Cost-Focused Active Learning for Statistical Machine Translation</a>. Michael Bloodgood and Chris Callison-Burch, 2010.  In Proceedings ACL-2010.
<a href="javascript:unhide('abstract/cost-focused-active-learning-for-statistical-machine-translation')">[abstract]</a> 
<a href="javascript:unhide('bib/cost-focused-active-learning-for-statistical-machine-translation')">[bib]</a>
<div id="abstract/cost-focused-active-learning-for-statistical-machine-translation" class="hidden-abstract">
We explore how to improve machine translation systems by adding more translation data in situations where we already have substantial resources. The main challenge is how to buck the trend of diminishing returns that is commonly encountered. We present an active learning-style data solicitation algorithm to meet this challenge. We test it, gathering annotations via Amazon Mechanical Turk, and find that we get an order of magnitude increase in performance rates of improvement.
</div>
<div id="bib/cost-focused-active-learning-for-statistical-machine-translation" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{bloodgood-callisonburch:2010:ACL,
  author    = {Bloodgood, Michael  and  Callison-Burch, Chris},
  title     = {Bucking the Trend: Large-Scale Cost-Focused Active Learning for Statistical Machine Translation},
  booktitle = {Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics},
  month     = {July},
  year      = {2010},
  address   = {Uppsala, Sweden},
  publisher = {Association for Computational Linguistics},
  pages     = {854--864},
  url       = {http://www.aclweb.org/anthology/P10-1088}
}
</pre>
</font>
</div>
</P>

<P><a href="publications/creating-speech-and-language-data-with-amazon-mechanical-turk.pdf">Creating Speech and Language Data With Amazon’s Mechanical Turk</a>. Chris Callison-Burch and Mark Dredze, 2010.  In Proceedings NAACL-2010 <a href="http://sites.google.com/site/amtworkshop2010/">Workshop on Creating Speech and Language Data With Amazon’s Mechanical Turk.</a>
<a href="javascript:unhide('abstract/creating-speech-and-language-data-with-amazon-mechanical-turk')">[abstract]</a> 
<a href="javascript:unhide('bib/creating-speech-and-language-data-with-amazon-mechanical-turk')">[bib]</a>
<div id="abstract/creating-speech-and-language-data-with-amazon-mechanical-turk" class="hidden-abstract">
In this paper we give an introduction to using Amazon's Mechanical Turk crowdsourcing platform for the purpose of collecting data for human language technologies. We survey the papers published in the NAACL2010 Workshop. 24 researchers participated in the workshop's $100 challenge to create data for speech and language applications.
</div>
<div id="bib/creating-speech-and-language-data-with-amazon-mechanical-turk" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{callisonburch-dredze:2010:MTURK,
  author    = {Callison-Burch, Chris  and  Dredze, Mark},
  title     = {Creating Speech and Language Data With {Amazon's Mechanical Turk}},
  booktitle = {Proceedings of the {NAACL HLT} 2010 Workshop on Creating Speech and Language Data with {Amazon's Mechanical Turk}},
  month     = {June},
  year      = {2010},
  address   = {Los Angeles},
  publisher = {Association for Computational Linguistics},
  pages     = {1--12},
  url       = {http://www.aclweb.org/anthology/W10-0701}
}
</pre>
</font>
</div>
</P>


<P><a href="publications/using-mechanical-turk-to-build-machine-translation-evaluation-sets.pdf">Using Mechanical Turk to Build Machine Translation Evaluation Sets</a>. Michael Bloodgood and Chris Callison-Burch, 2010.  In Proceedings NAACL-2010 Workshop on Creating Speech and Language Data With Amazon’s Mechanical Turk.
<a href="javascript:unhide('abstract/using-mechanical-turk-to-build-machine-translation-evaluation-sets')">[abstract]</a> 
<a href="javascript:unhide('bib/using-mechanical-turk-to-build-machine-translation-evaluation-sets')">[bib]</a>
<div id="abstract/using-mechanical-turk-to-build-machine-translation-evaluation-sets" class="hidden-abstract">
Building machine translation (MT) test sets is a relatively expensive task. As MT becomes increasingly desired for more and more language pairs and more and more domains, it becomes necessary to build test sets for each case. In this paper, we investigate using Amazon's Mechanical Turk (MTurk) to make MT test sets cheaply. We find that MTurk can be used to make test sets much cheaper than professionally-produced test sets. More importantly, in experiments with multiple MT systems, we find that the MTurk-produced test sets yield essentially the same conclusions regarding system performance as the professionally-produced test sets yield.
</div>
<div id="bib/using-mechanical-turk-to-build-machine-translation-evaluation-sets" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{bloodgood-callisonburch:2010:MTURK,
  author    = {Bloodgood, Michael  and  Callison-Burch, Chris},
  title     = {Using {Mechanical Turk} to Build Machine Translation Evaluation Sets},
  booktitle = {Proceedings of the {NAACL HLT} 2010 Workshop on Creating Speech and Language Data with {Amazon's Mechanical Turk}},
  month     = {June},
  year      = {2010},
  address   = {Los Angeles},
  publisher = {Association for Computational Linguistics},
  pages     = {208--211},
  url       = {http://www.aclweb.org/anthology/W10-0733}
}
</pre>
</font>
</div>
</P>

<P><a href="publications/crowdsourced-accessibility-elicitation-of-wikipedia-articles.pdf">Crowdsourced Accessibility: Elicitation of Wikipedia Articles</a>. Scott Novotoney and Chris Callison-Burch, 2010.  In Proceedings NAACL-2010 Workshop on Creating Speech and Language Data With Amazon’s Mechanical Turk.
<a href="javascript:unhide('abstract/crowdsourced-accessibility-elicitation-of-wikipedia-articles')">[abstract]</a> 
<a href="javascript:unhide('bib/crowdsourced-accessibility-elicitation-of-wikipedia-articles')">[bib]</a>
<div id="abstract/crowdsourced-accessibility-elicitation-of-wikipedia-articles" class="hidden-abstract">
Mechanical Turk is useful for generating complex speech resources like conversational speech transcription. In this work, we explore the next step of eliciting narrations of Wikipedia articles to improve accessibility for low-literacy users. This task proves a useful test-bed to implement qualitative vetting of workers based on difficult to define metrics like narrative quality. Working with the Mechanical Turk API, we collected sample narrations, had other Turkers rate these samples and then granted access to full narration HITs depending on aggregate quality. While narrating full articles proved too onerous a task to be viable, using other Turkers to perform vetting was very successful. Elicitation is possible on Mechanical Turk, but it should conform to suggested best practices of simple tasks that can be completed in a streamlined workflow.
</div>
<div id="bib/crowdsourced-accessibility-elicitation-of-wikipedia-articles" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{novotney-callisonburch:2010:MTURK,
  author    = {Novotney, Scott  and  Callison-Burch, Chris},
  title     = {Crowdsourced Accessibility: Elicitation of Wikipedia Articles},
  booktitle = {Proceedings of the {NAACL HLT} 2010 Workshop on Creating Speech and Language Data with {Amazon's Mechanical Turk}},
  month     = {June},
  year      = {2010},
  address   = {Los Angeles},
  publisher = {Association for Computational Linguistics},
  pages     = {41--44},
  url       = {http://www.aclweb.org/anthology/W10-0706}
}
</pre>
</font>
</div>
</P>

<P><a href="publications/cheap-facts-and-counter-facts.pdf">Cheap Facts and Counter-Facts</a>. Rui Wang and Chris Callison-Burch, 2010.  In Proceedings NAACL-2010 Workshop on Creating Speech and Language Data With Amazon’s Mechanical Turk.
<a href="javascript:unhide('abstract/cheap-facts-and-counter-facts')">[abstract]</a> 
<a href="javascript:unhide('bib/cheap-facts-and-counter-facts')">[bib]</a>
<div id="abstract/cheap-facts-and-counter-facts" class="hidden-abstract">
This paper describes our experiments of using Amazon's Mechanical Turk to generate (counter-)facts from texts for certain named entities. We give the human annotators a paragraph of text and a highlighted named entity. They will write down several (counter-)facts about this named entity in that context. The analysis of the results is performed by comparing the acquired data with the recognizing textual entailment (RTE) challenge dataset.
</div>
<div id="bib/cheap-facts-and-counter-facts" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{wang-callisonburch:2010:MTURK,
  author    = {Wang, Rui  and  Callison-Burch, Chris},
  title     = {Cheap Facts and Counter-Facts},
  booktitle = {Proceedings of the {NAACL HLT} 2010 Workshop on Creating Speech and Language Data with {Amazon's Mechanical Turk}},
  month     = {June},
  year      = {2010},
  address   = {Los Angeles},
  publisher = {Association for Computational Linguistics},
  pages     = {163--167},
  url       = {http://www.aclweb.org/anthology/W10-0725}
}
</pre>
</font>
</div>
</P>


<P><a href="publications/stream-based-translation-models.pdf">Stream-based Translation Models for Statistical Machine Translation</a>. Abby Levenberg, Chris Callison-Burch, and Miles Osborne, 2010.  In Proceedings NAACL-2010.
<a href="javascript:unhide('abstract/stream-based-translation-models')">[abstract]</a> 
<a href="javascript:unhide('bib/stream-based-translation-models')">[bib]</a>
<div id="abstract/stream-based-translation-models" class="hidden-abstract">
Typical statistical machine translation systems are trained with static parallel corpora. Here we account for scenarios with a continuous incoming stream of parallel training data. Such scenarios include daily governmental proceedings, sustained output from translation agencies, or crowd-sourced translations. We show incorporating recent sentence pairs from the stream improves performance compared with a static baseline. Since frequent batch retraining is computationally demanding we introduce a fast incremental alternative using an online version of the EM algorithm. To bound our memory requirements we use a novel data-structure and associated training regime. When compared to frequent batch retraining, our online time and space-bounded model achieves the same performance with significantly less computational overhead.
</div>
<div id="bib/stream-based-translation-models" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{levenberg-callisonburch-osborne:2010:NAACLHLT,
  author    = {Levenberg, Abby  and  Callison-Burch, Chris  and  Osborne, Miles},
  title     = {Stream-based Translation Models for Statistical Machine Translation},
  booktitle = {Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics},
  month     = {June},
  year      = {2010},
  address   = {Los Angeles, California},
  publisher = {Association for Computational Linguistics},
  pages     = {394--402},
  url       = {http://www.aclweb.org/anthology/N10-1062}
}
</pre>
</font>
</div>
</P>

<P><a href="publications/automatic-speech-recognition-with-non-expert-transcription.pdf">Cheap, Fast and Good Enough: Automatic Speech Recognition with Non-Expert Transcription</a>. Scott Novotney and Chris Callison-Burch, 2010.  In Proceedings NAACL-2010.
<a href="javascript:unhide('abstract/automatic-speech-recognition-with-non-expert-transcription')">[abstract]</a> 
<a href="javascript:unhide('bib/automatic-speech-recognition-with-non-expert-transcription')">[bib]</a>
<div id="abstract/automatic-speech-recognition-with-non-expert-transcription" class="hidden-abstract">
Deploying an automatic speech recognition system with reasonable performance requires expensive and time-consuming in-domain transcription. Previous work demonstrated that non-professional annotation through Amazon’s Mechanical Turk can match professional quality. We use Mechanical Turk to transcribe conversational speech for as little as one thirtieth the cost of professional transcription. The higher disagreement of non-professional transcribers does not have a significant effect on system performance. While previous work demonstrated that redundant transcription can improve data quality, we found that resources are better spent collecting more data. Finally, we describe a quality control method without needing professional transcription.
</div>
<div id="bib/automatic-speech-recognition-with-non-expert-transcription" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{novotney-callisonburch:2010:NAACLHLT,
  author    = {Novotney, Scott  and  Callison-Burch, Chris},
  title     = {Cheap, Fast and Good Enough: Automatic Speech Recognition with Non-Expert Transcription},
  booktitle = {Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics},
  month     = {June},
  year      = {2010},
  address   = {Los Angeles, California},
  publisher = {Association for Computational Linguistics},
  pages     = {207--215},
  url       = {http://www.aclweb.org/anthology/N10-1024}
}
</pre>
</font>
</div>
</P>


<P><a href="publications/integrating-output-from-specialized-modules-in-machine-translation.pdf">Integrating Output from Specialized Modules in Machine Translation: Transliteration in Joshua</a>. Ann Irvine, Mike Kayser, Zhifei Li, Wren Thornton, and Chris Callison-Burch, 2010.  In The Prague Bulletin of Mathematical Linguistics (PBML), Number 93, January 2010.
<a href="javascript:unhide('abstract/integrating-output-from-specialized-modules-in-machine-translation')">[abstract]</a> 
<a href="javascript:unhide('bib/integrating-output-from-specialized-modules-in-machine-translation')">[bib]</a>
<div id="abstract/integrating-output-from-specialized-modules-in-machine-translation" class="hidden-abstract">
In many cases in SMT we want to allow specialized modules to propose translation fragments to the decoder and allow them to compete with translations contained in the phrase table. Transliteration is one module that may produce such specialized output. In this paper, as an example, we build a specialized Urdu transliteration module and integrate its output into an Urdu–English MT system. The module marks-up the test text using an XML format, and the decoder allows alternate translations (transliterations) to compete.
</div>
<div id="bib/integrating-output-from-specialized-modules-in-machine-translation" class="hidden-abstract">
<font size="-2">
<pre>
@article{Irvine-EtAl:2010:PBML,
author = {Ann Irvine and Mike Kayser and Zhifei Li and Wren Thornton and Chris Callison-Burch },
title = {Integrating Output from Specialized Modules in Machine Translation: Transliteration in {J}oshua},
journal = {The Prague Bulletin of Mathematical Linguistics},
volume = {93},
pages = {107--116},
year = {2010}
}
</pre>
</font>
</div>
</P>

<P><a href="publications/visualizing-data-structures-in-parsing-based-machine-translation.pdf">Visualizing Data Structures in Parsing-Based Machine Translation</a>. Jonathan Weese and Chris Callison-Burch, 2010.  In The Prague Bulletin of Mathematical Linguistics (PBML), Number 93, January 2010.
<a href="javascript:unhide('abstract/visualizing-data-structures-in-parsing-based-machine-translation')">[abstract]</a> 
<a href="javascript:unhide('bib/visualizing-data-structures-in-parsing-based-machine-translation')">[bib]</a>
<div id="abstract/visualizing-data-structures-in-parsing-based-machine-translation" class="hidden-abstract">
As machine translation (MT) systems grow more complex and incorporate more linguistic knowledge, it becomes more difficult to evaluate independent pieces of the MT pipeline. Being able to inspect many of the intermediate data structures used during MT decoding allows a more fine-grained evaluation of MT performance, helping to determine which parts of the current process are effective and which are not. In this article, we present an overview of the visualization tools that are currently distributed with the Joshua (Li et al., 2009) MT decoder. We explain their use and present an example of how visually inspecting the decoder’s data structures has led to useful improvements in the MT model.
</div>
<div id="bib/visualizing-data-structures-in-parsing-based-machine-translation" class="hidden-abstract">
<font size="-2">
<pre>
@article{Weese-CallisonBurch:2010:PBML,
author = {Jonathan Weese and Chris Callison-Burch},
title = {Visualizing Data Structures in Parsing-based Machine Translation},
journal = {The Prague Bulletin of Mathematical Linguistics},
volume = {93},
pages = {127--136},
year = {2010}
}
</pre>
</font>
</div>
</P>

<P><a href="publications/hiero-grammar-extraction-with-suffix-arrays.pdf">Hierarchical Phrase-Based Grammar Extraction in Joshua: Suffix Arrays and Prefix Trees</a>. Lane Schwartz and Chris Callison-Burch, 2010.  In The Prague Bulletin of Mathematical Linguistics (PBML), Number 93, January 2010.
<a href="javascript:unhide('abstract/hiero-grammar-extraction-with-suffix-arrays')">[abstract]</a> 
<a href="javascript:unhide('bib/hiero-grammar-extraction-with-suffix-arrays')">[bib]</a>
<div id="abstract/hiero-grammar-extraction-with-suffix-arrays" class="hidden-abstract">
While example-based machine translation has long used corpus information at run-time, statistical phrase-based approaches typically include a preprocessing stage where an aligned parallel corpus is split into phrases, and parameter values are calculated for each phrase using simple relative frequency estimates. This paper describes an open source implementation of the crucial algorithms presented in (Lopez, 2008) which allow direct run-time calculation of SCFG translation rules in Joshua.
</div>
<div id="bib/hiero-grammar-extraction-with-suffix-arrays" class="hidden-abstract">
<font size="-2">
<pre>
@article{Schwartz-CallisonBurch:2010:PBML,
author = {Lane Schwartz and Chris Callison-Burch },
title = {Hierarchical Phrase-Based Grammar Extraction in Joshua: Suffix Arrays and Prefix Tree},
journal = {The Prague Bulletin of Mathematical Linguistics},
volume = {93},
pages = {157--166},
year = {2010}
}
</pre>
</font>
</div>
</P>

<h3>2009</h3>

<P><a href="publications/scale-2009-report.pdf">Semantically Informed Machine Translation (SIMT)</a>. Kathy Baker, Steven Bethard, Michael Bloodgood, Ralf Brown, Chris Callison-Burch, Glen Coppersmith, Bonnie Dorr, Wes Filardo, Kendall Giles, Anni Irvine, Mike Kayser, Lori Levin, Justin Martineau, Jim Mayﬁeld, Scott Miller, Aaron Phillips, Andrew Philpot, Christine Piatko, Lane Schwartz and David Zajic.  SCALE 2009 Summer Workshop Final Report.  Tech report for the Human Language Technology Center Of Excellence (HLTCOE).  
<a href="javascript:unhide('abstract/scale-2009-report')">[abstract]</a> 
<a href="javascript:unhide('bib/scale-2009-report')">[bib]</a>
<div id="abstract/scale-2009-report" class="hidden-abstract">
This report describes the findings of the machine translation team from the first Summer Camp for Applied Language Exploration (SCALE) hosted at the Human Language Technology Center of Excellence located at Johns Hopkins University. This intensive, eight week workshop brought together 20 students, faculty and researchers to conduct research on the topic of Semantically Informed Machine Translation (SIMT). The type of semantics that were examined at the SIMT workshop were "High Information Value Elements," or HIVEs, which include named entities (such as people or organizations) and modalities (indications that a statement represents something that has taken place or is a belief or an intention). These HIVEs were examined in the context of machine translation between Urdu and English. The goal of the workshop was to identify and translate HIVEs from the foreign language, and to investigate whether incorporating this sort of structured semantic information into machine translation (MT) systems could produce better translations.
</div>
<div id="bib/scale-2009-report" class="hidden-abstract">
<font size="-2">
<pre>
@techreport{Baker-EtAl:2010:HLTCOE,
    author = {Kathy Baker and Steven Bethard and Michael Bloodgood and Ralf Brown and Chris Callison-Burch and Glen Coppersmith and Bonnie Dorr and Wes Filardo and Kendall Giles and Anni Irvine and Mike Kayser and Lori Levin and Justin Martineau and Jim Mayﬁeld and Scott Miller and Aaron Phillips and Andrew Philpot and Christine Piatko and Lane Schwartz and David Zajic},
    title = {Semantically Informed Machine Translation},
    address = {Human Language Technology Center of Excellence},
    institution = {Johns Hopkins University, Baltimore, MD},
    number = {002},
    url = {http://web.jhu.edu/bin/u/l/HLTCOE-TechReport-002-SIMT.pdf}, 
    year = {2010}
}
</pre>
</font>
</div>
</P>



<P><a href="publications/mechanical-turk-for-machine-translation-evaluation.pdf">Fast, Cheap, and Creative: Evaluating Translation Quality Using Amazon's Mechanical Turk</a>. Chris Callison-Burch, 2009. In Proceedings of EMNLP 2009. 
<a href="javascript:unhide('abstract/mechanical-turk-for-machine-translation-evaluation')">[abstract]</a> 
<a href="javascript:unhide('bib/mechanical-turk-for-machine-translation-evaluation')">[bib]</a>
<a href="javascript:unhide('other/mechanical-turk-for-machine-translation-evaluation')">[NPR]</a>
<div id="abstract/mechanical-turk-for-machine-translation-evaluation" class="hidden-abstract">
Manual evaluation of translation quality is generally thought to be excessively time consuming and expensive. We explore a fast and inexpensive way of doing it using Amazon’s Mechanical Turk to pay small sums to a large number of non-expert annotators. For $10 we redundantly recreate judgments from a WMT08 translation task. We find that when combined non-expert judgments have a high-level of agreement with the existing gold-standard judgments of machine translation quality, and correlate more strongly with expert judgments than Bleu does. We go on to show that Mechanical Turk can be used to calculate human-mediated translation edit rate (HTER), to conduct reading comprehension experiments with machine translation, and to create high quality reference translations.
</div>
<div id="bib/mechanical-turk-for-machine-translation-evaluation" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{callisonburch:2009:EMNLP,
  author    = {Callison-Burch, Chris},
  title     = {Fast, Cheap, and Creative: Evaluating Translation Quality Using {Amazon's} {Mechanical Turk}},
  booktitle = {Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing},
  month     = {August},
  year      = {2009},
  address   = {Singapore},
  publisher = {Association for Computational Linguistics},
  pages     = {286--295},
  url       = {http://www.aclweb.org/anthology/D/D09/D09-1030}
}
</pre>
</font>
</div>
<div id="other/mechanical-turk-for-machine-translation-evaluation" class="hidden-abstract">
<i>I convinced my friend Joel Rose to do <a href="http://marketplace.publicradio.org/display/web/2009/06/30/pm_turking/">a story about Mechanical Turk</a> on NPR's Marketplace. His angle was people supplementing their income in the weak economy.  Next time: translation.  Update: here's Joel's <a href="http://www.npr.org/templates/story/story.php?storyId=127940249">story about crowdsourcing translation</a>.</i>
</div>
</P>


<P><a href="publications/HMERT.pdf">Feasibility of Human-in-the-loop Minimum Error Rate Training</a>. Omar Zaidan and Chris Callison-Burch, 2009.  In Proceedings of EMNLP 2009. 
<a href="javascript:unhide('abstract/HMERT')">[abstract]</a> 
<a href="javascript:unhide('bib/HMERT')">[bib]</a>
<div id="abstract/HMERT" class="hidden-abstract">
Minimum error rate training (MERT) involves choosing parameter values for a machine translation (MT) system that maximize performance on a tuning set as measured by an automatic evaluation metric, such as BLEU. The method is best when the system will eventually be evaluated using the same metric, but in reality, most MT evaluations have a human-based component. Although performing MERT with a human-based metric seems like a daunting task, we describe a new metric, RYPT, which takes human judgments into account, but only requires human input to build a database that can be reused over and over again, hence eliminating the need for human input at tuning time. In this investigative study, we analyze the diversity (or lack thereof) of the candidates produced during MERT, we describe how this redundancy can be used to our advantage, and show that RYPT is a better predictor of translation quality than BLEU.
</div>
<div id="bib/HMERT" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{zaidan-callisonburch:2009:EMNLP,
  author    = {Zaidan, Omar F.  and  Callison-Burch, Chris},
  title     = {Feasibility of Human-in-the-loop Minimum Error Rate Training},
  booktitle = {Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing},
  month     = {August},
  year      = {2009},
  address   = {Singapore},
  publisher = {Association for Computational Linguistics},
  pages     = {52--61},
  url       = {http://www.aclweb.org/anthology/D/D09/D09-1006}
}
</pre>
</font>
</div>
</P>


<P><a href="publications/improved-translation-with-monolingually-derived-paraphrases.pdf">Improved Statistical Machine Translation Using Monolingually-Derived Paraphrases</a>. Yuval Marton, Chris Callison-Burch and Philip Resnik, 2009.  In Proceedings of EMNLP 2009. 
<a href="javascript:unhide('abstract/improved-translation-with-monolingually-derived-paraphrases')">[abstract]</a> 
<a href="javascript:unhide('bib/improved-translation-with-monolingually-derived-paraphrases')">[bib]</a>
<div id="abstract/improved-translation-with-monolingually-derived-paraphrases" class="hidden-abstract">
Untranslated words still constitute a major problem for Statistical Machine Translation (SMT), and current SMT systems are limited by the quantity of parallel training texts. Augmenting the training data with paraphrases generated by pivoting through other languages alleviates this problem, especially for the so-called “low density” languages. But pivoting requires additional parallel texts. We address this problem by deriving paraphrases monolingually, using distributional semantic similarity measures, thus providing access to larger training resources, such as comparable and unrelated monolingual corpora. We present what is to our knowledge the first successful integration of a collocational approach to untranslated words with an end-to-end, state of the art SMT system demonstrating significant translation improvements in a low-resource setting.
</div>
<div id="bib/improved-translation-with-monolingually-derived-paraphrases" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{marton-callisonburch-resnik:2009:EMNLP,
  author    = {Marton, Yuval  and  Callison-Burch, Chris  and  Resnik, Philip},
  title     = {Improved Statistical Machine Translation Using Monolingually-Derived Paraphrases},
  booktitle = {Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing},
  month     = {August},
  year      = {2009},
  address   = {Singapore},
  publisher = {Association for Computational Linguistics},
  pages     = {381--390},
  url       = {http://www.aclweb.org/anthology/D/D09/D09-1040}
}
</pre>
</font>
</div>
</P>


<P><a href="publications/improving-translation-lexicon-induction.pdf"> Improving Translation Lexicon Induction from Monolingual Corpora via Dependency Contexts and Part-of-Speech Equivalences</a>. Nikesh Garera, Chris Callison-Burch and David Yarowsky, 2009.  In Proceedings of the Conference on Natural Language Learning (CoNLL). 
<a href="slides/conll-2009-poster.pdf">[poster]</a>
<a href="javascript:unhide('abstract/improving-translation-lexicon-induction')">[abstract]</a> 
<a href="javascript:unhide('bib/improving-translation-lexicon-induction')">[bib]</a>
<div id="abstract/improving-translation-lexicon-induction" class="hidden-abstract">
This paper presents novel improvements to the induction of translation lexicons from monolingual corpora using multilingual dependency parses. We introduce a dependency-based context model that incorporates long-range dependencies, variable context sizes, and reordering. It provides a 16% relative improvement over the baseline approach that uses a fixed context window of adjacent words. Its Top 10 accuracy for noun translation is higher than that of a statistical translation model trained on a Spanish-English parallel corpus containing 100,000 sentence pairs. We generalize the evaluation to other word-types, and show that the performance can be increased to 18% relative by preserving part-of-speech equivalencies during translation.
</div>
<div id="bib/improving-translation-lexicon-induction" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{garera-callisonburch-yarowsky:2009:CoNLL,
  author    = {Garera, Nikesh  and  Callison-Burch, Chris  and  Yarowsky, David},
  title     = {Improving Translation Lexicon Induction from Monolingual Corpora via Dependency Contexts and Part-of-Speech Equivalences},
  booktitle = {Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL-2009)},
  month     = {June},
  year      = {2009},
  address   = {Boulder, Colorado},
  publisher = {Association for Computational Linguistics},
  pages     = {129--137},
  url       = {http://www.aclweb.org/anthology/W09-1117}
}
</pre>
</font>
</div>
</P>


<P><a href="publications/findings-of-the-wmt09-shared-tasks.pdf">Findings of the 2009 Workshop on Statistical Machine Translation</a>.  Chris Callison-Burch, Philipp Koehn, Christof Monz and  Josh Schroeder, 2009. In Proceedings of WMT. 
<a href="javascript:unhide('abstract/findings-of-wmt09')">[abstract]</a> 
<a href="javascript:unhide('bib/findings-of-wmt09')">[bib]</a>
<div id="abstract/findings-of-wmt09" class="hidden-abstract">
This paper presents the results of the WMT09 shared tasks, which included a translation task, a system combination task, and an evaluation task. We conducted a large-scale manual evaluation of 87 machine translation systems and 22 system combination entries. We used the ranking of these systems to measure how strongly automatic metrics correlate with human judgments of translation quality, for more than 20 metrics. We present a new evaluation technique whereby system output is edited and judged for correctness.
</div>
<div id="bib/findings-of-wmt09" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{callisonburch-EtAl:2009:WMT,
  author    = {Callison-Burch, Chris  and  Koehn, Philipp  and  Monz, Christof  and  Schroeder, Josh},
  title     = {Findings of the 2009 {W}orkshop on {S}tatistical {M}achine {T}ranslation},
  booktitle = {Proceedings of the Fourth Workshop on Statistical Machine Translation},
  month     = {March},
  year      = {2009},
  address   = {Athens, Greece},
  publisher = {Association for Computational Linguistics},
  pages     = {1--28},
  url       = {http://www.aclweb.org/anthology/W09-0401}
}
</pre>
</font>
</div>
</P>

<P><a href="publications/joshua-open-source-toolkit-for-statistical-machine-translation.pdf">Joshua: An Open Source Toolkit for Parsing-based Machine Translation</a>. Zhifei Li, Chris Callison-Burch, Chris Dyer, Juri Ganitkevitch, Sanjeev Khudanpur, Lane Schwartz, Wren Thornton, Jonathan Weese and Omar Zaidan, 2009.  In WMT.
<a href="javascript:unhide('abstract/joshua')">[abstract]</a> 
<a href="javascript:unhide('bib/joshua')">[bib]</a>
<div id="abstract/joshua" class="hidden-abstract">
We describe Joshua, an open source toolkit for statistical machine translation. Joshua implements all of the algorithms required for synchronous context free grammars (SCFGs): chart-parsing, ngram language model integration, beamand cube-pruning, and k-best extraction. The toolkit also implements suffix-array grammar extraction and minimum error rate training. It uses parallel and distributed computing techniques for scalability. We demonstrate that the toolkit achieves state of the art translation performance on the WMT09 French-English translation task.
</div>
<div id="bib/joshua" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{li-EtAl:2009:WMT1,
  author    = {Li, Zhifei  and  Callison-Burch, Chris  and  Dyer, Chris  and  Khudanpur, Sanjeev  and  Schwartz, Lane  and  Thornton, Wren  and  Weese, Jonathan  and  Zaidan, Omar},
  title     = {{Joshua}: An Open Source Toolkit for Parsing-Based Machine Translation},
  booktitle = {Proceedings of the Fourth Workshop on Statistical Machine Translation},
  month     = {March},
  year      = {2009},
  address   = {Athens, Greece},
  publisher = {Association for Computational Linguistics},
  pages     = {135--139},
  url       = {http://www.aclweb.org/anthology/W09-0424}
}
</pre>
</font>
</div>
</P>



<P><a href="publications/decoding-in-joshua.pdf">Decoding in Joshua: Open Source, Parsing-Based Machine Translation</a>. Zhifei Li, Chris Callison-Burch,  Sanjeev Khudanpur, and Wren Thornton, 2009.  In The Prague Bulletin of Mathematical Linguistics (PBML), Number 91, January 2009.
<a href="javascript:unhide('abstract/decoding-in-joshua')">[abstract]</a> 
<a href="javascript:unhide('bib/decoding-in-joshua')">[bib]</a>
<div id="abstract/decoding-in-joshua" class="hidden-abstract">
We describe a scalable decoder for parsing-based machine translation. Thee decoder is written in Java and implements all the essential algorithms described in (Chiang, 2007) and (Li and Khudanpur, 2008b): chart-parsing, n-gram language model integration, beamand cube-pruning, and k-best extraction. Additionally, parallel and distributed computing techniques are exploited to make it scalable. We demonstrate experimentally that our decoder is more than 30 times faster than a baseline decoder written in Python.
</div>
<div id="bib/decoding-in-joshua" class="hidden-abstract">
<font size="-2">
<pre>
@article{Li-EtAl:2010:PBML,
   author = {Lane Schwartz and Chris Callison-Burch },
   title = {Hierarchical Phrase-Based Grammar Extraction in Joshua: Suffix Arrays and Prefix Tree},
   journal = {The Prague Bulletin of Mathematical Linguistics},
   volume = {91},
   pages = {47--56},
   year = {2009}
}
</pre>
</font>
</div>
</P>

<h3>2008</h3>

<P><a href="publications/syntactic-constraints-on-paraphrases.pdf">Syntactic Constraints on Paraphrases Extracted from Parallel Corpora</a>. Chris Callison-Burch, 2008.  In Proceedings of EMNLP 2008. <a href="slides/emnlp-2008-slides.pdf">[slides]</a>  <a href="howto-extract-paraphrases.html">[software]</a>
<a href="javascript:unhide('abstract/syntactic-constraints-on-paraphrases')">[abstract]</a> 
<a href="javascript:unhide('bib/syntactic-constraints-on-paraphrases')">[bib]</a>
<div id="abstract/syntactic-constraints-on-paraphrases" class="hidden-abstract">
We improve the quality of paraphrases extracted from parallel corpora by requiring that phrases and their paraphrases be the same syntactic type. This is achieved by parsing the English side of a parallel corpus and altering the phrase extraction algorithm to extract phrase labels alongside bilingual phrase pairs. In order to retain broad coverage of non-constituent phrases, complex syntactic labels are introduced. A manual evaluation indicates a 19% absolute improvement in paraphrase quality over the baseline method.
</div>
<div id="bib/syntactic-constraints-on-paraphrases" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{callisonburch:2008:EMNLP,
  author    = {Callison-Burch, Chris},
  title     = {Syntactic Constraints on Paraphrases Extracted from Parallel Corpora},
  booktitle = {Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing},
  month     = {October},
  year      = {2008},
  address   = {Honolulu, Hawaii},
  publisher = {Association for Computational Linguistics},
  pages     = {196--205},
  url       = {http://www.aclweb.org/anthology/D08-1021}
}
</pre>
</font>
</div>
</P>

<P><a href="publications/parametric.pdf">ParaMetric: An Automatic Evaluation Metric for Paraphrasing</a>. Chris Callison-Burch, Trevor Cohn, Mirella Lapata, 2008.  In Proceedings of CoLing 2008. <a href="slides/coling-2008-slides.pdf">[slides]</a> <a href="slides/coling-2008-slides.key">[keynote]</a> 
<a href="javascript:unhide('abstract/parametric')">[abstract]</a> 
<a href="javascript:unhide('bib/parametric')">[bib]</a>
<div id="abstract/parametric" class="hidden-abstract">
We present ParaMetric, an automatic evaluation metric for data-driven approaches to paraphrasing. ParaMetric provides an objective measure of quality using a collection of multiple translations whose paraphrases have been manually annotated. ParaMetric calculates precision and recall scores by comparing the paraphrases discovered by automatic paraphrasing techniques against gold standard alignments of words and phrases within equivalent sentences. We report scores for several established paraphrasing techniques.
</div>
<div id="bib/parametric" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{callisonburch-cohn-lapata:2008:Coling,
  author    = {Callison-Burch, Chris  and  Cohn, Trevor  and  Lapata, Mirella},
  title     = {ParaMetric: An Automatic Evaluation Metric for Paraphrasing},
  booktitle = {Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008)},
  month     = {August},
  year      = {2008},
  address   = {Manchester, UK},
  publisher = {Coling 2008 Organizing Committee},
  pages     = {97--104},
  url       = {http://www.aclweb.org/anthology/C08-1013}
}
</pre>
</font>
</div>
</P>

<P><a href="publications/further-meta-evaluation-of-machine-tranlsion.pdf">Further Meta-Evaluation of Machine Translation</a>.  Chris Callison-Burch, Cameron Fordyce, Philipp Koehn, Christof Monz and  Josh Schroeder, 2008. In Proceedings of WMT.  <a href="slides/wmt08-overview-slides.pdf">[slides]</a> 
<a href="javascript:unhide('abstract/findings-of-wmt08')">[abstract]</a> 
<a href="javascript:unhide('bib/findings-of-wmt08')">[bib]</a>
<div id="abstract/findings-of-wmt08" class="hidden-abstract">
This paper analyzes the translation quality of machine translation systems for 10 language pairs translating between Czech, English, French, German, Hungarian, and Spanish. We report the translation quality of over 30 diverse translation systems based on a large-scale manual evaluation involving hundreds of hours of effort. We use the human judgments of the systems to analyze automatic evaluation metrics for translation quality, and we report the strength of the correlation with human judgments at both the system-level and at the sentence-level. We validate our manual evaluation methodology by measuring intra- and inter-annotator agreement, and collecting timing information.<br>
<i>Note: This paper was corrected subsequent to publication.</i>
</div>
<div id="bib/findings-of-wmt08" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{callisonburch-EtAl:2008:WMT,
  author    = {Callison-Burch, Chris  and  Fordyce, Cameron  and  Koehn, Philipp  and  Monz, Christof  and  Schroeder, Josh},
  title     = {Further Meta-Evaluation of Machine Translation},
  booktitle = {Proceedings of the Third Workshop on Statistical Machine Translation},
  month     = {June},
  year      = {2008},
  address   = {Columbus, Ohio},
  publisher = {Association for Computational Linguistics},
  pages     = {70--106},
  url       = {http://www.aclweb.org/anthology/W/W08/W08-0309}
}
</pre>
</font>
</div>
</P>

<P><a href="publications/constructing-corpora-for-paraphrase-systems.pdf">Constructing Corpora for the Development and Evaluation of Paraphrase Systems</a>.  Trevor Cohn, Chris Callison-Burch, Mirella Lapata, 2008. Computational Linguistics.
<a href="javascript:unhide('abstract/constructing-corpora-for-paraphrase-systems')">[abstract]</a> 
<a href="javascript:unhide('bib/constructing-corpora-for-paraphrase-systems')">[bib]</a>
<div id="abstract/constructing-corpora-for-paraphrase-systems" class="hidden-abstract">
Automatic paraphrasing is an important component in many natural language processing tasks. In this paper we present a new parallel corpus with paraphrase annotations. We adopt a definition of paraphrase based on word-alignments and show that it yields high inter-annotator agreement. As Kappa is suited to nominal data, we employ an alternative agreement statistic which is appropriate for structured alignment tasks. We discuss how the corpus can be usefully employed in evaluating paraphrase systems automatically (e.g., by measuring precision, recall and F1) and also in developing linguistically rich paraphrase models based on syntactic structure
</div>
<div id="bib/constructing-corpora-for-paraphrase-systems" class="hidden-abstract">
<font size="-2">
<pre>
@article{cohn-callisonburch-lapata:2008:CL,
  author =  {Trevor Cohn and Chris Callison-Burch and Mirella Lapata},
  title =   {Constructing Corpora for the Development and Evaluation of Paraphrase Systems},
  journal = {Computational Linguistics},
  year =    {2008},
  volume = {34},
  number = {4},
  pages = {597--614}
}
</pre>
</font>
</div>
</P>


<P><a href="publications/graph-laplacian-affinity-measures.pdf">Affinity Measures based on the Graph Laplacian</a>. Delip Rao, David Yarowsky, Chris Callison-Burch, 2008.  In Proceedings of Proceedings of the 3rd Textgraphs workshop on Graph-based Algorithms for Natural Language Processing at CoLing 2008.
<a href="javascript:unhide('abstract/graph-laplacian-affinity-measures')">[abstract]</a> 
<a href="javascript:unhide('bib/graph-laplacian-affinity-measures')">[bib]</a>
<div id="abstract/graph-laplacian-affinity-measures" class="hidden-abstract">
Several language processing tasks can be inherently represented by a weighted graph where the weights are interpreted as a measure of relatedness between two vertices. Measuring similarity between arbitrary pairs of vertices is essential in solving several language processing problems on these datasets. Random walk based measures perform better than other path based measures like shortest-path. We evaluate several random walk measures and propose a new measure based on commute time. We use the psuedo inverse of the Laplacian to derive estimates for commute times in graphs. Further, we show that this pseudo inverse based measure could be improved by discarding the least significant eigenvectors, corresponding to the noise in the graph construction process, using singular value decomposition.
</div>
<div id="bib/graph-laplacian-affinity-measures" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{rao-yarowsky-callisonburch:2008:TG3,
  author    = {Rao, Delip  and  Yarowsky, David  and  Callison-Burch, Chris},
  title     = {Affinity Measures Based on the Graph {L}aplacian},
  booktitle = {Coling 2008: Proceedings of the 3rd Textgraphs workshop on Graph-based Algorithms for Natural Language Processing},
  month     = {August},
  year      = {2008},
  address   = {Manchester, UK},
  publisher = {Coling 2008 Organizing Committee},
  pages     = {41--48},
  url       = {http://www.aclweb.org/anthology/W08-2006}
}
</pre>
</font>
</div>
</P>

<h3>2007</h3>

<P><a href="publications/callison-burch-thesis.pdf">Paraphrasing and Translation</a>. Chris Callison-Burch, 2007.  PhD Thesis, University of Edinburgh. <a href="slides/thesis-defense-slides.pdf">[slides]</a> 
<a href="javascript:unhide('abstract/ccb-phd-thesis')">[abstract]</a> 
<a href="javascript:unhide('bib/ccb-phd-thesis')">[bib]</a>
<div id="abstract/ccb-phd-thesis" class="hidden-abstract">
<p>Paraphrasing and translation have previously been treated as unconnected natural language processing tasks. Whereas translation represents the preservation of meaning when an idea is rendered in the words in a different language, paraphrasing represents the preservation of meaning when an idea is expressed using different words in the same language. We show that the two are intimately related. The major contributions of this thesis are as follows:</p>
<ul>
<li> We define a novel technique for automatically generating paraphrases using bilingual parallel corpora, which are more commonly used as training data for statistical models of translation.</li>
<li> We show that paraphrases can be used to improve the quality of statistical machine translation by addressing the problem of coverage and introducing a degree of generalization into the models.</li>
<li> We explore the topic of automatic evaluation of translation quality, and show that the current standard evaluation methodology cannot be guaranteed to correlate with human judgments of translation quality.</li>
</ul>
<p>Whereas previous data-driven approaches to paraphrasing were dependent upon either data sources which were uncommon such as multiple translation of the same source text, or language specific resources such as parsers, our approach is able to harness more widely parallel corpora and can be applied to any language which has a parallel corpus. The technique was evaluated by replacing phrases with their paraphrases, and asking judges whether the meaning of the original phrase was retained and whether the resulting sentence remained grammatical. Paraphrases extracted from a parallel corpus with manual alignments are judged to be accurate (both meaningful and grammatical) 75% of the time, retaining the meaning of the original phrase 85% of the time. Using automatic alignments, meaning can be retained at a rate of 70%.</p>
<p>Being a language independent and probabilistic approach allows our method to be easily integrated into statistical machine translation. A paraphrase model derived from parallel corpora other than the one used to train the translation model can be used to increase the coverage of statistical machine translation by adding translations of previously unseen words and phrases. If the translation of a word was not learned, but a translation of a synonymous word has been learned, then the word is paraphrased and its paraphrase is translated. Phrases can be treated similarly. Results show that augmenting a state-of-the-art SMT system with paraphrases in this way leads to significantly improved coverage and translation quality. For a training corpus with 10,000 sentence pairs, we increase the coverage of unique test set unigrams from 48% to 90%, with more than half of the newly covered items accurately translated, as opposed to none in current approaches.</p>
</div>
<div id="bib/ccb-phd-thesis" class="hidden-abstract">
<font size="-2">
<pre>
@PhdThesis{callisonburch:2007:thesis,
  author =  {Chris Callison-Burch},
  title =   {Paraphrasing and Translation},
  school = {University of Edinburgh},
  address =   {Edinburgh, Scotland},
  year =    {2007},
  url = {http://cis.upenn.edu/~ccb/publications/callison-burch-thesis.pdf}
}
</pre>
</font>
</div>
</P>


<P><a href="publications/meta-evaluation-of-machine-tranlsion.pdf">(Meta-) Evaluation of Machine Translation</a>. Chris Callison-Burch, Cameron Fordyce, Philipp Koehn, Christof Monz and  Josh Schroeder, 2007.  In Proceedings of WMT.   <a href="slides/wmt07-overview-slides.pdf">[slides]</a> 
<a href="javascript:unhide('abstract/findings-of-wmt07')">[abstract]</a> 
<a href="javascript:unhide('bib/findings-of-wmt07')">[bib]</a>
<div id="abstract/findings-of-wmt07" class="hidden-abstract">
This paper evaluates the translation quality of machine translation systems for 8 language pairs: translating French, German, Spanish, and Czech to English and back. We carried out an extensive human evaluation which allowed us not only to rank the different MT systems, but also to perform higher-level analysis of the evaluation process. We measured timing and intra- and inter-annotator agreement for three types of subjective evaluation. We measured the correlation of automatic evaluation metrics with human judgments. This meta-evaluation reveals surprising facts about the most commonly used methodologies.
</div>
<div id="bib/findings-of-wmt07" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{callisonburch-EtAl:2007:WMT,
  author    = {Callison-Burch, Chris  and  Fordyce, Cameron  and  Koehn, Philipp  and  Monz, Christof  and  Schroeder, Josh},
  title     = {(Meta-) Evaluation of Machine Translation},
  booktitle = {Proceedings of the Second Workshop on Statistical Machine Translation},
  month     = {June},
  year      = {2007},
  address   = {Prague, Czech Republic},
  publisher = {Association for Computational Linguistics},
  pages     = {136--158},
  url       = {http://www.aclweb.org/anthology/W/W07/W07-0718}
}
</pre>
</font>
</div>
</P>

<P><a href="publications/open-source-toolkit-for-statistical-machine-translation.pdf">Open Source Toolkit for Statistical Machine Translation: Factored Translation Models and Confusion Network Decoding</a>. Philipp Koehn, Nicola Bertoldi, Ondrej Bojar, Chris Callison-Burch, Alexandra Constantin, Brooke Cowan, Chris Dyer, Marcello Federico, Evan Herbst, Hieu Hoang, Christine Moran, Wade Shen, and Richard Zens, 2007.  CLSP Summer Workshop Final Report WS-2006, Johns Hopkins University.
<a href="javascript:unhide('abstract/2006-clsp-ws-report')">[abstract]</a> 
<a href="javascript:unhide('bib/2006-clsp-ws-report')">[bib]</a>
<div id="abstract/2006-clsp-ws-report" class="hidden-abstract">
The 2006 Language Engineering Workshop <i>Open Source Toolkit for Statistical Machine Translation</i> had the objective to advance the current state-of-the-art in statistical machine translation through richer input and richer annotation of the training data. The workshop focused on three topics: factored translation models, confusion network decoding, and the development of an open source toolkit that incorporates this advancements. This report describes the scientific goals, the novel methods, and experimental results of the workshop. It also documents details of the implementation of the open source toolkit.
</div>
<div id="bib/2006-clsp-ws-report" class="hidden-abstract">
<font size="-2">
<pre>
@techreport{Koehn-EtAl:2007:CLSP,
   author = { Philipp Koehn and Nicola Bertoldi and Ondrej Bojar and Chris Callison-Burch and Alexandra Constantin and  Brooke Cowan and Chris Dyer and Marcello Federico and Evan Herbst and Hieu Hoang and Christine Moran and Wade Shen and Richard Zens},
   title = {Open Source Toolkit for Statistical Machine Translation: Factored Translation Models and Confusion Network Decoding. },
   institution = {Johns Hopkins University},
   number = {WS-2006},
   type = {CLSP Summer Workshop Final Report},
   year = {2007}
}
</pre>
</font>
</div>
</P>

<P><a href="publications/moses-toolkit.pdf">Moses: Open source toolkit for statistical machine translation</a>. Philipp Koehn, Hieu Hoang,  Alexandra Birch,  Chris Callison-burch,    Marcello Federico,  Nicola Bertoldi,   Brooke Cowan,  Wade Shen,  Christine Moran,  Richard Zens, Chris Dyer, Ondřej Bojar,  Alexandra Constantin,  and Evan Herbst, 2007. In ACL.
<a href="javascript:unhide('abstract/moses')">[abstract]</a> 
<a href="javascript:unhide('bib/moses')">[bib]</a>
<div id="abstract/moses" class="hidden-abstract">
We describe an open-source toolkit for statistical machine translation whose novel contributions are (a) support for linguistically motivated factors, (b) confusion network decoding, and (c) efficient data formats for translation models and language models. In addition to the SMT decoder, the toolkit also includes a wide variety of tools for training, tuning and applying the system to many translation tasks.
</div>
<div id="bib/moses" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{koehn-EtAl:2007:PosterDemo,
  author    = {Koehn, Philipp  and  Hoang, Hieu  and  Birch, Alexandra  and  Callison-Burch, Chris  and  Federico, Marcello  and  Bertoldi, Nicola  and  Cowan, Brooke  and  Shen, Wade  and  Moran, Christine  and  Zens, Richard  and  Dyer, Chris  and  Bojar, Ondrej  and  Constantin, Alexandra  and  Herbst, Evan},
  title     = {Moses: Open Source Toolkit for Statistical Machine Translation},
  booktitle = {Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions},
  month     = {June},
  year      = {2007},
  address   = {Prague, Czech Republic},
  publisher = {Association for Computational Linguistics},
  pages     = {177--180},
  url       = {http://www.aclweb.org/anthology/P07-2045}
}
</pre>
</font>
</div>
</P>

<P><a href="publications/paraphrase-substitution-for-recognizing-textual-entailment.pdf">Paraphrase Substitution for Recognizing Textual Entailment</a>. Wauter Bosma and Chris Callison-Burch, 2007.  In Evaluation of Multilingual and Multimodal Information Retrieval, Lecture Notes in Computer Science, C Peters et al editors.
<a href="javascript:unhide('abstract/paraphrase-substitution-for-rte')">[abstract]</a> 
<a href="javascript:unhide('bib/paraphrase-substitution-for-rte')">[bib]</a>
<div id="abstract/paraphrase-substitution-for-rte" class="hidden-abstract">
We describe a method for recognizing textual entailment that uses the length of the longest common subsequence (LCS) between two texts as its decision criterion. Rather than requiring strict word matching in the common subsequences, we perform a flexible match using automatically generated paraphrases. We find that the use of paraphrases over strict word matches represents an average F-measure improvement from 0.22 to 0.36 on the CLEF 2006 Answer Validation Exercise for 7 languages.
</div>
<div id="bib/paraphrase-substitution-for-rte" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{bosma-callisonburch:2006:CLEF,
  author = {Wauter Bosma and Chris Callison-Burch},
  title = {Paraphrase Substitution for Recognizing Textual Entailment},
  booktitle = {Proceedings of CLEF},
  year = {2006}
  url = {http://cis.upenn.edu/~ccb/publications/paraphrase-substitution-for-recognizing-textual-entailment.pdf}
}
</pre>
</font>
</div>
</P>

<h3>2006</h3>

<P><a href="publications/improved-statistical-machine-translation-using-paraphrases.pdf">Improved Statistical Machine Translation Using Paraphrases</a>. Chris Callison-Burch, Philipp Koehn and Miles Osborne, 2006.  In Proceedings NAACL-2006.  <a href="slides/naacl-2006-slides.pdf">[slides]</a> 
<a href="javascript:unhide('abstract/improved-statistical-machine-translation-using-paraphrases')">[abstract]</a> 
<a href="javascript:unhide('bib/improved-statistical-machine-translation-using-paraphrases')">[bib]</a>
<div id="abstract/improved-statistical-machine-translation-using-paraphrases" class="hidden-abstract">
Parallel corpora are crucial for training SMT systems. However, for many language pairs they are available only in very limited quantities. For these language pairs a huge portion of phrases encountered at run-time will be unknown. We show how techniques from paraphrasing can be used to deal with these otherwise unknown source language phrases. Our results show that augmenting a stateof-the-art SMT system with paraphrases leads to significantly improved coverage and translation quality. For a training corpus with 10,000 sentence pairs we increase the coverage of unique test set unigrams from 48% to 90%, with more than half of the newly covered items accurately translated, as opposed to none in current approaches.
</div>
<div id="bib/improved-statistical-machine-translation-using-paraphrases" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{callisonburch-koehn-osborne:2006:HLT-NAACL06-Main,
  author    = {Callison-Burch, Chris  and  Koehn, Philipp  and  Osborne, Miles},
  title     = {Improved Statistical Machine Translation Using Paraphrases},
  booktitle = {Proceedings of the Human Language Technology Conference of the NAACL, Main Conference},
  month     = {June},
  year      = {2006},
  address   = {New York City, USA},
  publisher = {Association for Computational Linguistics},
  pages     = {17--24},
  url       = {http://www.aclweb.org/anthology/N/N06/N06-1003}
}
</pre>
</font>
</div>
</P>

<P><a href="publications/re-evaluating-the-role-of-bleu-in-mt-research.pdf">Re-evaluating the Role of Bleu in Machine Translation Research</a>. Chris Callison-Burch, Miles Osborne and Philipp Koehn, 2006.  In Proceedings of EACL-2006. <a href="slides/eacl-2006-slides.pdf">[slides]</a> 
<a href="javascript:unhide('abstract/re-evaluating-the-role-of-bleu-in-mt-research')">[abstract]</a> 
<a href="javascript:unhide('bib/re-evaluating-the-role-of-bleu-in-mt-research')">[bib]</a>
<div id="abstract/re-evaluating-the-role-of-bleu-in-mt-research" class="hidden-abstract">
We argue that the machine translation community is overly reliant on the Bleu machine translation evaluation metric. We show that an improved Bleu score is neither necessary nor sufficient for achieving an actual improvement in translation quality, and give two significant counterexamples to Bleu’s correlation with human judgments of quality. This offers new potential for research which was previously deemed unpromising by an inability to improve upon Bleu scores.
</div>
<div id="bib/re-evaluating-the-role-of-bleu-in-mt-research" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{callisonburch-koehn-osborne:2006:HLT-NAACL06-Main,
  author    = {Callison-Burch, Chris  and  Osborne, Miles and  Koehn, Philipp},
  title     = {Re-evaluating the Role of BLEU in Machine Translation Research},
  booktitle = {11th Conference of the European Chapter of the Association for Computational Linguistics},
  month     = {April},
  year      = {2006},
  address   = {Trento, Italy},
  publisher = {Association for Computational Linguistics},
  pages     = {249--256},
  url       = {http://aclweb.org/anthology-new/E/E06/E06-1032}
}
</pre>
</font>
</div>
</P>

<P><a href="publications/constraining-the-phrase-based-joint-probability-model.pdf">Constraining the Phrase-Based, Joint Probability Statistical Translation Model</a>. Alexandra Birch, Chris Callison-Burch and Miles Osborne, 2006.  In Proceedings of WMT06. <a href="slides/amta-2006-slides.pdf">[slides]</a>
<a href="javascript:unhide('abstract/constraining-the-phrase-based-joint-probability-model')">[abstract]</a> 
<a href="javascript:unhide('bib/constraining-the-phrase-based-joint-probability-model')">[bib]</a>
<div id="abstract/constraining-the-phrase-based-joint-probability-model" class="hidden-abstract">
The Joint Probability Model proposed by Marcu and Wong (2002) provides a probabilistic framework for modeling phrase-based statistical machine translation (SMT). The model’s usefulness is, however, limited by the computational complexity of estimating parameters at the phrase level. We present a method of constraining the search space of the Joint Probability Model based on statistically and linguistically motivated word alignments. This method reduces the complexity and size of the Joint Model and allows it to display performance superior to the standard phrase-based models for small amounts of training material.
</div>
<div id="bib/constraining-the-phrase-based-joint-probability-model" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{birch-EtAl:2006:WMT,
  author    = {Birch, Alexandra  and  Callison-Burch, Chris  and  Osborne, Miles  and  Koehn, Philipp},
  title     = {Constraining the Phrase-Based, Joint Probability Statistical Translation Model},
  booktitle = {Proceedings on the Workshop on Statistical Machine Translation},
  month     = {June},
  year      = {2006},
  address   = {New York City},
  publisher = {Association for Computational Linguistics},
  pages     = {154--157},
  url       = {http://www.aclweb.org/anthology/W/W06/W06-3123}
}
</pre>
</font>
</div>
</P>

<h3>2005</h3>

<P><a href="publications/scaling-phrase-based-statistical-machine-translation.pdf">Scaling Phrase-Based Statistical Machine Translation to Larger Corpora and Longer Phrases</a>. Chris Callison-Burch, Colin Bannard and Josh Schroeder, 2005.  In Proceedings of ACL-2005. <a href="slides/acl-2005-slides.pdf">[slides]</a>
<a href="javascript:unhide('abstract/scaling-phrase-based-statistical-machine-translation')">[abstract]</a> 
<a href="javascript:unhide('bib/scaling-phrase-based-statistical-machine-translation')">[bib]</a>
<div id="abstract/scaling-phrase-based-statistical-machine-translation" class="hidden-abstract">
In this paper we describe a novel data structure for phrase-based statistical machine translation which allows for the retrieval of arbitrarily long phrases while simultaneously using less memory than is required by current decoder implementations. We detail the computational complexity and average retrieval times for looking up phrase translations in our suffix array-based data structure. We show how sampling can be used to reduce the retrieval time by orders of magnitude with no loss in translation quality.
</div>
<div id="bib/scaling-phrase-based-statistical-machine-translation" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{callisonburch-bannard-schroeder:2005:ACL,
  author    = {Callison-Burch, Chris  and  Bannard, Colin  and  Schroeder, Josh},
  title     = {Scaling Phrase-Based Statistical Machine Translation to Larger Corpora and Longer Phrases},
  booktitle = {Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL'05)},
  month     = {June},
  year      = {2005},
  address   = {Ann Arbor, Michigan},
  publisher = {Association for Computational Linguistics},
  pages     = {255--262},
  url       = {http://www.aclweb.org/anthology/P05-1032},
}
</pre>
</font>
</div>
</P>

<P><a href="publications/paraphrasing-with-bilingual-parallel-corpora.pdf">Paraphrasing with Bilingual Parallel Corpora</a>. Colin Bannard and Chris Callison-Burch, 2005.  In Proceedings of ACL-2005. <a href="slides/paraphrasing-and-translation-2007.pdf">[slides]</a> 
<a href="javascript:unhide('abstract/paraphrasing-with-bilingual-parallel-corpora')">[abstract]</a> 
<a href="javascript:unhide('bib/paraphrasing-with-bilingual-parallel-corpora')">[bib]</a>
<div id="abstract/paraphrasing-with-bilingual-parallel-corpora" class="hidden-abstract">
Previous work has used monolingual parallel corpora to extract and generate paraphrases. We show that this task can be done using bilingual parallel corpora, a much more commonly available resource. Using alignment techniques from phrase-based statistical machine translation, we show how paraphrases in one language can be identified using a phrase in another language as a pivot. We define a paraphrase probability that allows paraphrases extracted from a bilingual parallel corpus to be ranked using translation probabilities, and show how it can be refined to take contextual information into account. We evaluate our paraphrase extraction and ranking methods using a set of manual word alignments, and contrast the quality with paraphrases extracted from automatic alignments.
</div>
<div id="bib/paraphrasing-with-bilingual-parallel-corpora" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{bannard-callisonburch:2005:ACL,
  author    = {Bannard, Colin  and  Callison-Burch, Chris},
  title     = {Paraphrasing with Bilingual Parallel Corpora},
  booktitle = {Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL'05)},
  month     = {June},
  year      = {2005},
  address   = {Ann Arbor, Michigan},
  publisher = {Association for Computational Linguistics},
  pages     = {597--604},
  url       = {http://www.aclweb.org/anthology/P05-1074},
}
</pre>
</font>
</div>
</P>

<P><a href="publications/compact-data-structure-for-searchable-translation-memories.pdf">A Compact Data Structure for Searchable Translation Memories</a>. Chris Callison-Burch, Colin Bannard and Josh Schroeder, 2005.  In Proceedings of EAMT-2005. <a href="slides/eamt-2005-slides.pdf">[slides]</a>
<a href="javascript:unhide('abstract/compact-data-structure-for-searchable-translation-memories')">[abstract]</a> 
<a href="javascript:unhide('bib/compact-data-structure-for-searchable-translation-memories')">[bib]</a>
<div id="abstract/compact-data-structure-for-searchable-translation-memories" class="hidden-abstract">
In this paper we describe searchable translation memories, which allow translators to search their archives for possible translations of phrases. We describe how statistical machine translation can be used to align sub-sentential units in a translation memory, and rank them by their probability. We detail a data structure that allows for memory-efficient storage of the index. We evaluate the accuracy of translations retrieved from a searchable translation memory built from 50,000 sentence pairs, and find a precision of 86.6% for the top ranked translations.
</div>
<div id="bib/compact-data-structure-for-searchable-translation-memories" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{callison-burch-EtAl:2005:EAMT,
  author =  {Chris Callison-Burch and Colin Bannard and Josh Schroeder},
  title =           {A Compact Data Structure for Searchable Translation Memories},
    booktitle = {European Association for Machine Translation}, 
year =  {2005}
}
</pre>
</font>
</div>
</P>

<P><a href="publications/linear-b-system-description-for-nist-mt-eval-2005.pdf">Linear B System Description for the 2005 NIST MT Evaluation Exercise</a>. Chris Callison-Burch, 2005.  In Proceedings of Machine Translation Evaluation Workshop.  <a href="slides/nist-2005-slides.pdf">[slides]</a>
<a href="javascript:unhide('abstract/linear-b-system-description-for-nist-mt-eval-2005')">[abstract]</a> 
<a href="javascript:unhide('bib/linear-b-system-description-for-nist-mt-eval-2005')">[bib]</a>
<div id="abstract/linear-b-system-description-for-nist-mt-eval-2005" class="hidden-abstract">
This document describes Linear B’s entry for the 2005 NIST MT Evaluation exercise. Linear B examined the efficacy of human-aided statistical machine translation by looking at the improvements that could be had by involving non-Arabic speakers in the translation process. We examined two conditions: one in which non-Arabic speakers edited the output of a statistical machine translation system, and one in which they were allowed to select phrasal translations from a chart of possible translations for an Arabic sentence, and then edit the text.
</div>
<div id="bib/linear-b-system-description-for-nist-mt-eval-2005" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{callisonburch:2005:NIST,
  author =  {Chris Callison-Burch },
  title =           {A Compact Data Structure for Searchable Translation Memories},
    booktitle = {Proceedings of Machine Translation Evaluation Workshop}, 
year =  {2005}
}
</pre>
</font>
</div>
</P>

<P><a href="publications/iwslt05-report.pdf">Edinburgh System Description for the 2005 IWSLT Speech Translation Evaluation</a>. Philipp Koehn, Amittai Axelrod, Alexandra Birch Mayne, Chris Callison-Burch, Miles Osborne, and David Talbot, 2005.  In IWSLT. 
<a href="javascript:unhide('abstract/iwslt05-lexicalized-reordering-models')">[abstract]</a> 
<a href="javascript:unhide('bib/iwslt05-lexicalized-reordering-models')">[bib]</a>
<div id="abstract/iwslt05-lexicalized-reordering-models" class="hidden-abstract">
Our participation in the IWSLT 2005 speech translation task is our first effort to work on limited domain speech data. We adapted our statistical machine translation system that performed successfully in previous DARPA competitions on open domain text translations. We participated in the supplied corpora transcription track. We achieved the highest BLEU score in 2 out of 5 language pairs and had competitive results for the other language pairs.
</div>
<div id="bib/iwslt05-lexicalized-reordering-models" class="hidden-abstract">
<font size="-2">
<pre>
@InProceedings{Koehn-EtAl:2005:IWSLT,
  author =  {Philipp Koehn and Amittai Axelrod and Alexandra Birch and Chris Callison-Burch and Miles Osborne and David Talbot and Michael White},
  title =           {Edinburgh System Description for the 2005 {IWSLT} Speech Translation Evaluation},
    booktitle = {Proceedings of International Workshop on Spoken Language Translation},
year =  {2005},
  url = {http://cis.upenn.edu/~ccb/publications/iwslt05-report.pdf}
}
</pre>
</font>
</div>
</P>

<h3>2004</h3>

<P><A HREF="publications/smt-with-word-and-sentence-aligned-parallel-corpora.pdf">Statistical Machine Translation with Word- and Sentence-Aligned Parallel Corpora</A>. Chris Callison-Burch, David Talbot and Miles Osborne, 2004.  In Proceedings of ACL-2004.  <a href="slides/acl-2004-slides.pdf">[slides]</a>
<a href="javascript:unhide('abstract/smt-with-word-and-sentence-aligned-parallel-corpora')">[abstract]</a> 
<a href="javascript:unhide('bib/smt-with-word-and-sentence-aligned-parallel-corpora')">[bib]</a>
<div id="abstract/smt-with-word-and-sentence-aligned-parallel-corpora" class="hidden-abstract">
The parameters of statistical translation models are typically estimated from sentence-aligned parallel corpora. We show that significant improvements in the alignment and translation quality of such models can be achieved by additionally including word-aligned data during training. Incorporating word-level alignments into the parameter estimation of the IBM models reduces alignment error rate and increases the Bleu score when compared to training the same models only on sentence-aligned data. On the Verbmobil data set, we attain a 38% reduction in the alignment error rate and a higher Bleu score with half as many training examples. We discuss how varying the ratio of word-aligned to sentence-aligned data affects the expected performance gain.
</div>
<div id="bib/smt-with-word-and-sentence-aligned-parallel-corpora" class="hidden-abstract">
<font size="-2">
<pre>
@inproceedings{callisonburch-talbot-osborne:2004:ACL,
  author    = {Callison-Burch, Chris  and  Talbot, David  and  Osborne, Miles},
  title     = {Statistical Machine Translation with Word- and Sentence-Aligned Parallel Corpora},
  booktitle = {Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL'04), Main Volume},
  year      = {2004},
  month     = {July},
  address   = {Barcelona, Spain},
  pages     = {175--182},
  url       = {http://www.aclweb.org/anthology/P04-1023},
}
</pre>
</font>
</div>
</P>

<P><A HREF="publications/searchable-translation-memories.pdf">Searchable Translation Memories</A>. Chris Callison-Burch, Colin Bannard and Josh Schroeder, 2004. In Proceedings of ASLIB Translating and the Computer.  
<a href="slides/aslib-2004-slides.pdf">[slides]</a>
<a href="javascript:unhide('abstract/searchable-translation-memories')">[abstract]</a> 
<a href="javascript:unhide('bib/searchable-translation-memories')">[bib]</a>
<div id="abstract/searchable-translation-memories" class="hidden-abstract">
In this paper we introduce a technique for creating searchable translation memories. Linear B’s searchable translation memories allow a translator to type in a phrase and retrieve a ranked list of possible translations for that phrase, which is ordered based on the likelihood of the translations. The searchable translation memories use translation models similar to those used in statistical machine translation. In this paper we first describe the technical details of how the TMs are indexed and how translations are assigned probabilities, and then evaluate a searchable TM using precision and recall metrics.
</div>
<div id="bib/searchable-translation-memories" class="hidden-abstract">
<font size="-2">
<pre>
@inproceedings{Callison-Burch:2004:ASLIB,
 author =  {Chris Callison-Burch and Colin Bannard and Josh Schroeder},
    title = {Searchable Translation Memories},
    booktitle = {Proceedings of ASLIB Translating and the Computer 26}, 
    year = {2004}
}
</pre>
</font>
</div>
</P>

<P><A HREF="publications/improved-smt-through-editing.pdf">Improved Statistical Translation Through Editing</A>. Chris Callison-Burch, Colin Bannard and Josh Schroeder, 2004.   In EAMT.
<a href="javascript:unhide('abstract/improved-smt-through-editing')">[abstract]</a> 
<a href="javascript:unhide('bib/improved-smt-through-editing')">[bib]</a>
<div id="abstract/improved-smt-through-editing" class="hidden-abstract">
In this paper we introduce Linear B’s statistical machine translation system. We describe how Linear B’s phrase-based translation models are learned from a parallel corpus, and show how the quality of the translations produced by our system can be improved over time through editing. There are two levels at which our translations can be edited. The first is through a simple correction of the text that is produced by our system. The second is through a mechanism which allows an advanced user to examine the sentences that a particular translation was learned from. The learning process can be improved by correcting which phrases in the sentence should be considered translations of each other.
</div>
<div id="bib/improved-smt-through-editing" class="hidden-abstract">
<font size="-2">
<pre>
@inproceedings{Callison-Burch-EtAl:2004:EAMT,
 author =  {Chris Callison-Burch and Colin Bannard and Josh Schroeder},
    title = {Improved Statistical Translation Through Editing},
    booktitle = {European Association for Machine Translation}, 
    year = {2004}
}
</pre>
</font>
</div>
</P>

<h3>2003</h3>

<P><A HREF = "publications/statistical-natural-language-processing-chapter.pdf">Statistical Natural Language Processing</A>. Chris Callison-Burch and Miles Osborne, 2003. In A Handbook for Language Engineers, Ali Farghaly, Editor.
<a href="javascript:unhide('abstract/statistical-natural-language-processing-chapter')">[abstract]</a> 
<a href="javascript:unhide('bib/statistical-natural-language-processing-chapter')">[bib]</a>
<div id="abstract/statistical-natural-language-processing-chapter" class="hidden-abstract">
<p>Statistical natural language processing (SNLP) is a field lying in the intersection of natural language processing and machine learning. SNLP differs from traditional natural language processing in that instead of having a linguist manually construct some model of a given linguistic phenomenon, that model is instead (semi-) automatically constructed from linguistically annotated resources. Methods for assigning partof-speech tags to words, categories to texts, parse trees to sentences, and so on, are (semi-) automatically acquired using machine learning techniques.</p>
<p>The recent trend of applying statistical techniques to natural language processing came largely from industrial speech recognition research groups at AT&T's Bell Laboratories and IBM's T.J. Watson Research Center. Statistical techniques in speech recognition have so vastly outstripped the performance of their non-statistical counterparts that rule-based speech recognition systems are essentially no longer an area of research. The success of machine learning techniques in speech processing led to an interest in applying them to a broader range of NLP applications. In addition to being useful from the perspective of producing high-quality results, as in speech recognition, SNLP systems are useful for a number of practical reasons. They are cheap and fast to produce, and they handle the wide variety of input required by a real-world application. SNLP is therefore especially useful in industry. In particular:</p>
<ul>
<li>SNLP affords rapid prototyping. Whereas fully hand-crafted systems are extremely time consuming to build, statistical systems that are automatically trained using corpora can be produced more quickly. This allows many different approaches to be tried and evaluated in a short time-frame. As an example, Cucerzan and Yarowsky described how one might create a new part-of-speech tagger in a single day (Cucerzan and Yarowsky, 2002). An even more ambitious example is Al-Onaizan et al.'s "machine translation in a day" experiment wherein they used statistical techniques to develop a complete Chinese-English machine translation system in a 24-hour period (AlOnaizan et al., 1999).</li>
<li>Statistical systems are "robust" (Junqua and van Noord, 2001). Although this has a wide variety of meanings, in SNLP it generally means that a system will always produce some output no matter how badly formed the input is, and no matter how novel it is. For example, a text classification system may be able to classify a text even if all of the words in that text are previously unseen. Handling all kinds of input is necessary in real-world applications; a system which fails to produce output when it is unable to analyze a sentence will not be useful.</li>
<li>Statistical systems are often cheaper to produce than hand-crafted rule-based systems. Because the process of creating a statistical system is more automated than the process of creating a rule-based system, the actual number of participants needed to create a system will often be less. Furthermore, because they are learned from data, statistical systems require less knowledge of the particular language being analyzed. This becomes a budgetary issue on a multi-language project because of the expense of hiring language consultants or staff with specialized skills.</li>
</ul>
<p>A common theme with many early SNLP systems was a pride in minimizing the amount of linguistic knowledge used in the system. For example, Fred Jelinek, the then leader of IBM's speech recognition research group, purportedly said, "Every time I fire a linguist, my performance goes up." The sentiment is rather shocking. Should Jelinek's statement strike fear into the hearts of all linguists reading this chapter? Is there a strong opposition between theoretical linguistics and SNLP? Will SNLP put linguists out of work?</p>
<p>We put forth a positive answer in this chapter: there is a useful role for linguistic expertise in statistical systems. Jelinek's infamous quote represents biases of the early days of SNLP. While a decade's worth of research has shown that SNLP can be an extremely powerful tool and is able to produce impressive results, recent trends indicate that using naive approaches that are divorced from linguistics can only go so far. There is therefore a revival of interest in integrating more sophisticated linguistic information into statistical models. For example, language models for speech recognition are moving from being word-based "ngram" models towards incorporating statistical grammars (Chelba and Jelinek, 1998, Charniak, 2001). So there is indeed a role for the linguist. This chapter will provide an entry point for linguists entering into the field of SNLP so that they may apply their expertise to enhance an already powerful approach to natural language processing.</p>
<p>Lest we represent SNLP as a completely engineering-oriented discipline, we point the interested reader to Abney (1996) which describes a number of ways in which SNLP might inform academic topics in linguistics. For example, SNLP can be useful for psycholinguistic research since systems typically encode graduated notions of well-formedness. This offers a more psychologically plausible alternative to the traditional binary grammatical/ungrammatical distinction. In a similarly academic vein, Johnson (1998) shows how Optimality Theory can be interpreted in terms of statistical models. This in turn suggests a number of interesting directions that OT might take.</p>
<p>The rest of this chapter is as follows: We begin by presenting a simple worked example designed to illustrate some of the aspects of SNLP in Section 1.2. After motivating the usefulness of SNLP, we then move onto the core methods used in SNLP: modeling, learning, data and evaluation (Sections 1.3, 1.4, 1.5, and 1.6 respectively). These core methods are followed by a brief review of some of the many applications of SNLP (Section 1.7). We conclude with a discussion (Section 1.8) where we make some comments about the current state of SNLP and possible future directions it might take.</p>
</div>
<div id="bib/statistical-natural-language-processing-chapter" class="hidden-abstract">
<font size="-2">
<pre>
@incollection{Callison-Burch2003b,
author = {Chris Callison-Burch and Miles Osborne},
title = {Statistical Natural Language Processing},
booktitle = {A Handbook for Language Engineers},
editor = {Ali Farghaly},
publisher = {CSLI},
year = {2003}
}
</pre>
</font>
</div>
</P>

<P><A HREF="publications/bootstrapping-parallel-corpora.pdf">Bootstrapping Parallel Corpora</A>. Chris Callison-Burch and Miles Osborne, 2003. In NAACL workshop Building and Using Parallel Texts. <a href="slides/naacl-2003-slides.pdf">[slides]</a>
<a href="javascript:unhide('abstract/bootstrapping-parallel-corpora')">[abstract]</a> 
<a href="javascript:unhide('bib/bootstrapping-parallel-corpora')">[bib]</a>
<div id="abstract/bootstrapping-parallel-corpora" class="hidden-abstract">
We present two methods for the automatic creation of parallel corpora. Whereas previous work into the automatic construction of parallel corpora has focused on harvesting them from the web, we examine the use of existing parallel corpora to bootstrap data for new language pairs. First, we extend existing parallel corpora using co-training, wherein machine translations are selectively added to training corpora with multiple source texts. Retraining translation models yields modest improvements. Second, we simulate the creation of training data for a language pair for which a parallel corpus is not available. Starting with no human translations from German to English we produce a German to English translation model with 45% accuracy using parallel corpora in other languages. This suggests the method may be useful in the creation of parallel corpora for languages with scarce resources.
</div>
<div id="bib/bootstrapping-parallel-corpora" class="hidden-abstract">
<font size="-2">
<pre>
@inproceedings{CallisonBurch-Osborne:2003:PARALLEL,
  author = {Callison-Burch, Chris  and  Osborne, Miles},
  title  = {Bootstrapping Parallel Corpora},
  booktitle = {Proceedings of the HLT-NAACL 2003 Workshop on Building and Using Parallel Texts: Data Driven Machine Translation and Beyond},
  editor = {Rada Mihalcea and Ted Pedersen},
  url    = {http://www.aclweb.org/anthology/W03-0310},
  year   = 2003,
  pages  = {44--49}
}
</pre>
</font>
</div>
</P>

<P><A HREF = "publications/co-training-for-smt.pdf">Co-training for Statistical Machine Translation</A>. Chris Callison-Burch and Miles Osborne, 2003.   In Proceedings of the 6th Annual CLUK Research Colloquium.
<a href="javascript:unhide('abstract/co-training-for-smt')">[abstract]</a> 
<a href="javascript:unhide('bib/co-training-for-smt')">[bib]</a>
<div id="abstract/co-training-for-smt" class="hidden-abstract">
We present a novel co-training method for statistical machine translation. Since cotraining requires independent views on the data, with each view being sufficient for the labeling task, we use source strings in multiple languages as views on translation. Co-training for statistical machine translation is therefore a type of multi-source translation. We show that using five language pairs our approach can yield improvements of up to 2.5% in word error rates for translation models. Our experiments suggest that co-training is even more effective for languages with highly impoverished parallel corpora: starting with no human translations from German to English we produce a German to English translation model with 45% accuracy using parallel corpora in other languages.
</div>
<div id="bib/co-training-for-smt" class="hidden-abstract">
<font size="-2">
<pre>
@inproceedings{CallisonBurch-Osborne:2003:CLUK,
  author = {Callison-Burch, Chris  and  Osborne, Miles},
  title  = {Co-Training For Statistical Machine Translation},
  booktitle = {Proceedings of the 6th Annual CLUK Research Colloquium},
  year   = {2003}
}
</pre>
</font>
</div>
</P>

<P><A HREF = "publications/evaluating-question-answering-systems-using-faq-answer-injection.pdf">Evaluating Question Answering Systems Using FAQ Answer Injection</A>.  Jochen Leidner and Chris Callison-Burch, 2003. In Proceedings of the 6th Annual CLUK Research Colloquium.
<a href="javascript:unhide('abstract/evaluating-question-answering-systems-using-faq-answer-injection')">[abstract]</a> 
<a href="javascript:unhide('bib/evaluating-question-answering-systems-using-faq-answer-injection')">[bib]</a>
<div id="abstract/evaluating-question-answering-systems-using-faq-answer-injection" class="hidden-abstract">
Question answering (NLQA) systems which retrieve a textual fragment from a document collection that represents the answer to a question are an active field of research. But evaluations currently involve a large amount of manual effort. We propose a new evaluation scheme that uses the insertion of answers from Frequently Asked Questions collections (FAQs) to measure the ability of a system to retrieve it from the corresponding question. We describe how the usefulness of the approach can be assessed and discuss advantages and problems.
</div>
<div id="bib/evaluating-question-answering-systems-using-faq-answer-injection" class="hidden-abstract">
<font size="-2">
<pre>
@inproceedings{Leidner-CallisonBurch:2003:CLUK,
  author = {Jochen L. Leidner and Chris Callison-Burch},
  title  = {Evaluating Question Answering Systems Using FAQ Answer Injection},
  booktitle = {Proceedings of the 6th Annual CLUK Research Colloquium},
  year   = {2003}
}
</pre>
</font>
</div>
</P>

<h3>2002</h3>

<P><A HREF = "publications/msc-thesis.pdf">Co-Training for Statistical Machine Translation</A>.   Chris Callison-Burch, 2002. Master's thesis, School of Informatics, University of Edinburgh. <a href="slides/naacl-2003-slides.pdf">[slides]</a>
<a href="javascript:unhide('abstract/msc-thesis')">[abstract]</a> 
<a href="javascript:unhide('bib/msc-thesis')">[bib]</a>
<div id="abstract/msc-thesis" class="hidden-abstract">
I propose a novel co-training method for statistical machine translation. As co-training requires multiple learners trained on views of the data which are disjoint and sufficient for the labeling task, I use multiple source documents as views on translation. Co-training for statistical machine translation is therefore a type of multi-source translation. Unlike previous mutli-source methods, it improves the overall quality of translations produced by a model, rather than single translations. This is achieved by augmenting the parallel corpora on which the statistical translation models are trained. Experiments suggest that co-training is especially effective for languages with highly impoverished parallel corpora.
</div>
<div id="bib/msc-thesis" class="hidden-abstract">
<font size="-2">
<pre>
@MastersThesis{Callison-Burch2002,
  author =       {Chris Callison-Burch},
  title =        {Co-training for Statistical Machine Translation},
  school =       {University of Edinburgh},
  year =         {2002}
}
</pre>
</font>
</div>
</P>

<h3>2001</h3>

<P><A HREF = "publications/upping-the-ante.pdf">Upping the Ante for "Best of Breed" Machine Translation Providers</A>. Chris Callison-Burch, 2001.    In Proceedings of ASLIB Translating and the Computer.
<a href="javascript:unhide('abstract/upping-the-ante')">[abstract]</a> 
<a href="javascript:unhide('bib/upping-the-ante')">[bib]</a>
<div id="abstract/upping-the-ante" class="hidden-abstract">
The notion of "best of breed" among value-added machine translation technology providers is generally defined as providing access to the single best commercially available machine translation engine for each language pair. This paper describes the efforts of Amikai, Inc. to go beyond that definition of best of breed. Rather than relying on a single engine for each pair, we have written a program that automatically selects the best translation from a set of candidate translations generated by multiple commercial machine translation engines. The program is implemented using a simple statistical language modelling technique, and relies on the simplifying assumption that the most fluent item in the set is the best translation. The program was able to produce the best translation in human ranked data up to 19% more often than the single best performing engine.
</div>
<div id="bib/upping-the-ante" class="hidden-abstract">
<font size="-2">
<pre>
@inproceedings{Callison-Burch:2001:ASLIB,
  title =               {Upping the Ante for "Best of Breed" Machine Translation Providers},
  author =              {Chris Callison-Burch},
  booktitle =   {Proceedings of ASLIB Translating and the Computer 23},
  year =                {2001},
}
</pre>
</font>
</div>
</P>

<P><A HREF = "publications/multi-engine-mt-with-language-models.pdf">A program for automatically selecting the best output from multiple machine translation engines</A>. Chris Callison-Burch and Raymond Flournoy, 2001.   In Proceedings of MT Summit.
<a href="javascript:unhide('abstract/multi-engine-mt-with-language-models')">[abstract]</a> 
<a href="javascript:unhide('bib/multi-engine-mt-with-language-models')">[bib]</a>
<div id="abstract/multi-engine-mt-with-language-models" class="hidden-abstract">
This paper describes a program that automatically selects the best translation from a set of translations produced by multiple commercial machine translation engines. The program is simplified by assuming that the most fluent item in the set is the best translation. Fluency is determined using a trigram language model. Results are provided illustrating how well the program performs for human ranked data as compared to each of its constituent engines.
</div>
<div id="bib/multi-engine-mt-with-language-models" class="hidden-abstract">
<font size="-2">
<pre>
@inproceedings{Callison-Burch-Flournoy:2001:MTSummit,
  title =               {A Program for Automatically Selecting the Best Output from Multiple Machine Translation Engines},
  author =              {Chris Callison-Burch and Raymond S. Flournoy},
  booktitle =   {Proceedings of the Machine Translation Summit VIII},
  year =                {2001},
}
</pre>
</font>
</div>
</P>

<P> <A HREF = "publications/secondary-benefits-of-user-feedback-in-mt.pdf">Secondary Benefits of Feedback and User Interaction in Machine Translation Tools</A>.  Raymond Flournoy and Chris Callison-Burch, 2001.  MT Summit Workshop.
<a href="javascript:unhide('abstract/secondary-benefits-of-user-feedback-in-mt')">[abstract]</a> 
<a href="javascript:unhide('bib/secondary-benefits-of-user-feedback-in-mt')">[bib]</a>
<div id="abstract/secondary-benefits-of-user-feedback-in-mt" class="hidden-abstract">
User feedback has often been proposed as a method for improving the accuracy of machine translation systems, but useful feedback can also serve a number of secondary benefits, including increasing user confidence in the MT technology and expanding the potential audience of users. Amikai, Inc. has produced a number of communication tools which embed translation technology and which attempt to improve the user experience by maximizing useful user interaction and feedback. As MT continues to develop, further attention needs to be paid to developing the overall user experience, which can improve the utility of translation tools even when translation quality itself plateaus
</div>
<div id="bib/secondary-benefits-of-user-feedback-in-mt" class="hidden-abstract">
<font size="-2">
<pre>
@inproceedings{Flournoy-Callison-Burch:2001:MTSummit,
  title =               {Secondary Benefits of Feedback and User Interaction in Machine Translation Tools},
  author =              {Raymond S. Flournoy and Chris Callison-Burch},
  booktitle =   {Workshop paper for "MT2010: Towards a Roadmap for MT" of the MT Summit VIII},
  year =                {2001},
}
</pre>
</font>
</div>
</P>

<h3>2000</h3>

<P><A HREF = "publications/computer-model-of-a-grammar-for-english-questions.pdf">A Computer Model of a Grammar for English Questions</A>.  Chris Callison-Burch, 2000. Undergraduate thesis, Symbolic Systems Program, Stanford University. 

My undergraduate advisor was <a href="http://lingo.stanford.edu/sag/">Ivan Sag</a>. <a href="slides/undergraduate-thesis-handout.pdf">[handout]</a>
<a href="javascript:unhide('abstract/computer-model-of-a-grammar-for-english-questions')">[abstract]</a> 
<a href="javascript:unhide('bib/computer-model-of-a-grammar-for-english-questions')">[bib]</a>
<div id="abstract/computer-model-of-a-grammar-for-english-questions" class="hidden-abstract">
This document describes my senior honors project, which is an implementation of a grammar for English questions. I have created a computer model of Ginzburg and Sag’s theory of English interrogative constructions using the parsing software developed at the Center for Study of Language and Information (CSLI). In this chapter I describe the LKB parsing software, give instructions on downloading the system, and comment on the process of grammar engineering. The next chapter gives a summary of Ginzburg and Sag (2000). Chapter 3 details the discrepancies between the Ginzburg and Sag theory and my implementation. Chapter 4 provides a detailed discussion of a set of key example sentences. The appendices contain tables describing all the grammar constructions, lexical rules, types, and example lexical entries used in my implementation.
</div>
<div id="bib/computer-model-of-a-grammar-for-english-questions" class="hidden-abstract">
<font size="-2">
<pre>
@MISC{Callison-Burch2000,
  author =  {Chris Callison-Burch},
  title =   {A Computer Model of a Grammar for English Questions},
  school = {Stanford University},
  address =   {Palo Alto, California},
  note = {Undergraduate honors thesis},
  year =    {2000}
}
</pre>
</font>
</div>
</P>

  </p>
  </div>
	  <div id="news">
<div id="contentcenter"><h2>Grants</h2></div>

		<p>
<img src="include/images/darpa-logo.jpg" width="100" border="0"  /><br />
DARPA DEFT: Large-Scale Paraphrasing for Natural Language Understanding</p> 

		<p><a href="http://nsf.gov/awardsearch/showAward.do?AwardNumber=1430651">
<img src="include/images/NSF-logo.jpg" width="100" border="0"  /><br />
EAGER: Simplification as Machine Translation </a></p> 






<div id="contentcenter"><h2>Past Grants</h2></div>
		<p>
<img src="include/images/darpa-logo.jpg" width="100" border="0"  /><br />
Computer Science Study Group phase 3: "Crowdsourcing Translation"</p> 



		<p><a href="http://nsf.gov/awardsearch/showAward.do?AwardNumber=1249516">
<img src="include/images/NSF-logo.jpg" width="100" border="0"  /><br />
EAGER: Combining natural language inference and data-driven paraphrasing </a></p> 




		<p><a href="http://web.jhu.edu/hltcoe">
<img src="include/images/hltcoe-logo1.jpg" width="100" border="0"  /><br />
Head of machine translation research at the HLTCOE</a></p> 

	<p>
<a href="http://www.vulcan.com/TemplateCompany.aspx?contentId=65"><img src="include/images/vulcan-logo.gif" width="100" border="0"  /></a><br />
Acquisition and use of paraphrases in a knowledge-rich setting</a></p> 


	
    <p><img src="include/images/bbn-logo.jpg" width="100" border="0"  /><br />
Crowdsourcing Arabic Dialects
</p> 




		<p>
<img src="include/images/darpa-logo.jpg" width="100" border="0"  /><br />
Computer Science Study Group phase 2: "BABEL: Bayesian Architecture Begetting Every Language"</p> 




		<p><a href="http://nsf.gov/awardsearch/showAward.do?AwardNumber=0713448">
<img src="include/images/NSF-logo.jpg" width="100" border="0"  /><br />
Multi-level modeling of language and translation </a></p> 



		<p><a href="http://cordis.europa.eu/search/index.cfm?fuseaction=proj.document&PJ_LANG=EN&PJ_RCN=10391532">
<img src="include/images/EMPlus-logo.png" width="100" border="0"  /><br />
EuroMatrixPlus: Bringing machine translation for European languages to the user  </a></p> 



		<p><img src="include/images/bbn-logo.jpg" width="100" border="0"  /><br />
Translation of informal texts via Mechanical Turk
</p> 

		<p><a href="http://www.darpa.mil/ipto/programs/gale/gale.asp">
<img src="include/images/darpa-logo.jpg" width="100" border="0"  /><br />
Global Autonomous Language Exploitation (GALE) </a></p> 


		<p><a href="http://web.jhu.edu/hltcoe">
<img src="include/images/hltcoe-logo1.jpg" width="100" border="0"  /><br />
SCALE: Summer Camp for Applied Language Exploration</a></p> 


		<p><a href="http://www.darpa.mil/Our_Work/I2O/Programs/Computer_Science_Study_Group_(CSSG).aspx">
<img src="include/images/cssg.jpg" width="100" border="0"  /><br />
Computer Science Study Group </a></p> 

		<p><a href="http://cordis.europa.eu/search/index.cfm?fuseaction=proj.document&PJ_LANG=EN&PJ_RCN=9055296">
<img src="include/images/EM-logo.gif" width="100" border="0"  /><br />
EuroMatrix: Statistical and hybrid machine translation between all European languages</a></p> 


		<p><a href="http://www.scottishbusinessgrants.gov.uk/rsa/999.html">
<img src="include/images/smart-scotland-logo.gif" width="100" border="0" /><br />
Small business grant for Linear B Ltd.</a></p> 


	  </div>
	<br clear="all" />
</div>


<!-- Start of StatCounter Code -->
<script type="text/javascript">
var sc_project=6898582; 
var sc_invisible=1; 
var sc_security="be87d2b4"; 
</script>

<script type="text/javascript"
src="http://www.statcounter.com/counter/counter.js"></script><noscript><div
class="statcounter"><a title="create counter"
href="http://statcounter.com/free_hit_counter.html"
target="_blank"><img class="statcounter"
src="http://c.statcounter.com/6898582/0/be87d2b4/1/"
alt="create counter" ></a></div></noscript>
<!-- End of StatCounter Code -->

</body>
</html>

	
