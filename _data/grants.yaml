-
   title: FW-HTF Theme 1&colon; Enabling Rural Digital Workers to Collaborate with AI to Learn Skills Over Time, Increase Wages and Opportunities, and Access Creative Work
   awarding_body: NSF (in preparation)
   amount: $3m
   start_date: 2019
   end_date: 2024
   status: pending
   PI_info: Jeffrey Bigham (CMU) - PI, Chris Callison-Burch (UPenn), Ben Hanrahan (Penn State), Aniket Kittur (CMU), Saiph Savage (West Virgina University)
   url: https://www.nsf.gov/pubs/2018/nsf18548/nsf18548.htm
   abstract: 
-
   title: STTR&colon; Personalized Retrieval-based Simplification
   awarding_body: NSF (in preparation)
   amount: $225k
   start_date: 2019
   end_date: 2023
   status: pending
   PI_info: Eleni Miltsakaki (Choosito.com) - PI, Chris Callison-Burch
   url: https://www.nsf.gov/pubs/2017/nsf17595/nsf17595.htm
   abstract: 
-
   title: RIME&colon; Real-tIme Multimodal Evidence-based Reasoning
   awarding_body: ONR (submitted)
   amount: $2m
   start_date: 2019
   end_date: 2023
   status: pending
   PI_info: Zack Ives - PI, Dan Roth, Chris Callison-Burch, Susan Davidson, Mark Sammons
   url: https://www.grants.gov/web/grants/view-opportunity.html?oppId=300565
   abstract: |
     Maintaining situational awareness in support of decision-making, across multiple personnel and with many incoming information streams, poses many challenges.  One must handle unreliable observations, combine low-level observations with background knowledge to produce higher-level predictions of state along with their underlying evidence, efficiently do this in real-time, and formulate potential action recommendations based on goals and objectives. We propose to develop Real-tIme Multimodal Evidence-based Reasoning technologies (RIME).  
     We address the above challenges by considering three key research questions&colon;
     1. How to acquire and represent raw information about classes, entities, and relationships, across various modalities including social media, open-source data posted to the Web, streams of sensor data, and pre-existing knowledge bases.
     2. How to rapidly evaluate, rank, and synthesize data into higher-level conclusions, with associated justifications and confidence levels. 
     3. How to efficiently combine data, constraints and goals, and potential actions into ranked potential courses of action (COAs), and how to present status and COAs to decision-makers in a real-time interactive form.
     Through a multidisciplinary team consisting of artificial intelligence, natural language processing, and web/database researchers, we leverage advances in natural language processing for analyzing single sentences in text, data provenance techniques for providing evidence for hypotheses and conclusions from inference, data stream processing systems for handling high-volume information streams, and planning techniques for finding potential courses of action. Our innovations revolve around how to systematically integrate and represent propositions originating from multiple (sometimes conflicting) streams into a unified model of the world that also incorporates background information; how to integrate across different data modalities such as social media, sensor streams, knowledge bases, and open-source documents; and how to perform reasoning under uncertainty in a streaming environment.
     Our deliverables will be instantiated within a unified RIME system, which takes streams of structured and textual data and continuously updates a concept meta-graph representing (and ranking) the hypothesized situations in the world.  When goals are specified or constraints are being violated, the system will also recommend potential courses of action.  Users will be able to interactively explore the evidence behind each potential situation and each course of action.
-
   title: Learning to Reason with Learned Models and Domain Knowledge
   awarding_body: ONR (submitted)
   amount: $2m
   start_date: 2019
   end_date: 2023
   status: pending
   PI_info: Dan Roth - PI, Zack Ives, Chris Callison-Burch, Susan Davidson, Mark Sammons
   url: https://www.grants.gov/web/grants/view-opportunity.html?oppId=300565
   abstract: |
      There is broad recognition of the promise of data-driven and “intelligent” solutions to a range of complex decision problems in the physical and life sciences, in engineering, and in their applications to problems in government, defense, and the social sciences. There is agreement that decisions should be informed by data. Indeed, the success of statistical machine learning over the last few years in several visible supervised function estimation tasks such as image recognition and speech recognition, has tilted the pendulum in the direction of “only data”. Given a task, the standard machine learning methodology suggests to collect annotated data for this task, and then train a model for it.  However, this methodology is not scalable – it is unrealistic to assume it possible to supervise the complex decisions needed without incorporating domain specific knowledge and background knowledge, which are essential to support problem decomposition, generalization, and transfer, as well as decision making in complex scenarios that have not been observed before. 
      Our primary scientific goal is to change this narrow problem setting and offer an encompassing approach to Learning to Reason&colon; supporting decisions made by incorporating knowledge – domain specific, common sense, declarative and statistical – along with statistically learned models.  We propose to study three fundamental and complementary themes&colon;  
      Inference&colon; We propose a principled computational framework for integrating domain knowledge and machine learning for supporting diverse complex inferences that are robust and transferable. In particular, our inference framework allows the incorporation of different knowledge representations – rules, constraints and preferences – encoding various forms of knowledge – quantitative, temporal, relational and structural. It supports integrating these knowledge representations directly with statistical machine learning models, as a way to bias and combine predictions of individual models, or within a joint (end-to-end) learning and inference framework that account for the declarative constraints while learning. 
      Knowledge Representation&colon; Declarative knowledge representations are powerful since they often come with a proof system. However, they do not account for the ambiguity and variability that are inherent in the messy data that must be dealt with in real world applications. We propose to develop a knowledge representation scheme that supports the “traditional” relational structure, but nevertheless enjoys useful properties of continuous representations. 
      Learning with Knowledge is perhaps the most significant challenge to effective machine learning for complex problems. We will address two key issues in this context&colon; (i) How to guide learning of complex models, via (declarative, soft and hard) prior knowledge and indirect supervision, so that interdependent output variables satisfy, perhaps softly, global expectations; and (ii) How to decompose models and automatically learn KR-like structured models of knowledge, in the course of performing a complex task, as a way to better support transfer across domains and facilitate better generalization for decisions in previously  unseen situations. 
      Our vision and concrete goals are fully supported by the expertise and experience of our team. We are leading researchers in Artificial Intelligence, including natural language processing, machine learning, and knowledge representation and reasoning, as well as in probabilistic knowledge bases, web and databases. We believe that we can significantly impact the way machine learning is studied in the context of complex decision problems, proposing new learning protocols, advanced knowledge representations, and an integrated learning to reason approach. 
-
   title: Using Artificial Intelligence to Understand Gun Violence in America
   awarding_body: University of Pennsylvania URF (submitted)
   amount: $50k
   start_date: 2019
   end_date: 2020
   status: pending
   PI_info: Chris Callison-Burch
   url: http://www.upenn.edu/research/smarts/university_research_foundation/
   abstract: |
      I propose to construct a database of all incidents of gun violence in the United States using techniques from artificial intelligence (AI), natural language processing (NLP), and crowdsourcing. I will extend a project that I developed for my undergraduate computer science class on Crowdsourcing and Human Computation, which uses a large number of volunteers and paid crowd workers to extract data from newspaper articles about gun violence. You can see the current state of the project here&colon; gun-violence.org
      My goals for this research grant are (1) to engineer a system using AI and NLP to automate the data extraction pipeline that is now largely done manually, (2) to build a resource for policy makers, public health researchers, social scientists and advocacy groups so that they may gather data about gun violence in America, and (3) to obtain short term funding for my PhD students, since a recent administrative problem caused a provisionally approved $4M DARPA grant to be rescinded. I plan to seek additional external funding for this project, and I believe that a URF would provide a strong starting point for further research.

-
   title: CI-NEW&colon; NIEUW&colon; Novel Incentives and Workflows in Linguistics Data Collection
   awarding_body: NSF
   amount: $1,218,465
   start_date: July 14, 2017
   end_date: June 30, 2020
   status: current
   PI_info: co-PI with Christopher Cieri and Mark Liberman
   url: https://www.nsf.gov/awardsearch/showAward?AWD_ID=1730377
   abstract: Language touches every aspect of human life. People speak and write in order to manage relationships from the personal to the international, to gather and provide information, to negotiate, influence and inspire. Scientists use language to communicate their findings regardless of their field of study. Although researchers have worked for decades to process language via computer, only in the past several years have their efforts have produced technologies of sufficient maturity that they can affect the lives of the average citizen. Today, some of the most fortunate use computers to search the vast archives of the Internet, to translate material from languages they do not understand into languages they do and to interact with smart devices by giving them natural language commands and queries and receive responses in kind. Despite the growth and promise of human language technologies, they are in fact available only for a tiny portion of the world’s approximately 7000 languages and, even then, only for a limited range of situations. This is the case because the approaches that have proven most successful in developing human language technologies are data starved. Specifically, they require language volumes of spoken or written language that have been augmented by human judgment, but lack such resources for most languages and for many situations even in languages of international importance, including English. This project will address the shortage of language resources by employing novel incentives and alternate workflows to supplement the methods that have been used traditionally to collect and annotate language data. The resulting resources will support an expanded range of language technologies leading to apps for a broader range language of languages and situations. The same data will support basic research in language and language teaching. Even a brief observation of user behavior on social media, online games, citizen science and public good initiatives demonstrates that many people around the world are willing to devote collectively vast amounts of effort when given appropriate motivation and effective tools. This project will harness some of the immense people-power that drives such activities and focus it on problems of developing language resources that help computers learn to process language. Specifically, the project will create a software toolkit to be used by the project team and independent researchers to create online activities that yield language resources. The activities will include games, citizen science and tools for language professionals, clustered into a series of portals that appeal to different populations of users. The project will build and maintain the database and web servers, with redundancy, load balancing and fail over, to run the principal instance of all of the activities. An open source release of the software will enable others to build their own instances independently. Finally, the project will share the data resulting from this project with the least restrictive terms possible to support research, technology development and language teaching. 
-
   title: DEFT Extension
   awarding_body: DARPA
   amount: $116,000
   start_date: 2017
   end_date: 2017
   status: past
   PI_info: PI with Ben Van Durme
-
   title: CI-P&colon; Planning for Scalable Language Resource Creation through Novel Incentives and Crowdsourcing
   awarding_body: NSF
   amount: $100,000
   start_date: 2016
   end_date: 2017
   status: past
   PI_info: co-PI with Christopher Cieri and Mark Liberman
-
   title: Amazon Web Services supplimental grant to Amazon Academic Research Award
   awarding_body: Amazon
   amount: $40,000 
   type: AWS credit
   start_date: 2016
   status: past
   PI_info: PI
-
   title: Low Resource Machine Translation via Matrix Factorization (Amazon Academic Research Awards)
   awarding_body: Amazon
   type: Gift
   amount: $68,000
   start_date: 2016
   end_date: 2017
   status: past
   PI_info: PI
-
   title: Learning translations from monolingual texts (LORELEI)
   awarding_body: DARPA
   amount: $478,000
   start_date: 2015
   end_date: 2019
   status: current
   PI_info: PI at Penn
-
   title: SIREN-IL&colon; Specialized Intra/Interlingual Resources for Emergent News - Incident Language
   awarding_body: DARPA
   amount: $3,031,412
   start_date: 2015
   end_date: 2017
   PI_info: co-PI with Stephanie Strassel
   status: current
-
   title: Natural Logic Solver for Aristo
   awarding_body: Allen Institute for Artificial Intelligence (AI2)
   amount: $95,000
   start_date: 2015
   end_date: 2016
   PI_info: PI
   status: past
-
   title: EAGER&colon; Simplification as Machine Translation
   awarding_body: NSF
   amount: $100,000
   start_date: 2014
   end_date: 2015
   PI_info: PI
   status: past
-
   title: Unsolicited Gift
   awarding_body: Facebook
   amount: $50,000
   start_date: 2014
   status: past
-
   title: Sloan Research Fellowship
   awarding_body: Alfred P. Sloan Foundation
   amount: $50,000
   start_date: 2014
   status: past
-
   title: Google Faculty Research Award (Learning Paraphrases from Large, Diverse Data Sets)
   awarding_body: Google
   amount: $62,000
   start_date: 2013
   status: past
-
   title: Large-scale Paraphrasing for Natural Language Understanding (DEFT)
   awarding_body: DARPA
   amount: $1,600,000
   start_date: 2012
   end_date: 2017
   PI_info: PI with Ben Van Durme
   status: past
-
   title: EAGER&colon; Combining natural language inference and data-driven paraphrasing
   awarding_body: NSF
   amount: $100,000
   start_date: 2012
   end_date: 2013
   status: past
   PI_info: co-PI with Ben Van Durme
-
   title: Crowdsourcing Translation (Computer Science Study Panel phase 3)
   awarding_body: DARPA
   amount: $500,000
   start_date: 2012
   end_date: 2015
   PI_info: PI
   status: past
-
   title: Improved Arabic dialect translation through Crowdsourcing
   awarding_body: DARPA
   amount: $176,000
   start_date: 2012
   end_date: 2013
   status: past
   PI_info: PI
-
   title: Acquisition and use of paraphrases in a knowledge-rich setting
   awarding_body: Vulcan
   amount: $260,000
   start_date: 2011
   end_date: 2013
   status: past
   PI_info: co-PI with Ben Van Durme
-
   title: Google Faculty Research Award (Translate the World&colon; A Unified Framework for Crowdsourcing Translation)
   awarding_body: Google
   amount: $150,000
   start_date: 2011
   status: past
   PI_info: co-PI with Philip Resnik and Ben Bederson
-
   title: Crowdsourcing Translation
   awarding_body: Microsoft
   amount: $25,000
   status: past
   start_date: 2011
-
   title: RI&colon;Medium&colon; Semi-supervised Discriminative Training of Sequence Transduction Model
   awarding_body: NSF
   amount: $800,000
   start_date: 2011
   status: past
   end_date: 2015
   PI_info: co-PI with Sanjeev Khudanpur, Brian Roark, Damianos Karakos, Richard Sproat
-
   title: Translation of informal texts via Mechanical Turk
   awarding_body: BBN Technologies 
   amount: $144,000
   start_date: 2010
   end_date: 2011
   status: past
   PI_info: PI
-
   title: BABEL&colon; Bayesian Architecture Begetting Every Language (Computer Science Study Panel phase 2)
   awarding_body: DARPA
   amount: $500,000
   start_date: 2010
   end_date: 2012
   status: past
   PI_info: PI
-
   title: Google Faculty Research Award (The Babel Challenge&colon; Translating all the World’s Languages)
   awarding_body: Google
   amount: $45,000
   start_date: 2010
   status: past
   PI_info: co-PI with Miles Osborne
-
   title: EuroMatrixPlus&colon; Bringing Machine Translation for European Languages to the User
   awarding_body: European Union Framework 7 Programme
   amount: €4,950,000 
   start_date: 2009
   end_date: 2012
   status: past
   PI_info: PI at JHU (JHU Amount&colon; €516,000)
   notes: JHU Amount&colon; 516,000 euros / 319,000 euros not including cost sharing. Total project budget&colon;4,950,000 euros / 3,800,000 euros not including cost sharing 
-
   title: Global Autonomous Language Exploitation (GALE) project, Periods 3 and 4
   awarding_body: DARPA
   amount: $575,000
   start_date: 2009
   end_date: 2011
   status: past
   PI_info: co-PI with Sanjeev Khudanpur and Damianos Karakos
-
   title: Computer Science Study Panel
   awarding_body: DARPA
   amount: $93,000
   start_date: 2008
   end_date: 2009
   status: past
   PI_info: PI
-
   title: RI&colon;SMALL&colon; Multi-Level Modeling of Language and Translation
   awarding_body: NSF
   amount: $400,000
   start_date: 2007
   end_date: 2012
   status: past
   PI_info: co-PI with David Yarowsky
-
   title: EuroMatrix&colon; Statistical and Hybrid Machine Translation Between All European Lan
   awarding_body: European Union Framework 6 Programme
   amount: €3,200,000 
   start_date: 2009
   end_date: 2012
   PI_info: non-PI coauthor 
   notes: 4,950,000 euros / 3,800,000 euros not including cost sharing 
-
   title: SMART&colon;Scotland Technology Innovation Grant
   awarding_body: British Government
   amount: £45,000 
   start_date: 2002
   end_date: 2005
   status: past
   notes: research funds for my company, Linear B Ltd.